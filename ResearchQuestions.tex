%
% CHAPTER: Computational Creativity
%

\chapterimage{Wikipedia_Monument_2.pdf}

\chapter{The Discovery of the Unknown}
\label{chap:computational-creativity}

\begin{quote}
\begin{flushright}
\emph{To be surprised, to wonder, \\
is to begin to understand.}\\
José Ortega y Gasset \\
\end{flushright}
\end{quote}
\bigskip

In this chapter, we are going to see how to apply in practice our methodology for the assisted discovery of interesting research questions. As was the case in the previous chapter, in which we studied the concept of nescience from a practical point of view, here we will focus on the empirical side of our framework, showing how the theoretical concepts introduced earlier can be operationalized and used to guide actual research activities.

In the first part of this chapter, we will examine how to approximate the two new metrics introduced: relevance and applicability. The relevance of a topic will be estimated from the number of web pages on the Internet that link to the topic's page on Wikipedia (external links). Applicability will be estimated from the number of links among Wikipedia's scientific pages themselves (internal links). We will illustrate both metrics with examples drawn from the set of topics that make up the research area of theoretical computer science.

Next, we will describe how to apply our methodology for the discovery of interesting questions and present several examples of new research questions that, in principle, could be addressed by science. Some of these questions will be intradisciplinary (arising within theoretical computer science) while others will be interdisciplinary, combining theoretical computer science with philosophy or biochemistry. Finally, we will derive a number of new research topics which, according to our subjective interpretation of the combinations found, are sufficiently promising to warrant further investigation. We will also assess whether these proposed topics satisfy the criteria for interesting questions established in Chapter \ref{chap:Interesting-Research-Questions}.

In the last part of the chapter, we will apply the set of metrics defined for the classification of individual research topics to entire research areas. This will allow us to estimate the interestingness of different disciplines both as sources of new problems and as sources of useful tools for solving open problems. These metrics will also enable us to compare the relative merits of different fields of knowledge, and to highlight some examples of research areas that appear to be in decline.

%
% Relevance
%
\section{Relevance}
\label{sec:relevance_in_practice}

\begin{figure}[t]
\centering
\includegraphics[width=0.6\textwidth]{RelevanceTopics.png}
\caption{Relevance of Topics.}
\label{figure:relevance_all_topics}
\end{figure}

In Definition \ref{def:relevance} we introduced the concept of the relevance of a research topic as a measure of the impact that this topic could have on people's lives. The idea was that the higher the relevance, the greater its potential as a source of interesting questions, since it would address problems that affect many people. Relevance was defined as the degree of the research topic in the relevance graph, a bipartite graph connecting topics and people (see Definition \ref{def:relevance-graph}). Of course, this relevance graph is a mathematical abstraction that is very difficult to compute in practice, since we do not have information about how people are affected by each topic.

As a practical proxy for the relevance of a topic, we use its Wikipedia pageviews over the last two months (i.e., the sum of daily visits during the most recent 60 complete UTC days). The intuition is that the more relevant a topic is, the more frequently people will consult its Wikipedia article. Our goal is not an absolute notion of relevance but a measure of relative relevance across topics. Moderate under- or over-estimation is acceptable provided it affects all topics roughly uniformly—for example, due to seasonal effects or platform-wide trends—so that comparative rankings remain stable. Further work is needed to quantify how well pageview-based relevance aligns with the theoretical construct of relevance and to correct for known biases (e.g., transient news spikes or bot traffic).

\begin{table}
\begin{centering}
\begin{tabular}{|c|c|}
\hline 
Topic & Relevance \tabularnewline
\hline 
\hline 
Dirac delta function & 70,869 \tabularnewline
\hline 
Rule of inference & 58,356 \tabularnewline
\hline 
Fast inverse square root & 46,570 \tabularnewline
\hline 
Euclidean algorithm & 38,032 \tabularnewline
\hline 
Trie & 29,116 \tabularnewline
\hline 
Binary search & 23,246 \tabularnewline
\hline 
Reinforcement learning from human feedback & 22,294 \tabularnewline
\hline 
Commutative property & 17,322 \tabularnewline
\hline 
Gale–Shapley algorithm & 11,251 \tabularnewline
\hline 
Pick's theorem & 7,255 \tabularnewline
\hline 
\end{tabular}
\par\end{centering}
\caption{\label{tab:Most-Relevant-Topics}Most relevant topics}
\end{table}

In Figure \ref{figure:relevance_all_topics}, which shows the histogram of the relevance of all good articles in the area of theoretical computer science, total traffic over the last 60 days is 393,672 pageviews, with an average relevance of 7,719. The histogram shows a classic head–long-tail pattern: most topics cluster in the lowest bins (a few hundred to a few thousand pageviews), while a small number of articles receive very large traffic, extending the right tail out past ~70k. The top three pages—Dirac delta function (70,869), Rule of inference (58,356), and Fast inverse square root (46,570)—collect 44.7\% of all views. This strong right-skew implies that the mean relevance will sit far above the median and be dominated by a handful of high-visibility pages (e.g., widely taught or broadly cited topics). The sparsity of mid-range bins suggests a sharp separation between everyday background interest and a small set of standout articles; outliers are genuine and not just binning artifacts. For modeling purposes we will use log-transformed counts to stabilize variance.

Table \ref{tab:Most-Relevant-Topics} lists the ten most relevant topics according to this metric. For each topic, it shows its raw relevance (number of external links). The top ten ariticles account for 82.4\% of the total page views. Overall, the list aligns reasonably well with what one would expect to attract broad attention around theoretical computer science. Judged purely by intuitive relevance (irrespective of formal classification), most items in the list plausibly merit attention from a theoretical computer science audience: Euclidean algorithm, Binary search, Trie, and the Gale–Shapley algorithm are canonical in algorithms, data structures, and algorithmic game theory; Rule of inference underpins proof techniques used throughout complexity and verification; Fast inverse square root is a celebrated algorithmic trick illustrating implementation–theory trade-offs; and Reinforcement learning from human feedback reflects an influential line of modern learning that interacts with algorithmic and statistical theory.

A few highly viewed pages are better understood as adjacent or cross-disciplinary anchors rather than core theoretical computer science articles: Dirac delta function (analysis/mathematical physics), Commutative property (elementary algebra), or Pick’s theorem (discrete geometry). As it was explained in Section \ref{sec:measuring_research_areas}, Wikipedia’s hierarchical category system is not a strict ontological taxonomy with hard area–subarea boundaries; it is closer to a bibliographic organization in which topics are linked across neighboring fields when readers, editors, or sources commonly associate them. In this sense, it is unsurprising—and entirely reasonable—that a few non-pure TCS pages appear alongside canonical entries such as the Euclidean algorithm, binary search, tries, and the Gale–Shapley algorithm. 

\begin{table}
\begin{centering}
\begin{tabular}{|c|c|}
\hline 
Topic & Relevance \tabularnewline
\hline 
\hline 
Well-covered graph & 228 \tabularnewline
\hline 
BIT predicate	 & 242 \tabularnewline
\hline 
Halin graph & 360 \tabularnewline
\hline 
Laves graph & 462 \tabularnewline
\hline 
Tropical cyclone forecast model & 510 \tabularnewline
\hline 
Book embedding & 516 \tabularnewline
\hline 
Turán's brick factory problem & 520 \tabularnewline
\hline 
Farthest-first traversal & 626 \tabularnewline
\hline 
Cop-win graph & 647 \tabularnewline
\hline 
Finite subdivision rule & 662 \tabularnewline
\hline 
\end{tabular}
\par\end{centering}
\caption{\label{tab:Least-Relevant-Topics}Least relevant topics}
\end{table}

Table \ref{tab:Least-Relevant-Topics} lists the ten least relevant topics according to this metric. The bottom ten articles account for 1.2\% of the total page views. Well-covered graph, Halin graph, Cop-win graph, and Book embedding speak to structural and algorithmic themes in graph theory and graph drawing; Turán’s brick factory problem and Finite subdivision rule touch classic extremal and geometric constructions; Farthest-first traversal is a recognizable clustering/approximation heuristic; and the BIT predicate underlies descriptive complexity formalisms that, while niche, are conceptually central. By contrast, Laves graph and Tropical cyclone forecast model draw smaller, more domain-specific audiences yet still intersect algorithmic or structural concerns. The common thread is their narrow scope: these topics serve expert or subfield-focused needs rather than broad readership, which naturally depresses pageviews. Consequently, pageviews are a sensible proxy for broad relevance (what many people consult), that match or intuition of how many people could be affected by the topic.

Taken together, both lists are consistent with what we would expect people to consult when engaging with theoretical computer science ideas. Using Wikipedia pageviews as a proxy for relevance is therefore a sensible first-order approximation: it captures widespread interest in core topics, is easy to compute at scale, and yields stable comparative rankings over multi-week windows, while benefiting from standard safeguards (e.g., log-scaling, smoothing, and outlier checks) to mitigate transient spikes or teaching-cycle effects.

%
% Section: Applicability
%
\section{Applicability}

Applicability measures how likely it is that a research topic can be applied to solve open problems. The underlying idea is that if a tool has already been applied to solve multiple problems, then there is a high probability that it can be used again to solve new ones. Formally, the number of problems to which a tool has been applied is computed using the applicability graph (see Definition \ref{def:applicability-graph}), and the applicability of a topic is defined as its out-degree in this graph (see Definition \ref{def:applicability}). 

In practice, we have approximated the applicability graph by using the network of internal links between the scientific pages of Wikipedia. Specifically, we approximate the applicability of a topic by counting the number of Wikipedia pages that link to its page (using the \emph{``What links here''} facility, which lists the pages that link to—but do not redirect to—the current page).

Figure \ref{fig:Applicability-of-Topics} shows a histogram of the applicability values for the selected set of topics. The histogram's shape is dominated by an enormous spike in the very first bin and a sparsely populated, elongated right-hand tail. Roughly three-quarters of the theoretical computer science topics attract fewer than about 50 incoming Wikipedia links, while only a few reach the triple-digit range and just one or two exceed 300. This steep drop-off is the hallmark of a power-law (or at least heavy-tailed) distribution: applicability, as measured here, is concentrated in a tiny set of "super-connectors," while the median topic sees only modest reuse. In practical terms, the average link count is a misleadingly optimistic figure—pulled upward by a few giants—whereas the typical topic remains relatively niche.

Such inequality has several implications. First, it reinforces the idea that a small core of foundational concepts underpins a large share of problem-solving across the field; investing effort in those hubs yields the greatest leverage. Second, the near-emptiness of the mid-range suggests that rising topics face a kind of applicability “valley of death”: they must bridge a substantial gap before joining the elite group of widely referenced concepts. Finally, the long tail highlights opportunity—numerous specialized notions lie at low link counts, potentially poised for breakout if new cross-disciplinary applications emerge.

Table \ref{tab:Applicability-of-Topics} lists the ten most applicable topics according to this metric. The backlink data confirm the long-tailed picture hinted at by the histogram: applicability, at least as proxied by Wikipedia's “What links here” counts—is highly unequal. A single super-hub (the \emph{Dirac delta function}, 625 links) dwarfs the rest, while only a handful of topics even cross the 200-link mark. This means that when researchers look for broadly reusable tools, the "return on attention" is greatest in a very small set of concepts that already function as connective tissue across many areas.

Equally striking is \emph{who} those hubs are. Alongside classic algorithmic staples such as the \emph{Euclidean algorithm}, \emph{Trie}, and \emph{Binary search}, we see foundational math and logic notions (e.g., \emph{Rule of inference}, \emph{Commutative property}), a fast-rising AI methodology (\emph{Reinforcement learning from human feedback}), and even a domain-specific meteorology model. In other words, high applicability favors breadth rather than disciplinary purity: ideas that spill into multiple conversations—whether introductory, theoretical, or applied—accumulate the most links. For anyone mapping future research bets, this suggests monitoring backlink growth over time (to catch newcomers like RLHF early) and normalizing counts by sub-field size to filter out topics whose popularity is driven by narrow, self-referential clusters.

\begin{table}
\begin{centering}
\begin{tabular}{|c|c|}
\hline 
Topic & Internal Links \tabularnewline
\hline
\hline
Dirac delta function & 625\tabularnewline
\hline
Rule of inference & 409\tabularnewline
\hline
Reinforcement learning from human feedback & 351\tabularnewline
\hline
Euclidean algorithm & 343\tabularnewline
\hline
Trie & 244\tabularnewline
\hline
Telephone number (mathematics) & 228\tabularnewline
\hline
Commutative property & 214\tabularnewline
\hline
Tropical cyclone forecast model & 195\tabularnewline
\hline
Cartesian tree & 155\tabularnewline
\hline
Binary search & 116\tabularnewline
\hline 
\end{tabular}
\par\end{centering}
\caption{\label{tab:Applicability-of-Topics}Applicability of topics}
\end{table}

%
% Section: Maturity
%

\section{Maturity}

As introduced in Definition \ref{def:surfeit}, \emph{maturity} is the opposite of \emph{surfeit}. While surfeit measures the amount of redundant or superfluous information present in our current description of a topic, maturity quantifies how concise and efficient that description has become. In other words, a topic is considered mature when our understanding of it is sufficiently advanced that its essential content can be stated without unnecessary verbosity. High maturity thus indicates that knowledge about the topic has been largely consolidated, leaving little room for removing redundant parts from its description.

The maturity of a topic is estimated based on the length of its Wikipedia article (only the textual content) and the length of a compressed version of that same text. The intuition behind this approach is that the more mature a topic is, the less redundant information its article will contain, and therefore the better it can be compressed. Topics that are still immature often accumulate loosely organized or repetitive content, which resists compression. By comparing the original and compressed lengths, we obtain a practical proxy for surfeit (as the ratio between the two lengths), and therefore for maturity as its inverse.

Table \ref{tab:Maturity-of-Topics} lists the ten most mature topics according to this metric. For each topic, it shows its maturity value and its normalized version. Well-classified topics—those that our intuition tells us are well understood—include \emph{Read-only right moving Turing machines}, \emph{Crossing sequence (Turing machines)}, and perhaps the \emph{P'' language}. Other topics that might be misclassified include \emph{communication X-Machine}, \emph{Power DEVS}, \emph{MPIR}, and \emph{constraint automaton}.


\begin{table}
\begin{centering}
\begin{tabular}{|c|c|c|}
\hline 
Topic & Maturity & Norm.\tabularnewline
\hline 
\hline 
Carry operator & 5.34 & 1.00\tabularnewline
\hline 
Binade & 4.54 & 0.99\tabularnewline
\hline 
Comm. X-Machine & 3.01 & 0.97\tabularnewline
\hline 
PowerDEVS & 2.35 & 0.94\tabularnewline
\hline 
MPIR & 2.00 & 0.92\tabularnewline
\hline 
Constraint automaton & 1.84 & 0.90\tabularnewline
\hline 
RO right moving TM & 1.73 & 0.89\tabularnewline
\hline 
P'' & 1.71 & 0.89\tabularnewline
\hline 
Crossing sequence (TM) & 1.63 & 0.88\tabularnewline
\hline 
Microsoft Binary Format & 1.53 & 0.86\tabularnewline
\hline 
\end{tabular}
\par\end{centering}

\caption{\label{tab:Maturity-of-Topics}Maturity of topics}
\end{table}

%
% Section: Interestingness
%
\section{Interestingness}

The \emph{interestingness} of a topic, when considered as a tool, measures the likelihood that this tool can be applied to other problems. Table \ref{tab:Interestingness-of-Areas-as-Tools} shows the average applicability and average maturity of each of the selected areas, together with their average interestingness as a source of tools. The table largely fits our intuitive expectations about which areas are more important as sources of tools: computer science appears as the most interesting area, while sociology is the least. The only surprising case is epistemology, which emerges as a source of very interesting tools, even more so on average than mathematics. This anomaly may be explained by the high proportion of poorly written articles in this area, which artificially lowers maturity and thereby increases the calculated interestingness.

\begin{table*}
\begin{centering}
\begin{tabular}{|c|c|c|c|}
\hline 
Research Area & Applicability & Maturity & Tools\tabularnewline
\hline 
\hline 
Sociology & $1.00\times10^{-3}$ & $2.93\times10^{-3}$ & $3.09\times10^{-3}$\tabularnewline
\hline 
Biology & $9.20\times10^{-4}$ & $4.65\times10^{-3}$ & $4.74\times10^{-3}$\tabularnewline
\hline 
Chemistry & $3.11\times10^{-3}$ & $5.01\times10^{-3}$ & $5.90\times10^{-3}$\tabularnewline
\hline 
Psychology & $1.14\times10^{-3}$ & $6.91\times10^{-3}$ & $7.00\times10^{-3}$\tabularnewline
\hline 
Mathematics & $9.32\times10^{-3}$ & $9.47\times10^{-3}$ & $1.32\times10^{-2}$\tabularnewline
\hline 
Epistemology & $1.55\times10^{-3}$ & $1.75\times10^{-2}$ & $1.76\times10^{-2}$\tabularnewline
\hline 
Computer\_science & $9.93\times10^{-3}$ & $1.90\times10^{-2}$ & $2.15\times10^{-2}$\tabularnewline
\hline 
\end{tabular}
\par\end{centering}

\caption{\label{tab:Interestingness-of-Areas-as-Tools}Interestingness of Areas
as Tools}
\end{table*}

Table \ref{tab:Interestingness-of-Areas-as-Problems} shows the relevance and nescience of the selected areas, as well as their interestingness as sources of problems. Once again, the results align with our intuition: sociology is the area with the highest number of interesting problems, while mathematics is the area with the fewest.

\begin{table*}
\begin{centering}
\begin{tabular}{|c|c|c|c|}
\hline 
 & Relevance & Nescience & Problems\tabularnewline
\hline 
\hline 
Mathematics & $4.22\times10^{-2}$ & $3.51\times10^{-1}$ & $3.53\times10^{-1}$\tabularnewline
\hline 
Computer\_science & $2.35\times10^{-2}$ & $4.43\times10^{-1}$ & $4.44\times10^{-1}$\tabularnewline
\hline 
Chemistry & $5.95\times10^{-2}$ & $4.66\times10^{-1}$ & $4.70\times10^{-1}$\tabularnewline
\hline 
Biology & $3.85\times10^{-2}$ & $4.75\times10^{-1}$ & $4.77\times10^{-1}$\tabularnewline
\hline 
Psychology & $5.06\times10^{-2}$ & $5.28\times10^{-1}$ & $5.31\times10^{-1}$\tabularnewline
\hline 
Epistemology & $4.54\times10^{-2}$ & $5.30\times10^{-1}$ & $5.32\times10^{-1}$\tabularnewline
\hline 
Sociology & $4.21\times10^{-2}$ & $5.43\times10^{-1}$ & $5.44\times10^{-1}$\tabularnewline
\hline 
\end{tabular}
\par\end{centering}

\caption{\label{tab:Interestingness-of-Areas-as-Problems}Interestingness of Areas as Problems}
\end{table*}

Table \ref{tab:Interestingness-of-Tools} lists the ten most relevant topics according to their interestingness as tools. Out of these ten, only two (\emph{ternary numeral system} and \emph{recursion}) appear in the lists of the top ten most mature or most applicable topics; the rest are new. Among these we find clear examples of tools, such as the \emph{GNU Multiple Precision Arithmetic Library} and the \emph{standard for radix-independent floating-point arithmetic} (IEEE 854-1987). Other cases are less clear, such as \emph{arithmetic logic unit}, \emph{barrel shifter}, or \emph{arithmetic overflow}. Topics that match our intuitive notion of a tool include \emph{recursion}, \emph{state space}, \emph{abstract machine}, and \emph{ternary numeral system}. Finally, some topics, like \emph{computational model}, are too broad to be meaningful in the context of a single research question.

\begin{table}
\begin{centering}
\begin{tabular}{|c|c|}
\hline 
Topic & Interestingness\tabularnewline
\hline 
\hline 
GNU MPAL & 0.49\tabularnewline
\hline 
Ternary numeral system & 0.48\tabularnewline
\hline 
IEEE 854-1987 & 0.47\tabularnewline
\hline 
Arithmetic logic unit & 0.43\tabularnewline
\hline 
Recursion & 0.42\tabularnewline
\hline 
Barrel shifter & 0.42\tabularnewline
\hline 
State space & 0.42\tabularnewline
\hline 
Abstract machine & 0.41\tabularnewline
\hline 
Computational model & 0.39\tabularnewline
\hline 
Arithmetic overflow & 0.39\tabularnewline
\hline 
\end{tabular}
\par\end{centering}

\caption{\label{tab:Interestingness-of-Tools}Interestingness of Tools}
\end{table}

Table \ref{tab:Interestingness-of-Problems} lists the ten most interesting topics as problems. Examples that align with our intuitive notion of problems—concepts that are both highly relevant and poorly understood—include \emph{arithmetical hierarchy}, \emph{halting problem}, \emph{floating point}, \emph{quantum computer}, and \emph{computable function}. Interestingly, the topic \emph{recursion} appears in both lists: as a tool it refers to the general concept, while as a problem it refers to the specific implementation of recursion in computer science. The classification of \emph{regular expression} as a problem, rather than as a tool, can be explained by the length and detail of its Wikipedia article, which provides an extensive reference-level description. This observation raises the broader methodological question of how to distinguish introductory from reference articles when analyzing Wikipedia data. Finally, some topics, such as \emph{computability theory}, \emph{lambda calculus}, and \emph{computability}, are too broad to be treated as individual problems.

\begin{table}
\begin{centering}
\begin{tabular}{|c|c|}
\hline 
Topic & Interestingness\tabularnewline
\hline 
\hline 
Arithmetical hierarchy & 0.72\tabularnewline
\hline 
Regular expression & 0.68\tabularnewline
\hline 
Computability theory & 0.65\tabularnewline
\hline 
Halting problem & 0.65\tabularnewline
\hline 
Recursion (CS) & 0.64\tabularnewline
\hline 
Lambda calculus & 0.63\tabularnewline
\hline 
Floating point & 0.61\tabularnewline
\hline 
Quantum computer & 0.57\tabularnewline
\hline 
Computability & 0.55\tabularnewline
\hline 
Computable function & 0.55\tabularnewline
\hline 
\end{tabular}
\par\end{centering}

\caption{\label{tab:Interestingness-of-Problems}Interestingness of Problems}
\end{table}

% \begin{remark}
% Based on the given definition of "Interestingness of a topic as a tool", we can explore various mathematical properties and concepts derived from this idea. Some possibilities include:

% \begin{itemize}

% \item Normalization: To compare different topics fairly, we can normalize their interestingness values by scaling them to a specific range, e.g., [0, 1]. This normalization can help compare the relative interestingness of various topics.

% \item Weighted Interestingness: We can introduce weights to the maturity and applicability dimensions to emphasize one over the other depending on the specific context or application. This would allow us to fine-tune the interestingness measure for different scenarios.

% \item Correlation: Studying the correlation between maturity and applicability could provide insights into how these dimensions are related and possibly reveal trends across different research topics.

% \item Cluster Analysis: By examining topics in the two-dimensional vector space defined by maturity and applicability, we can perform cluster analysis to identify groups of topics with similar levels of interestingness. This can help identify areas of research that share characteristics and possibly suggest interdisciplinary research opportunities.

% \item Rate of Change: Investigating the rate of change of interestingness over time can provide insights into the evolving landscape of a research field. This analysis could reveal emerging topics or those that are becoming less relevant.

% \item Optimization: Using the interestingness metric, we can explore optimization techniques to find the most interesting topics given certain constraints or within specific domains. This could be useful for research prioritization and resource allocation.

% \end{itemize}

% These derived mathematical properties and concepts can provide a deeper understanding of the interestingness of research topics and their potential application as tools for solving problems.

% \end{remark}

%
% Section: Interesting Research Questions
%
\section{Interesting Research Questions}

Before computing the new interesting questions, it is highly convenient to normalize the metrics of the topics involved in the study. Otherwise, a small number of topics with extreme values could dominate the results. For the normalization process we have used the Box-Cox method, which is based on the identification of the best transformation from a family of power transformations. This method is particularly useful when the data is skewed or exhibits heteroscedasticity, as it stabilizes variance and makes the distributions of the metrics more comparable across topics.

A major challenge in identifying topics as tools, that is, topics with very high maturity (or, equivalently, very low nescience), is to distinguish between cases where a description is short because the topic is genuinely well understood (for example, a mathematical theorem), and cases where the article is short simply because it is unfinished or poorly written. Our approach uses Wikipedia's classification of articles as stubs, but this classification is far from reliable, since many articles that are essentially stubs are not labeled as such. Many of the misclassified topics in our dataset suffer from precisely this problem. Developing an automatic method to distinguish well-understood topics from poorly written descriptions remains an open research question.

By combining the results of Table \ref{tab:Interestingness-of-Tools}
and Table \ref{tab:Interestingness-of-Problems}, we can generate new ideas for how existing tools might be applied to open problems. As stated above, the goal of this approach is not to provide definitive research problems, but to highlight potentially interesting applications. It is ultimately the responsibility of the researcher to decide whether a given combination of topics is meaningful and worth pursuing. Table \ref{tab:Interesting-Intradisciplinary-Questions} shows the results of this intradisciplinary combination process.

\begin{table*}
\begin{centering}
\begin{tabular}{|l|c|c|}
\hline 
{Tool} & Problem & Interestingness\tabularnewline
\hline 
\hline 
Ternary numeral system & Regular expression & 1.21\tabularnewline
\hline 
{GNU MPAL} & Arithmetical hierarchy & 1.19\tabularnewline
\hline 
IEEE 854-1987 & Arithmetical hierarchy & 1.17\tabularnewline
\hline 
Quantum computer & Regular expression & 1.17\tabularnewline
\hline 
Ternary numeral system & Arithmetical hierarchy & 1.15\tabularnewline
\hline 
Division by zero & Regular expression & 1.15\tabularnewline
\hline 
Turing machine & Regular expression & 1.14\tabularnewline
\hline 
GNU MPAL & Regular expression & 1.13\tabularnewline
\hline 
Ternary numeral system & Halting problem & 1.13\tabularnewline
\hline 
Recursion & Halting\_problem & 1.13\tabularnewline
\hline 
\end{tabular}
\par\end{centering}

\caption{\label{tab:Interesting-Intradisciplinary-Questions}Interesting Intradisciplinary
Questions}
\end{table*}

Most of the interesting questions identified in this way have relatively low quality. As noted earlier, the main difficulty is that it is very hard to distinguish automatically, and in an unsupervised fashion, between a short article that reflects a well-understood topic and a short article that is simply poorly written. In this section we review some of the identified intradisciplinary questions in order to clarify what we mean by \emph{interesting question} and how such questions should be interpreted. A few examples include:
\begin{itemize}
\item Interesting Question 7: \emph{Can we apply Turing machines to regular expressions?} The answer is clearly yes, and this is a well-known result: regular expressions define regular languages, which are recognized by finite automata, and finite automata can be simulated by Turing machines.
\item Interesting Question 10: \emph{Can we apply recursion to the halting problem?} Again, the answer is yes. The proof of the undecidability of the halting problem is itself based on a machine that calls itself recursively.
\end{itemize}
Both examples demonstrate that the methodology does not always produce original questions, but sometimes recovers already established results.

The most genuinely interesting questions arise when combining topics from two different disciplines. However, the probability that such automatically identified questions are meaningful is typically lower than in the intradisciplinary case, due to larger semantic gaps between fields.

For the interdisciplinary analysis we used the same collection of pages from the theory of computation as in the intradisciplinary study, combined with a new collection of topics from the area of bioinformatics. The topics were selected using the Wikipedia categories \emph{natural sciences}, \emph{biology}, and \emph{biological processes}. In total, more than $10^{5}$ combinations were analyzed. Table \ref{tab:Interesting-Intradisciplinary-Questions-1-1} lists the most relevant interdisciplinary applications.

\begin{table*}
\begin{centering}
\begin{tabular}{|l|c|c|}
\hline 
{Tool} & Problem & Interestingness\tabularnewline
\hline 
\hline 
State space & Action potential & 1.17\tabularnewline
\hline 
{Turing machine} & Action potential & 1.16\tabularnewline
\hline 
Quantum computer & Action potential & 1.16\tabularnewline
\hline 
Abstract machine & Action potential & 1.14\tabularnewline
\hline 
Computational model & Action potential & 1.13\tabularnewline
\hline 
State space & Membrane potential & 1.12\tabularnewline
\hline 
State space & Meiosis & 1.11\tabularnewline
\hline 
Arithmetic logic unit & Meiosis & 1.11\tabularnewline
\hline 
GNU MPAL & Flashbulb memory & 1.11\tabularnewline
\hline 
Ternary numeral system & Working memory & 1.10\tabularnewline
\hline 
\end{tabular}
\par\end{centering}

\caption{\label{tab:Interesting-Intradisciplinary-Questions-1-1}Interesting
Interdisciplinary Questions}
\end{table*}

The interdisciplinary set of questions also suffers from the stub-article problem, and thus the quality of the results remains limited. Nevertheless, some examples are worth discussing:
\begin{itemize}
\item Interesting Question 1: \emph{Can we apply state space to action potential?} Questions 1-5 all point toward the same idea: whether the notion of action potential can be formalized in a way that allows it to be simulated or reproduced computationally.
\item Interesting Question 7: \emph{Can we apply state space to meiosis?} This is analogous to Question 1, but now concerning the possibility of formalizing and simulating the process of meiosis.
\end{itemize}
These examples illustrate how interdisciplinary combinations can hint at possible directions for formal modeling, even if many of the suggested questions are too vague or already well established to constitute truly novel research avenues.


%
% Section: New Research Topics
%
\section{New Research Topics}

If we combine the list of highly relevant and not very well understood problems with themselves, we might obtain new topics that lie in the \emph{unknown unknown} area.

Table \ref{tab:Serendipity-Topics} presents the top 25 candidates for potential new topics according to their interestingness. In this analysis we included all the topics from all knowledge areas. A striking result is that many of the suggested combinations involve the concept of intellectual property (\emph{copyright}, \emph{open access}, \emph{public domain}, and perhaps \emph{wiki}), which suggests that this is an area where there are still many issues to explore, far more than we might expect. On the other hand, it is possible that the outcome reflects a bias in Wikipedia toward these topics. Further investigation is needed to clarify this point.

To illustrate how new topics are generated, we consider the following examples:

\begin{itemize}
\item New topic 17: \emph{Public domain + Earth}. This question raises the issue of whether the Earth should be considered a public resource, touching upon the fundamental concept of private property. The methodology suggests that this is not a well-understood topic.
\item New topic 18: \emph{Public domain + Internet}. This raises a similar issue to Question 17, but in the context of Internet governance.
\end{itemize}

In both cases, however, the combinations fail to provide well-defined, innovative, and genuinely novel research topics.

\begin{table*}
\begin{centering}
\begin{tabular}{|l|c|c|}
\hline 
{Problem} & Problem & Interestingness\tabularnewline
\hline 
\hline 
Public domain & Open access & 1.71\tabularnewline
\hline 
{Public domain} & REST & 1.70\tabularnewline
\hline 
Public domain & Wiki & 1.70\tabularnewline
\hline 
Open access & REST & 1.70\tabularnewline
\hline 
Copyright & Public domain & 1.69\tabularnewline
\hline 
Open access & Wiki & 1.69\tabularnewline
\hline 
Public domain & QR code & 1.69\tabularnewline
\hline 
Copyright & Open access & 1.68\tabularnewline
\hline 
Wiki & REST & 1.68\tabularnewline
\hline 
Open access & QR code & 1.68\tabularnewline
\hline 
Public domain & Transport Layer Security & 1.68\tabularnewline
\hline 
Copyright & REST & 1.68\tabularnewline
\hline 
QR code & REST & 1.67\tabularnewline
\hline 
Open access & Transport Layer Security & 1.67\tabularnewline
\hline 
Copyright & Wiki & 1.67\tabularnewline
\hline 
Wiki & QR code & 1.67\tabularnewline
\hline 
Public domain & Earth & 1.67\tabularnewline
\hline 
Public domain & Internet & 1.67\tabularnewline
\hline 
REST & Transport Layer Security & 1.66\tabularnewline
\hline 
Copyright & QR code & 1.66\tabularnewline
\hline 
Earth & Open access & 1.66\tabularnewline
\hline 
Internet & Open access & 1.66\tabularnewline
\hline 
Public domain & Open source & 1.66\tabularnewline
\hline 
Public domain & Web 2.0 & 1.66\tabularnewline
\hline 
Wiki & Transport Layer Security & 1.66\tabularnewline
\hline 
\end{tabular}
\par\end{centering}

\caption{\label{tab:Serendipity-Topics}New Topics}
\end{table*}

We can also restrict our search for new topics to a reduced number of knowledge categories. For example, Table \ref{tab:Restricted-Serendipity} shows the ten most interesting new topics arising from the already studied area of \emph{theory of computation} and the new area of \emph{phenomenology} (from Level 2 \emph{philosophy of mind}, and Level 1 \emph{cognitive science}). Based on this list, we might consider the following potential new topics:

\begin{itemize}
\item New topic 2: \emph{Turing machine + synesthesia}. This could suggest a new type of Turing machine that incorporates synesthetic properties. These \emph{synesthetic Turing machines} might be defined as a group of Turing machines linked together so that when one machine reads a symbol from its tape, it automatically triggers a state change in another machine. This property of synesthesia could also be extended to nondeterministic Turing machines.
\item New topic 4: \emph{Kolmogorov complexity + self-awareness}. This could be interpreted as an investigation into the minimum complexity required for a computer program to exhibit self-awareness.
\end{itemize}

\begin{table*}
\begin{centering}
\begin{tabular}{|l|c|c|}
\hline 
{Question} & Question & Interestingness\tabularnewline
\hline 
\hline 
Kolmogorov complexity & Change blindness & 1.24\tabularnewline
\hline 
{Turing machine} & Synesthesia & 1.23\tabularnewline
\hline 
Kolmogorov complexity & Qualia & 1.23\tabularnewline
\hline 
Kolmogorov complexity & Self-awareness & 1.22\tabularnewline
\hline 
Turing machine & Qualia & 1.22\tabularnewline
\hline 
Kolmogorov complexity & Synesthesia & 1.21\tabularnewline
\hline 
Turing completeness & Synesthesia & 1.20\tabularnewline
\hline 
Turing machine & Self-awareness & 1.20\tabularnewline
\hline 
Turing completeness & Qualia & 1.20\tabularnewline
\hline 
Turing completeness & Self-awareness & 1.18\tabularnewline
\hline 
\end{tabular}
\par\end{centering}

\caption{\label{tab:Restricted-Serendipity}Restricted New Topics}
\end{table*}

%
% Section: The Unknown Unknowns Project
%
\section{The Unknown Unknowns Project}

The Unknown Unknowns Project is rooted in the theory of nescience, and in particular in its metrics for quantifying how well we understand a scientific topic. It builds upon the idea that by combining topics that are not yet well understood, we can generate new and previously unknown areas of knowledge. The project leverages the rich collection of scientific descriptions contained in Wikipedia to map the current extent of human understanding and to detect where it begins to fail. Its ultimate goal is to discover what lies hidden in the scientific unknown unknown, the research topics that humanity not only does not understand but is not yet aware it does not understand. In essence, the project aims to bring to the present the research topics of the future.

\subsection*{Wikipedia Crawling}

We treat Wikipedia as a vast, labeled graph in which vertices represent pages and categories, and edges connect categories to their subcategories and contained pages. Starting from a small set of root scientific categories, we perform a breadth-first traversal to identify relevant pages. For each discovered article, we (i) retrieve structured metadata in batches via the MediaWiki API, (ii) apply structural and quality filters to remove out-of-scope entries (e.g., redirects, disambiguation pages, and non-scientific entities identified through Wikidata typing), and (iii) compute per-page metrics, including pageviews (relevance) and compression-based maturity or surfeit derived from article text. Finally, we normalize these metrics and export both a tabular dataset and a hierarchical JSON representation of the category-page structure.

Our pipeline relies on three Wikimedia services: the MediaWiki Action API (English Wikipedia) for category traversal, page metadata, content, and assessments; the Wikidata Query Service (WDQS) to verify whether a page's topic should be excluded by checking instance of (P31) and transitive subclass of (P279*) relationships; and the Wikimedia REST Pageviews API to aggregate daily user pageviews over a specified time window. 

\emph{Step 1.- Category traversal.} We begin with a list of root categories ("Applied sciences," "Formal sciences," "Natural sciences," and "Social sciences") and discover associated scientific pages via a breadth-first search (BFS) up to a user-defined maximum depth (by default 5). In Wikipedia, a category is itself a page that organizes subcategories and pages. Categories reside in \texttt{namespace} 14, while encyclopedic articles (our targets) belong to \texttt{namespace} 0 or mainspace. Using the MediaWiki Action API's \texttt{list=categorymembers}, which returns both subcategories and pages directly contained in a category, we iterate level by level. For each category, we call \texttt{action=query}, following pagination through the returned \texttt{cmcontinue} and \texttt{continue} tokens, which are pagination tokens provided by the MediaWiki API and must be included in subsequent requests to retrieve additional results until no further tokens are returned. Since the category graph is a directed acyclic graph (DAG) rather than a strict hierarchy (categories may have multiple parents), we explicitly record edges rather than assuming a unique tree. At each iteration, discovered subcategories are added to the BFS frontier, and all discovered pages are added to the dataset. Visited sets for categories and pages prevent duplicates and cycles. We record the structure as category edges (parent category id, child category id) for the category DAG and page to categories (page id, category id) for direct page-category relationships.

\emph{Step 2.- Batch enrichment of page properties.} For the distinct page ids identified in Step 1, we obtain metadata from the MediaWiki Action API in batches of at most 50 ids per request using \texttt{action=query}. The \texttt{info} module provides metadata (page ids, titles), redirect status, and content model; \texttt{pageprops} includes structured flags such as \texttt{disambiguation} and \texttt{set\_index\_article}, along with the Wikidata identifier (\texttt{wikibase\_item}); \texttt{revisions} retrieves the latest wikitext, byte size, and timestamp; categories lists all page categories (for completeness); and \texttt{pageassessments} returns community quality ratings (e.g., Stub, Start, C, B, GA, FA) assigned by WikiProjects.

\emph{Step 3.- Filtering.} We retain only pages passing a series of structured checks, avoiding heuristic title filters (e.g., avoiding regular-expression checks on page titles). First, we apply structural filters to ensure valid encyclopedic content: the page must be in mainspace, not a redirect, not a disambiguation page, not a set-index page, and must use the wikitext content model. Next, we apply quality filters to exclude low-quality or list-style pages: we prioritize the community PageAssessments label and discard Stubs (including List/FL and Start quality classes).  Finally, we remove non-scientific topics via Wikidata typing: each page's Wikidata entity (its Q-ID in \texttt{pageprops.wikibase\_item}) is tested through WDQS to determine whether a path—following "instance of" (P31) and recursively "subclass of" (P279) relationships in Wikidata, tracing upward through the class hierarchy—P31 / (P279)* leads to any of several high-level deny anchors (e.g., human Q5, book Q571, film Q11424, city Q515, Wikimedia list article Q13406463). Here, P31 means "instance of," P279 means "subclass of," and (P279)* represents zero or more subclass steps (the transitive closure). If such a path exists, the page is excluded. This three-part filter removes people, places, creative works, organizations, products, and other non-topic entities, yielding a clean collection of scientific articles.

\emph{Step 4.- Metric collection.} For each remaining page, we compute a consistent set of features. We first  measure the article's length from its wikitext after removing low-signal sections—headings such as "See also", "References", "Further reading", and "External links", using a \texttt{wikitext} parser. From this cleaned text we record article\_length in UTF-8 bytes (and optionally raw characters). We compute compression-based measures by compressing the text with \texttt{zlib} (level 9) and compute Redundancy as $1 - (article\_comp\_length / article\_length)$. For relevance, we sum daily user pageviews over a defined window (e.g., 30 or 60 days) via the REST endpoint \texttt{all-access}, using canonical titles resolved during enrichment.

\emph{Step 5.- Derived metrics and interestingness.} From these primary measurements we define Relevance as total pageviews and Maturity from compression. We then normalize the dataset: NormMaturity using min-max scaling, and NormRelevance using min-max scaling on log(x+1) to reduce heavy-tail effects. A composite indicators is then computed: Interestingness (Problem) = NormRelevance x NormRedundancy, identifying topics that are popular yet textually redundant (potentially under-explained and research-worthy).

\emph{Step 6.- Outputs}. For reproducibility and visualization, we export canonical tables: categories (\texttt{cat\_id}, \texttt{title}), category\_edges (\texttt{parent\_cat\_id}, \texttt{child\_cat\_id}) capturing the category DAG, page\_categories (\texttt{page\_id}, \texttt{cat\_id}) for direct memberships, and pages\_with\_metrics containing per-page metrics and labels. We also produce a hierarchical JSON projection of the category graph by identifying root categories (those without incoming edges), recursively nesting subcategories, and inserting page nodes beneath each category they belong to. Because categories may have multiple parents, a category can legitimately appear in multiple locations within this JSON structure, a deliberate duplication preserving the DAG while supporting tree-like visualizations.

To ensure stability, all enrichment requests are batched (< 50 IDs per call). We log pagination tokens, HTTP errors, and retry decisions for auditing. Concurrency is avoided to respect Wikimedia's usage guidelines and to maintain deterministic runs. As pageviews depend on both the chosen window and the execution date, we record the UTC end date of the REST query; since article content, assessments, and backlinks change over time, we also store lastrevid and timestamps. The pipeline gracefully degrades for optional services: if WDQS is unavailable or rate-limited, processing continues with missing labels or deny checks defaulting to "keep," and gaps noted in the logs. The software stack uses Python with \texttt{requests}, \texttt{pandas}, \texttt{mwparserfromhell}, and optionally \texttt{pyarrow} for Parquet output.

\subsection*{The Known and the Unknown}

The crawl covered the scientific content of the English Wikipedia, starting from the four principal branches of knowledge—Applied sciences, Formal sciences, Natural sciences, and Social sciences—and expanding through their subcategories to a maximum depth of five levels. In total, 38,074 categories were explored, of which approximately 18,000 did not contain articles of sufficient quality to be included in the analysis. The resulting dataset comprises 18,149 high-quality scientific topics, distributed across the major branches as follows: 10,785 articles in the Applied sciences, 2,776 in the Formal sciences, 9,826 in the Natural sciences, and 11,794 in the Social sciences. Each article was classified according to Wikipedia’s internal quality assessment scale, which ranks entries based on their completeness, accuracy, and sourcing. \emph{C-class} articles are moderately developed, providing substantial information but often lacking depth or comprehensive references. \emph{B-class} articles are more complete, with reasonably good structure, accuracy, and coverage of the topic, though they may still require some polishing or additional citations. \emph{A-class} articles are near-publication quality, representing a high standard of completeness and reliability, just below the \emph{Good Article} and \emph{Featured Article} levels. Within this classification, the crawl collected 11,894 C-class, 4,928 B-class, 882 Good Articles (GA), 429 Featured Articles (FA), and 16 A-class entries. Given that Wikipedia functions as the largest collaborative encyclopedia ever created, this corpus constitutes one of the most comprehensive and accurate descriptive representations of current human knowledge, offering a unique empirical foundation for analyzing the state of science and its frontiers.

In Figure \ref{figure:maturity_all_topics} it is shown an histogram of the maturity of the known topics, computed as the ratio of the size of the text of the Wikipedia article and its compressed version. The histogram reveals that the maturity of Wikipedia’s scientific topics follows an approximately normal distribution centered around 0.4, indicating that most articles exhibit a balanced level of informational density. This suggests that, on average, about 40\% of each article’s content represents essential, non-redundant information, while the rest reflects natural linguistic and structural redundancy typical of encyclopedic writing.

\begin{figure}[ht]
\centering
\includegraphics[width=0.6\textwidth]{Maturity_all_topics.png}
\caption{Maturity of scientific topics.}
\label{figure:maturity_all_topics}
\end{figure}

In Figure \ref{figure:relevance_all_topics} it is shown an histogram of the logarithm of the relevance of a topic, as the total number of visits to the Wikipedia page over the last two months. The histogram shows that the logarithm of topic relevance, measured by the total number of visits to each Wikipedia page over the last two months, follows a roughly log-normal distribution centered around a log relevance of about 8–9. This implies that most scientific topics receive between $10^8$ and $10^9$ visits, while only a few attract extremely high or low levels of attention. The right-skewed shape indicates the presence of a small number of highly popular topics that dominate user interest, reflecting the uneven distribution of public attention across scientific fields. Overall, the data suggest that while most topics maintain a moderate and steady level of visibility, a minority of them capture a disproportionately large share of the audience, highlighting the concentration of public interest in a limited set of scientific areas.

\begin{figure}[t]
\centering
\includegraphics[width=0.6\textwidth]{Relevance_all_topics.png}
\caption{Log-relevance of scientific topics.}
\label{figure:relevance_all_topics}
\end{figure}

Compuation of the new research topics, as the creative combinantion of already existing topics, has been performed automatically using a large language model. The OpenAI API provides programmatic access to a family of advanced lager language models developed by OpenAI, allowing developers and researchers to integrate natural language understanding, reasoning, and generation capabilities into their own applications. Among these models, \emph{GPT-5-nano} represents a lightweight yet remarkably capable variant of the GPT-5 architecture—optimized for efficiency, speed, and cost while retaining much of the creativity and fluency of larger models. Despite its compact size, GPT-5-nano demonstrates an impressive ability to generate coherent, context-aware, and often original ideas across diverse domains. Its design enables it not only to respond accurately to prompts but also to combine existing concepts in novel ways, making it a powerful tool for creative exploration, brainstorming, and the discovery of new research directions or innovative solutions. The following is the prompt used to generate a new research topic:

\bigskip

"You are an innovative scientist exploring unexplored frontiers of knowledge. Your task is to conceive a new and original research topic that emerges from the creative synthesis or inspiration of the two given scientific concepts. The proposed topic must:

\begin{itemize}
\item Represent a novel idea that, to your knowledge, has never been formally studied or proposed before.

\item Have the potential, if successfully developed and applied, to produce a major positive impact on humanity by advancing science, technology, or understanding.

\item Be scientifically plausible—grounded in real principles, not fantasy or pseudoscience.

\item Be expressed in a single, concise paragraph written in formal academic language, rich in scientific and technical terminology, and free of filler or speculation markers (avoid “perhaps”, “maybe”, etc.).

\item Avoid generic formulations like 'a study of the relationship between…' and instead describe a specific, well-defined new direction.
\end{itemize}

Respond directly with the proposed research topic, nothing else."

\bigskip

The exploration of the unknown unknown encompassed an unprecedented combinatorial space of potential scientific discoveries. In total, 164 million new research topics were generated and evaluated, each representing a possible novel research area. Within single disciplines, or intradisciplinary combinations, the analysis produced approximately 12 million new topics in the Applied sciences, 8 million in the Formal sciences, 96 million in the Natural sciences, and 139 million in the Social sciences. When considering interdisciplinary combinations—those that bridge distinct domains—the numbers were even higher, with 132 million in the Applied sciences, 45 million in the Formal sciences, 125 million in the Natural sciences, and 138 million in the Social sciences. Although these figures are immense, they reflect not ambition for its own sake, but the scale of the challenge involved in systematically exploring what remains beyond our current understanding. This constitutes, to date, one of the most extensive and systematic attempts to identify and describe the unknown unknown in science—an experiment that seeks not to claim discovery, but to illuminate the vast and still largely uncharted territory of human ignorance.

\subsubsection*{Uknown Unknowns App}

The Uknown Unknowns application (see Figure \ref{figure:UUP}) serves as an exploratory instrument for discovering what it is hidden in the scientific unknown. It transforms our current vast scientific corpus into an interactive landscape where both what is known and what remains undiscovered can be visually explored. At its core lies the idea that new knowledge emerges not in isolation, but from the interplay of existing concepts. By combining less mature, not yet well understood topics with automatically generated hypotheses about potential new ones, the application becomes a map of the scientific frontier, a cartographic representation of the boundary between understanding and ignorance.

\begin{figure}[t]
\centering
\includegraphics[width=1\textwidth]{UUP.png}
\caption{Uknown Uknowns App.}
\label{figure:UUP}
\end{figure}

When launched, the program constructs an internal graph that mirrors the structure of scientific knowledge. Categories and subcategories form a tree that organizes the disciplines, while individual articles represent specific research topics. Each page is associated with several indicators: maturity, which measures how developed or well-established a topic is; relevance, which reflects its significance and social impact; and interestingness, which captures its potential to raise new questions. A complementary dataset describes the “unknown topics”—novel research ideas automatically inferred from pairs of existing ones. These unknown topics, described textually and assigned a preliminary maturity level, represent possible directions in which human knowledge could expand.

The interface is divided into two complementary regions. On the left, a circular diagram depicts the maturity of topics as a constellation of points over a concentric gradient. The center of the diagram glows brightly, symbolizing the domains of science that are most mature and consolidated. The darker outer regions represent areas of uncertainty and opportunity (the uknown unknowns), where new ideas are still forming. Known topics appear as filled black dots, positioned according to their maturity: the more developed the topic, the closer it lies to the center. Unknown topics appear as empty circles, marking the places where new combinations of knowledge could give rise to discoveries. Their distribution reveals the topology of ignorance, an intricate periphery of potential that surrounds and extends the boundaries of current science. Hovering over any unknwon displays the research opportunity in a multi-line tooltip, while the lower status bar shows its numerical maturity.

The right side of the window offers the tools to navigate this landscape. A search bar allows the user to locate specific scientific categories by name, while the hierarchical tree below displays the organization of disciplines and subdisciplines. Expanding a branch of the tree simply reveals its subareas, but selecting a category triggers a full update of the diagram and the topics table. In this mode, the application displays all the known topics that belong to the chosen category and its descendants, together with the unknown topics that emerge from them. The unknown topics are filtered so that only those whose maturity exceeds a minimum threshold are shown, ensuring that the visualization remains focused on meaningful possibilities rather than random combinations.

Beneath the tree, the topics table lists all the pages that directly belong to the selected category. Each entry includes its maturity, relevance, and interestingness. Clicking on a row switches the visualization into topic mode, in which the diagram focuses on that particular topic and displays all the unknown topics that are conceptually derived from it. This view allows the user to see how a not very well-understood idea can serve as a seed for new research directions, how from a single concept, many potential discoveries can emerge. Double-clicking a topic opens its Wikipedia page in a browser, connecting the abstract representation back to the underlying content.

The scale at the bottom of the interface controls the threshold of relevance and maturity used to filter the visualization. It allows the user to move smoothly from a wide, inclusive view of the scientific landscape to a more focused view that highlights only those topics that are socially impactful. By raising the threshold, the user filters out marginal or less relevant areas, concentrating instead on the regions of knowledge that have the greatest influence on human life and technological progress. In this way, the application not only reveals the unknown unknowns but also helps prioritize which of them might lead to discoveries of real significance.

Every design element in the application serves the same epistemological goal: to make the frontier of human knowledge visible. The bright center of the diagram stands for what science already understands, while the dark periphery shows where ignorance still dominates. The empty circles of the unknown topics are markers of potential discovery, each one a hypothetical domain of future research, a conceptual territory awaiting exploration. The relevance filter allows the user to discern which of these emerging ideas connect most strongly to society’s needs and interests. The result is not merely a visualization of data, but a dynamic, exploratory tool that guides the intellect toward the edges of what is currently thinkable.

In this sense, the application is both cartographic and philosophical. It functions as a visual compass for discovery, helping the observer navigate between the solid continents of established knowledge and the open ocean of possibility. By grounding the abstract notion of the “unknown unknown” in concrete, measurable data, it transforms ignorance into something that can be mapped, explored, and eventually reduced. In doing so, it exemplifies the central idea of the theory of nescience: that by quantifying what we do not yet know, we can systematically move beyond the limits of present understanding.

\section*{References}

Core references for the chapter "Interesting Research Questions"

\cite{popper2014conjectures}: Popper's account of conjectures, refutations, and the growth of knowledge provides the philosophical foundation for thinking about unanswered questions and how science progresses through them.

\cite{chalmers2013thing}: Chalmers offers a clear overview of debates about what constitutes science. This is essential background for addressing the demarcation problem in identifying valid research questions.

\cite{li2004similarity}: Introduces the normalized compression distance (NCD), which provides a universal method for comparing objects. This is a key methodological tool for estimating redundancy and discovering connections between topics.

\cite{cebrian2005common}: Warns about practical limitations of using real compressors to approximate Kolmogorov complexity. Essential for a sound application of compression-based metrics in identifying research frontiers.

\cite{li2013introduction}: The standard reference on Kolmogorov complexity. It connects theoretical information content with practical methods like NCD, underpinning the discovery of redundancy, miscoding, and research gaps.

\cite{suppes2002representation}: Suppes discusses how scientific theories can be formally represented. This supports the extension from individual topics to structured research areas and the search for interdisciplinary questions.

\cite{latour2013laboratory}: Latour highlights how scientific knowledge emerges from negotiation and practice. This adds a sociological perspective to the identification of research questions and debates.

\cite{ioannidis2005most}: Ioannidis shows that much of published research is flawed or irreproducible. This underscores the importance of using independent measures (like nescience) to identify which questions are still genuinely open.


