%
% CHAPTER 8.- Properties of Nescience
%

\chapterimage{Philosophers.pdf}

\chapter{Advanced Properties}
\label{chap:Properties-Nescience}

\begin{quote}
\begin{flushright}
\emph{Invert, always invert.}\\
Carl Gustav Jacob Jacobi\\
\end{flushright}
\end{quote}
\bigskip

This chapter covers more advanced mathematical properties of the concept of nescience. This chapter can be safely skipped by those readers interested only in the applications of nescience. However, it is highly recommended to read it, since if provides a deeper understanding of what nescience is exactly.

Since the time of David Hilbert, mathematics is about the study of the properties of abstract objects and their relations, without paying too much attention to what these objects are or represent. Mathematicians create (or discover) abstract frameworks of logic that can have multiple interpretations. It is up to applied scientists to provide those interpretations. In the same way, we can provide an abstract definition of the concept of nescience, and study its properties, without making any explicit reference to science nor to the scientific method. In doing so, we loose the interpretability of our theory, but, on the other side, we could apply the same results to other disciplines.

{\color{red} Extend this introduction with a very short review of the topics covered in the chapter.}

%
% Section: Axioms
%

\section{The Axioms of Science}

{\color{red} TODO: Review}

In this section we propose a collection of axioms that formalize the concept of science and the scientific method. Our axioms are based on first-order logic and the ZFC axioms of set theory (see Appendix \ref{apx:foundations_mathematics}). We also prove some basic results and show how the axioms relate to the concepts we have introduced in the previous chapters. In Appendix \ref{apx:coq} the reader can find the axioms and proofs implemented in the \texttt{Coq} proof assistant language.

Let $\Sigma = \{ \sigma_1, \sigma_2, \ldots, \sigma_n \}$ be a finite non-empty alphabet, and let $\Sigma^\ast$ denote the set composed by all possible finite strings made up of symbols from $\Sigma$. A \emph{science} is a first-order logic structure $(\Sigma^\ast \mid \lambda, \mathcal{O}, <_n, \oplus, \mid, U)$ where:

\vskip 0.25cm

\begin{enumerate}[label=(\roman*)]
\item $\lambda \in \Sigma^\ast$ is the empty string.
\item $\mathcal{O}$ is a relation called \emph{oracle},
\item $<_n$ is a relation called \emph{nescience},
\item $\oplus$ is a binary function called \emph{joint},
\item $\mid$ is a binary function called \emph{conditional}, and
\item $\mathcal{U}$ is a unary function called \emph{machine}
\end{enumerate}

\vskip 0.25cm

The oracle $\mathcal{O}$ is an equivalence relation:

\vskip 0.25cm

\begin{description}
\item[Axiom 1] $\forall t \in \Sigma^\ast \; t \mathcal{O} t$.
\item[Axiom 2] $\forall s , t \in \Sigma^\ast$ if $s \mathcal{O} t$ then $t \mathcal{O} s$.
\item[Axiom 3] $\forall r, s , t \in \Sigma^\ast$ if $r \mathcal{O} s$ and $s \mathcal{O} t$ then $r \mathcal{O} t$.
\end{description}

\vskip 0.25 cm

The oracle equivalence relation $\mathcal{O}$ partitions the set of strings $\Sigma^\ast$ into the quotient set $\Sigma^\ast / \mathcal{O}$. Intuitively, each equivalence class refers to an entity, and it contains all possible representations (strings) that encode that entity. Entities are not part of the axioms of the theory of nescience, and the encoding schema is in general unknown. The abstract oracle is the only tool we have at our disposal to connect entities and their representations.

The nescience relation $<_N$ is a strict partial order:

\vskip 0.25cm

\begin{description}
\item[Axiom 4] $\forall t \in \Sigma^\ast$ we have that $\lnot t <_N t$.
\item[Axiom 5] $\forall s , t \in \Sigma^\ast$ if $s <_N t$ then $\lnot t <_N s$.
\item[Axiom 6] $\forall r , s, t \in \Sigma^\ast$ if $r <_N s$ and $s <_N t$ then $r <_N t$.
\end{description}

\vskip 0.25cm

We denote by $ s =_N t$ when $\lnot s <_N t$ and $\lnot t <_N s$. Intuitively, the symbol $=_N$ represents the case that our unknown given the representations $s$ and $t$, which may belong to the same equivalence class or to different equivalence classes, is the same. 

Every equivalence class defined by $\mathcal{O}$ has a minimal element with respect to the relation $<_N$:

\vskip 0.25cm

\begin{description}
\item[Axiom 7] for all $[x] \in \mathcal{O} / <_N$ there exists $r \in [x]$ such that it does not exists an $s \in [x]$ such that $s <_N r$.
\end{description}

\vskip 0.25cm

A class could have more than one minimal element with respect to the nescience ordering. The nescience relation does not define a global minimum element for $\Sigma^\ast$, nor minimum elements for the individual equivalence classes. Given an entity, in general it does not exists a single optimal description, instead what we have is a collection of optimal descriptions.

The concatenation function $\oplus : \Sigma^\ast \times \Sigma^\ast \rightarrow \Sigma^\ast$ is a binary function that satisfy the following properties:

\vskip 0.25cm

\begin{description}
\item[Axiom 8] $\forall s, t \in \Sigma^\ast$ we have that $\oplus(s, t) \in \Sigma$.
\item[Axiom 9] $\forall s \in \Sigma^\ast$ we have that $\oplus(s, \lambda) = \oplus( \lambda, s) = s$.
\item[Axiom 10] $\forall r, s, t \in \Sigma^\ast$ we have that $\oplus(\oplus(r, s), t) = \oplus(r, \oplus(s, t))$.
\end{description}

\vskip 0.25cm

$\Sigma^\ast$ with the concatenation operation $\oplus$ forms a free monoid. Since this point we will use the infix notation of the concatenation function, that is, we will write $s \oplus t$ instead of the $\oplus(s, t)$.

Next axiom states how the operation of concatenation is related to nescience (recall that $\Sigma^{+}$ denotes $\Sigma^\ast-\{\lambda\}$ and $[x] \in \mathcal{O} / <_N$ denotes a equivalence class):

\vskip 0.25cm

\begin{description}
\item[Axiom 11] Let $r \in \Sigma^{+}$ a minimal element of class $[x]$, then we have that $r <_N r \oplus s$ for all $s \in [x]$.
\end{description}

\vskip 0.25cm

Axiom 11 captures the concept of miscoding, since adding more symbols to an optimal representation only increases the nescience. Unfortunately, we cannot say anything about adding more symbols to a non-optimal representation, since the nescience could increase or decrease. The same happens when we concatenate strings that belong to different classes. 

The machine $\mathcal{U} : \Sigma^\ast \rightarrow \Sigma^\ast$ is an universal Turing machine, that given a string $s \in \Sigma^\ast$ encoding a Turing machine, simulates its behaviour. Of course, the function $\mathcal{U}$ is partial, since not all the strings of $\Sigma^\ast$ encode valid Turing machines. We have to select a particular universal Turing machine and encode its description using first-order logic. As we have seen, selecting a different universal machine would result in encoded machines with different length, and that could alter the actual values of nescience. However, since in this axiomatization we are only interested in the ordering o of strings according to their nescience, the particular machine selected is not relevant, since that ordering is not altered. We will use the shortest possible universal machine, composed by two states and three tape symbols:

\vskip 0.25cm

\begin{description}
\item[Axiom 12] The machine $\mathcal{U} : \Sigma^\ast \times \Sigma^\ast \rightarrow \Sigma^\ast$ satisfy the following properties ...
\end{description}

\vskip 0.25cm

The relation between the machine $\mathcal{U}$ and the oracle $\mathcal{O}$ is given by the following axiom:

\vskip 0.25cm

\begin{description}
\item[Axiom 13] For all $r \in \Sigma^\ast$ such that $\mathcal{U}(r) \uparrow$ we have that $r \mathcal{O} U(r)$.
\end{description}

\vskip 0.25cm

That is, descriptions are also representations.

\vskip 0.25cm

The relation between the machine $\mathcal{U}$ and the concatenation of strings is given by the following axiom:

\vskip 0.25cm

\begin{description}
\item[Axiom 14] For all $r, s \in \Sigma^\ast$ such that $U(r) \uparrow$ and $U(s) \uparrow$ we have that $U(r \oplus s) = U(r) \oplus U(s)$.
\end{description}

\vskip 0.25cm

That is, we require that descriptions have to be self-delimited, for example, by being prefix-free.

The conditional function $\mid : \Sigma^\ast \times \Sigma^\ast \rightarrow \Sigma^\ast$ is a binary function that satisfy the following properties:

\vskip 0.25cm

\begin{description}
\item[Axiom 15] $\forall s, t \in \Sigma^\ast$ we have that $\mid(s, t) \in \Sigma^\ast$.
\item[Axiom 16] $\forall s \in \Sigma^\ast$ we have that $\mid (s, \lambda) = \mid( \lambda, s) = s$.
\item[Axiom 17] $\forall r, s, t \in \Sigma^\ast$ we have that $\mid (\mid (r, s), t) = \mid (r, \mid (s, t))$.
\end{description}

Since this point we will use the infix notation of the conditional function, that is, we will write $s \mid t$ instead of the $\mid (s, t)$.

The relation between the machine $\mathcal{U}$ and conditional $\mid$ is given by the following axiom:

\vskip 0.25cm

\begin{description}
\item[Axiom 18] For all $r \in \Sigma^\ast$ such that $U(r) \uparrow$ we have that $U(r \mid s) = U(r)$.
\end{description}

\vskip 0.25cm

The relation between the machine $\mathcal{U}$ and the nescience is given by the following axiom:

\begin{description}
\item[Axiom 19] For all $s \in \Sigma^\ast$ such that $U(s) \uparrow$ and $U(s) = t$ we have that $\lnot U(s) =_N t$.
\end{description}

\vskip 0.25cm

The relation of the nescience ordering and the conditional function is given through the application of the machine:

\begin{description}
\item[Axiom 20] Let $s \in \Sigma^\ast$ such that $U(s) \uparrow$, then we have that $U(s \mid t) <_N U(s)$ for all $t \in \Sigma^\ast-\{\lambda\}$.
\end{description}

{\color{red} TODO: Pending, axiom of distributive law}

\begin{proposition}
Let $d \in \mathcal{D}$ be a description such that $N(d)=0$, then $\mathcal{O}(d)=0$.
\end{proposition}
\begin{proof}
Apply the axiom of perfect knowledge.
\end{proof}

We have assumed as axioms the behavior of the nescience function in case of having two related descriptions with the same length and one of them with a smaller inaccuracy than the other ($l(s) = l(t)$ and $\mathcal{O} (s) \leq \mathcal{O} (t)$), the case of two descriptions with the same inaccuracy and one of them shorter than the other ($l(s) \leq l(t)$ and $\mathcal{O} (s) = \mathcal{O} (t)$), and the case of equality ($l(s) = l(t)$ and $\mathcal{O} (s) = \mathcal{O} (t)$). In the next proposition we will consider the rest of the provable cases.

\begin{proposition}
\label{prop:properties_nescience}
Let $s, t \in \mathcal{D}$ such that $s \mathcal{R} t$, then we have that
\begin{enumerate}[label=(\alph*)]
\item if $l(s) < l(t)$ and $\mathcal{O}(s) < \mathcal{O}(t)$ then $N(s) < N(t)$,
\item if $l(s) < l(t)$ and $\mathcal{O}(s) = \mathcal{O}(t)$ then $N(s) < N(t)$,
\item if $l(s) = l(t)$ and $\mathcal{O}(s) < \mathcal{O}(t)$ then $N(s) < N(t)$,
\item if $l(s) = l(t)$ and $\mathcal{O}(s) > \mathcal{O}(t)$ then $N(s) > N(t)$,
\item if $l(s) > l(t)$ and $\mathcal{O}(s) = \mathcal{O}(t)$ then $N(s) > N(t)$, and
\item if $l(s) > l(t)$ and $\mathcal{O}(s) > \mathcal{O}(t)$ then $N(s) < N(t)$.
\end{enumerate}
\end{proposition}
\begin{proof}

Recall that if $a \le b$ we have that $a < b$ or $a = b$, and that $a < b$ implies $b > a$. 

\begin{enumerate}[label=(\alph*)]

\item Apply the axiom of surfeit.

\item Apply the axiom of surfeit.

\item Apply the axiom of inaccuracy. 

\item Interchange $s$ and $t$ and apply (c).

\item Interchange $s$ and $t$ and apply (b).

\item Interchange $s$ and $t$ and apply (a).

\end{enumerate}

\end{proof}

Unfortunately there is not too much we can say from the axioms about the nescience of two related descriptions $s$ and $t$ in case that $l(s) < l(t)$ and $\mathcal{O} (s) > \mathcal{O} (t)$, and in case that $l(s) > l(t)$ and $\mathcal{O} (s) < \mathcal{O} (t)$. 

Next definition formally introduces the concept of scientific methodology in the context of the theory of nescience.

\begin{definition}
A \emph{scientific methodology} is an effective procedure that produces a sequence of $t_1, t_2, \ldots, t_n, \ldots$ where $t_i \in \mathcal{D}$ such that $N(t_i) < N(t_{i+1})$.
\end{definition}

Note that we do not require that in a scientific methodology the collection of $t_i$ refer to the same entity.

% Properties of the Oracle

\subsection{Properties of the Oracle}

{\color{red} TODO: equivalence classes, quotation set, projection function, ...}

Let $S$ be the set of topics in which we are interested, and assume by the moment that $S$ is finite with $k$ elements. The oracle partitions the set $\Sigma_\star$ into $k$ sets such that:
\[
\argmin_S \sum_{i=1}^k \sum_{x \in S_i} NID(x, \mu_i)
\]
where $\mu_i$ is the average topic of class $S_i$.

{\color{red} TODO: explain what $\mu_i$ is, and how to generalize this concept to the case of having infinite topics.}

% Properties of Inaccuracy

\subsection{Properties of Inaccuracy}

{\color{red} TODO: Explain the consequences of requiring to be well-founded.}

%
% Section: Scientific Method
%

\section{Scientific Method}

{\color{red} Describe our proposal of scientific method. Short story: based on a exploration/exploitation approach, where the exploration is based in the concept of joint descriptions, and the exploitation in the concept of conditional description.}

{\color{red} Compare against another proposals of scientific method (inductive-deductive, hypothetico-deductive, etc) and with other techniques for knowledge discovery and creativity (triz, etc.)}

\subsection{Science as a Language}

{\color{red} TODO: Provide an alternative definition of the set of descriptions, and prove that it is equivalent to our definition based on the description function}

Since we require computable descriptions, we would like to know if the set of all possible descriptions of a topic is computable as well.

\begin{proposition}
Study if $D_{t}$ is Turing-decidable, Turing-recognizable or none.
\end{proposition}
\begin{proof}
{\color{red} TODO}
\end{proof}

Although we know that it is not computable, we are interested in the set composed by the shortest possible description of each topic.

\begin{definition}
We define the set of \emph{perfect descriptions}, denoted by $\mathcal{D}^\star$, as:
\[
\mathcal{D}^\star = \{ d_t^\star : t \in \mathcal{T} \}
\]
\end{definition}

Since the set $\mathcal{D}$ includes all the possible descriptions of all the possible (describable) topics, we can see this set as a kind of language for science. We do not call it universal language since it depends on the initial set of entities $\mathcal{E}$ and the particular encoding used for these entities.

\begin{proposition}
The set $\mathcal{D}$ is not Turing-decidable.
\end{proposition}
\begin{proof}
{\color{red} TODO: Because it depends on the set $\mathcal{T}$ that it could be not computable}
\end{proof}

Say something here

\begin{proposition}
The set $\mathcal{D}$ is Turing-recognizable.
\end{proposition}
\begin{proof}
{\color{red} TODO: The same argument as the previous proposition}
\end{proof}

A universal language is determined by a universal Turing machine. Given Two different universal Turing machines $\delta_{a}$ and $\delta_{b}$ defines two different universal languages $\mathcal{L}_{a}$ and $\mathcal{L}_{b}$. Let $\mathcal{L}_{a=b}=\left\{ \left\langle d_{a},d_{b}\right\rangle \,,\,d_{a},d_{b}\in\mathcal{D}\mid\delta_{a}\left(d_{a}\right)=\delta_{b}\left(d_{b}\right)\right\}$.

\begin{proposition}
Study if $\mathcal{L}_{a=b}$ is Turing-decidable, Turing-recognizable or none.
\end{proposition}
\begin{proof}
{\color{red} TODO}
\end{proof}

Let $\mathcal{L}_{\nexists t}$ the laguage of valid descriptions (from a formal point of view) that do not describe any topic, that is, $\mathcal{L}_{\nexists t}=\left\{ d\in\mathcal{D}\mid\nexists t\in\mathcal{T}\,,\,\delta\left(d\right)=t\right\}$.

\begin{proposition}
Study if $\mathcal{L}_{\nexists t}$ is Turing-decidable, Turing-recognizable or none.
\end{proposition}

Let $\mathcal{L}_{\nexists d}$ the laguage topics that are not described by any description, that is, $\mathcal{L}_{\nexists d}=\left\{ t\in\mathcal{T}\mid\nexists d\in\mathcal{D}\,,\,\delta\left(d\right)=t\right\}$.

\begin{proposition}
Study if $\mathcal{L}_{\nexists d}$ is Turing-decidable, Turing-recognizable or none.
\end{proposition}

{\color{red} TODO: Extend the concept of conditional description to multiple topics.}

{\color{red} TODO: Introduce the concept of "independent topics" based on the complexity of the conditional description. Study its properties.}

{\color{red} TODO: Define a topology in $\mathcal{T}$ and $\mathcal{D}$. Study the continuity of $\delta$. Study the invariants under $\delta$.}


%
% Section: The Inaccuracy - Surfeit Trade-off
%

\section{The Inaccuracy - Surfeit Trade-off}

{\color{red} TODO: Explain that given a miscoding, there is a trade-off between inaccuracy and surfeit, in the sense that there exists an optimal point beyond it the more we decrease the inaccuracy, the more we increase the surfeit, and so, the nescience keep constant. Explain how this trade-off imposes a limit to knowledge.}

%
% Section: Science vs. Pseudoscience
%

\section{Science vs. Pseudoscience}

{\color{red} TODO: Provide a characterization of the difference between science and pseudoscience. In science, nescience decreases with time, in pseudoscience not.}

%
% Section: Graspness
%
\section{Graspness}

There are some topics whose nescience decrease with time much faster than others, even if the amount of research effort involved is similar. A possible explaination to this fact is that there are some topics that are inherently more difficult to understand.

We define the \emph{graspness} of a topic as the entropy of the set of possible descriptions of that topic. A high graspness means a difficult to understand topic. Intuitively, a research topic is difficult if it has no descriptions much shorter than the others, that is, descriptions that significantly decrease the nescience. For example, in physics there have been a sucession of theories that produced huge advances in our understanding of how nature works (Aristotelian physics, Newton physics, Einstein physics), meanwhile in case of philosophy of science, new theories (deductivism, inductivism, empirism, falsation, ...) have a similar nescience than previous ones.

\begin{definition}[Graspness]
Let $D_t$ the set of descriptions of a topic $t \in T$. The \emph{graspness} of topic $t$, denoted by $G(t)$, is defined by:
\[
G(t) = \sum_{d \in D_t} 2^{-l(d)} l(d)
\]
\end{definition}

Grapsness is a postive quantity, whose maximum is reached when all the descriptions of the topic have the same length:

\begin{proposition}
Let $D_t = \{ d_1, d_2, \ldots, d_q \}$ the set of descriptions of a topic $t \in T$, then we have that $G(t) \leq \log q$, and $G(t) = \log q$ if, and only if, $l(d_1) = l(d_2) = \ldots = l(d_q)$.
\end{proposition}
\begin{proof}
Replace $P(s_i)$ by $2^{-l(d_i)}$ in Proposition \ref{prop:maximum_entropy}.
\end{proof}

If $G(t) = \log q$ then we have that $N_t = 0$ for all $\hat{d}_t$. In that case, it does not make any sense to do research, since no knew knowledge can be adquired. This is the case of pseudosciences, like astrology, where the nescience of descriptions does not decrease with time. If fact, graspness can be used as a distintive element of what constitutes \emph{science} and what does not.

\begin{definition}
A topic $t \in T$ is \emph{scientable} if $G(t) < \log d(D_t) - \epsilon$, where $\epsilon \in \mathbb{R}$ is a constant.
\end{definition}

We can extend the concept of graspness from topics to areas, for example, by means of computing the average graspness of all the topics included in the area.

\begin{definition}
Let $A \subset T$ a research area. The \emph{graspness} of area $A$, denoted by $G(A)$, is defined by:
\[
G(A) = \frac{1}{d(A)} \sum_{t \in A} G(t)
\]
\end{definition}

%
% Section: Effort
%
\section{Effort}

{\color{red} TODO: Provide a characterization of the effort, measured in terms of number of operations, or time, to reduce the nescience. Based in the concept of computational complexity. Provide a physical interpretation in terms of information.}

%
% Section: Human Understanding
%
\section{Human Understanding}

In his landmark paper \emph{"On Computable Numbers with an Application to the Entscheidungsproblem"}, where the concept of computable function was proposed for the first time, when the author Alan M. Turing talked about computers, he was thinking about human computers, not machines. In this sense, according to Turing, everything that is computable, can be computed by a human, at least in theory.

The fist limitation is about computation time. We expect that a human is able to find a solution to a particular instance of a problem in order of seconds, maybe minutes or hours, but definitely, in less than a life time, otherwise another human have to start again from scratch to solve the problem. So, given the average computing speed of a human brain, we identify as human solvable problems only those problems with a complexity smaller than a fixed number of steps.

The second limitation is about program size. It might happen that the algorithms to solve a problem is simply too big to fit in our brains. Of course, we could argue that {\color{red} as we saw in Example XX, only X states and Y tape symbols} are sufficient to implement a universal Turing machine capable of solving any computable problem, that is, any problem for which exist a Turing machine that can solve it. However, by just following a set of instruction we do not mean that we understand a problem. We understand a problem when we have made the problem for ourselves, in the sense, that the problem is somehow stored in our brain in our own language. So this limits the problem to those whose length, including the necessary background, can be stored in our brain.

We are looking for solutions that minimize at the same time the computational complexity and the Kolmogorov complexity.

\begin{definition}
We say that a problem $P$ is \emph{human solvable} if there exist an algorithm $TM$ to solve $P$ such that $t(n)$ and $K(P) < l$.
\end{definition}

Given the above definition, we could argue that most of the problems we know are not human solvable, but in fact, they have been solved by human. We use two strategies to deal with too complex problems for our individual brains. The fist strategy is that those time-comsuming mechanical parts of the problems are left for computers, so we can reduce the computing time. The second one is that we split the problems into subproblems and each of use specializes in those subproblems.

In this section we are interested in to study the nature of these problems in which this strategy cannot be applied, and so, they are out of reach of individual, nor groups of, humans.

%
% Section: Areas in Decay
%

\section{Areas in Decay}

{\color{red} Provide a model of the decay in the interest of research areas. For example, a good explanatory variable could be the number of interesting questions: the less interesting questions, the more the area is near to its end as a interesting research area, of course, as long as its topics are not used as tools.}

%
% Section: References
%

\section*{References}

{\color{red} Mention the polemic between Hilbert and Fredge given a reference to the book of Mosterin.}


