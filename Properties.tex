%
% CHAPTER 8.- Properties of Nescience
%

\chapterimage{Philosophers.pdf}

\chapter{Advanced Properties}
\label{chap:Properties-Nescience}

\begin{quote}
\begin{flushright}
\emph{Invert, always invert.}\\
Carl Gustav Jacob Jacobi\\
\end{flushright}
\end{quote}
\bigskip

This chapter covers more advanced mathematical properties of the concept of nescience. This chapter can be safely skipped by those readers interested only in the applications of nescience. However, it is highly recommended to read it, since if provides a deeper understanding of what nescience is exactly.

{\color{red} TODO: Explain the abstract nature of the axioms vs. the interpretation we have provided in the previous chapters. Mention that perhaps there exists other interpretations.}

Since the time of David Hilbert, mathematics is about the study of the properties of abstract objects and their relations, without paying too much attention to what these objects are or represent. Mathematicians create (or discover) abstract frameworks of logic that can have multiple interpretations. It is up to applied scientists to provide those interpretations. In the same way, we can provide an abstract definition of the concept of nescience, and study its properties, without making any explicit reference to science nor to the scientific method. In doing so, we loose the interpretability of our theory, but, on the other side, we could apply the same results to other disciplines.

{\color{red} Extend this introduction with a very short review of the topics covered in the chapter.}

%
% Section: Axioms
%

\section{The Axioms of Science}

In this section we are going to propose a collection of axioms that formalize what is science. Our axioms are based on first-order logic and the ZFC axioms of set theory with equality (see Appendix \ref{apx:foundations_mathematics}). We will also prove some basic results and explain how these axioms match the new ideas we have introduced in this book. In our axiomatization we are not going to follow the approach described in the previous chapters, that is, we are not going to explicitly definine the quantities of miscoding, surfeit and inaccuracy. Instead, we will introduce the junction and conditional operations, list their fundamental properties, and explain how nescience is afected by them. The remaining concepts follow from these basic axioms.

\begin{definition}

Let $\mathcal{B}^\ast$ be the set of all finite binary strings. We define \emph{science} as the first-order logic structure $(\mathcal{B}^\ast \mid \lambda, \mathcal{O}, <_N, \oplus, \mid)$ where:

\vskip 0.25cm

\begin{enumerate}[label=(\roman*)]
\item $\lambda \in \Sigma$ is the empty string.
\item $\mathcal{O}$ is a relation called \emph{oracle},
\item $<_N$ is a relation called \emph{nescience},
\item $\oplus$ is a binary function called \emph{joint}, and
\item $\mid$ is a binary function called \emph{conditional}
\end{enumerate}

\vskip 0.25cm

that satisfies the following axioms:

\vskip 0.25cm

\begin{itemize}

% Oracle
\item[A1] $\forall t \in \mathcal{B}^\ast \; t \mathcal{O} t$.
\item[A2] $\forall s , t \in \mathcal{B}^\ast$ if $s \mathcal{O} t$ then $t \mathcal{O} s$.
\item[A3] $\forall r, s , t \in \mathcal{B}^\ast$ if $r \mathcal{O} s$ and $s \mathcal{O} t$ then $r \mathcal{O} t$.

\vskip 0.25cm

% Nescience
\item[A4] $\forall t \in \mathcal{B}^\ast$ $\lnot t <_N t$.
\item[A5] $\forall s , t \in \mathcal{B}^\ast$ if $s <_N t$ then $\lnot t <_N s$.
\item[A6] $\forall r , s, t \in \mathcal{B}^\ast$ if $r <_N s$ and $s <_N t$ then $r <_N t$.

\vskip 0.25cm

% Concatenation
\item[A8] $\forall s, t \in \mathcal{B}^\ast$ $\oplus(s, t) \in \mathcal{B}^\ast$.
\item[A9] $\forall s \in \mathcal{B}^\ast$ $\oplus(s, \lambda) = \oplus( \lambda, s) = s$.
\item[A10] $\forall r, s, t \in \mathcal{B}^\ast$ $\oplus(\oplus(r, s), t) = \oplus(r, \oplus(s, t))$.

\vskip 0.25cm

% Conditional
\item[A11] $\forall s \in \mathcal{B}^\ast$ $\mid (s, \lambda) = s$.
\item[A12] $\forall s, t \in \mathcal{B}^\ast$ $\lnot s <_N \mid (s, t)$

\end{itemize}

\end{definition}

Axioms A1, A2 and A3 state that the oracle $\mathcal{O}$ is an equivalence relation that partitions the set of strings into entities. The nescience relation $<_N$, described by Axioms A4, A5 and A6 is a strict partial order that compares the relative unknowns of pairs of strings. The concatenation operation $\oplus$ of Axioms A8, A9 and A10 contains the usual properties of the contatenation of strings, and together with $\mathcal{B}^\ast$ forms a free monoid. Axioms A11 and A12 define the behaviour of the conditional operator $\mid$. 

We still need two more axioms to fully characterize the behaviour of the nescience function. But fist we have to introduce some additional definitions and notations.

\begin{definition}
Let $\mathcal{B}^\ast / \mathcal{O}$ be the quotation set defined by the oracle relation over the set of strings. We call \emph{entity}, denoted by $[e]$, to every class of this quotation set, that is, $[e] \in \mathcal{B}^\ast / \mathcal{O}$.
\end{definition}

We require that every entity contains at least one minimal string with respect to the nescience ordering.

\begin{definition}[Axiom A13]
For every entity $[e] \in \mathcal{B}^\ast / \mathcal{O}$ there exists at least one $r \in [e]$ such that it is minimal with respect to $<_N$, that is, it does not exists an $s \in [e]$ such that $s <_N r$.
\end{definition}

An entity can have more than one minimal element. The axioms do not require the nescience relation to have a global minimum element for $\mathcal{B}^\ast$, nor minimum elements for the individual equivalence classes.

The following notational convention is introduced to simplify the algebraic operations dealing with nescience.

\begin{notation}
We will use the infix notation for the concatenation function, that is, we will write $s \oplus t$ instead of the $\oplus(s, t)$. Moreover, given Axiom A10, we will drop parenthesis in case of multiple concatenations.

We will use the infix notation for the conditional function, that is, we will write $s \mid t$ instead of the $\mid(s, t)$.
\end{notation}

Our last axiom explains how we can decrease the nescience of a given a particular entity.

\begin{definition}[Axiom A14]
Let $t \in \mathcal{B}^\ast$ be a non-minimal element, then at least one of the following is true:
\begin{enumerate}[label=(\roman*)]
\item there exist $s \in \mathcal{B}^\ast$ such that $s \oplus t <_N s$ or $t \oplus s <_N t$,
\item there exists $s, \alpha, \beta \in \mathcal{B}^\ast$ in the form $t = \alpha \oplus s \oplus \beta$ such that $s <_N t$,
\item there exists $s \in \mathcal{B}^\ast$ such that $t \mid s <_N t$.
\end{enumerate}
\end{definition}

It is convenient to introduce the symbol $=_N$ to represent the case that our unknown given the strings $s$ and $t$ is the same. This can be done only if both strings belong to the same equivalence class.

\begin{notation}
Let $[e]$ be an entity, and $s, t \in [e]$ two strings. We denote by $ s =_N t$ the case that $(s, t) \notin <_N$.
\end{notation}

Concatenation is intended to capture the concept of creativity in the theory of nescience. Next axiom proves this capability.

\begin{proposition}
\item[Axiom XX] Let $[e]$ be an entity, and $t \in [e]$ and $s \notin [e]$ two arbitrary strings, then we have that $s <_N \oplus(s, t)$ and $t <_N \oplus(s, t)$.
\end{proposition}
\begin{proof}
{\color{red} TO DO}
\end{proof}

\begin{proposition}
{\color{red} TODO: Explain how concatenation and conditional can be combined into a single equation, something like a distributive law.}
\end{proposition}

{\color{red} TODO: Prove that the concatenation of two minimal elements of the same class is also minimal.}

{\color{red} TODO: Properties of the Oracle: projection function, ...}

{\color{red} TODO: Explain what happens with $\lambda$, the class it belongs to, and its role as a minimal element.}


{\color{red} TODO: Prove that there is an isomorphism between set of finite binary strings and the set of natural numbers. The same for a set of non-binary strings.}

{\color{red} TODO: Prove the invariance theorem, that is, changing the oracle (the equivalence relation) does not changes the order of the strings in terms of the nescience.}

%
% Things to cover in the interpretation
%

\subsection{Interpretation of the Axioms}

The axioms of nescience do not expliclty mention the concepts of miscoding, inaccuracy and surfeit. However, there is a natural interpretation of these concepts under these axioms.


Oracle: Each equivalence class corresponds to an entity, and it contains all possible representations
and descriptions of that entity, including the wrong ones. Fron an axiomatic point of view,
reprsentations and descriptions are indistinguishable. The entities themselves are not part of the
set. This abstract oracle is the only tool we have at our disposal to match entities and their
string based representations. The actual schema used internally by the oracle to relate entities and
its representations is irrelevant in this axiomatization. All possible strings belong to at least on
entity, and one string cannot be part of two entities.

We cannot provide a quantitative measure of nescience, since numbers are not part of our
axiomatic structure. Although binary strings can be equaled to natural numbers, the symbols +
and  are missing in our logic structure. Instead what we have defined is a relative ordering of
the different elements of B according to how much we do not known given those strings. The
ordering has to be partial, i.e. not every pair of elements of B can be compared. This partial order
is applicable not only in case of strigs that belong to different entities, but also when they belong to
the same entity. Intra-entity order strictness leads to the notion of nescience Pareto frontier. The
order has to be strict, i.e. nescience equality is not defined. The problem of assuming a non-strict
total order for nescience N is that if s N t and t N s then s = t, that is, if two strings have the
same nescience, they must be the same string, and this is not necessarily the case. Within our
axioms, nescience equality is just a notational convention.

Concatenation is the process that allow us to discover new entities: concatenating two strings
that belong to different entities might lead to a new, previously unknown, entity. Concatenation
implements the exploration part in this schema of exploration/exploitation in which science is
characterized.

%
% Axioms based on Type Theory
%

\subsection{Type Theory}

In the previous section we have provided a formalization of the theory of nescience based in set theory and first order logic. Set theory is not the only available framework in which mathematics can be formalized. We could have used type theory or category theory instead. Having meaniful axioms of our theory in multiple formalization frameworks, such as set theory, type theory, and category theory, will constitute strong evidence that nescience is a fundamental concept in mathematics, and not a mere artifact of a particular formalization.

In this section we are going to provide a formalization of the theory of nescience in the context of type theory (see Section \ref{sec:lambda_calculus}). Type theory has some advantages over set theory. The most important is that it is a constructive theory, which means that we do not assume the existence of abstract mathematical entities that satisfy some properties, but we show how to construct those entities. For example, there is no need to resort to an abstract, uncomputable, oracle. In type theory, all propositions and proven theorems have an equivalent computable function or algorithm, and thus, we can provide computer programs to solve all problems addressed by our theory (see Section \ref{sec:nescience_library} for a practical implementation of some of these algorithms in the form of a software library).

A second advantage of type theory is that the lambda terms used in the theory are by definition computable functions, and that lambda calculus is a Turing machine capable of universal computation. In the theory of nesciece we require that our models be lambda terms, and that our universal Turing machine be the lambda calculus. In this sense, our models are native elements within the theory, not external artifacts based on an arbitrary, axiomatically defined, universal machine. The models that describe entities are lambda terms executed in the univeral Turing machine of lambda calculus.

The third advantage is that there are software implementations of type theory, such as the Coq proof assistant (see Section \ref{apx:coq}), which allow us to mechanically verify the correctness of our theory. In the rest of this section, we will use the coq syntax for definitions, propositions and theorems so that interested readers can use a computer and a Coq interpreter to verify by themselves that the proofs are correct. We have also included an appendix where we briefly describe the Coq language, so that those readers who prefer traditional mathematics can translate the Coq scripts into classical mathematical definitions and propositions.

% Foundamental Concepts

\subsubsection*{Foundamental Concepts}

We start by introducing a new type, called \texttt{String}. The type string is defined recursively in the following way: the empty string, called \texttt{lambda}\footnote{Do not confuse the $\lambda$ symbol with a $\lambda$-term.}, is a string, and the sucessor of a string, given the function \texttt{S}, is also a string. For us strings are just a list of lambdas, and our theory is based on the collection of all finite strings $\{ \lambda, \lambda \lambda, \lambda \lambda \lambda, \ldots \}$. Both descriptions and representations will be finite strings of lambdas.

\begin{sourcecode}
{\scriptsize \begin{verbatim}
Inductive String : Set :=
  | lambda : String
  | S      : String -> String.
\end{verbatim}}
\end{sourcecode}

Before to introduce the main concepts of the theory of nescience, we have to define a helper funcion called \texttt{Difference}. The \texttt{Difference} function computes the absolute difference between two strings, that is, the excess of lambdas of the longer string with respect to the shortest one. For example, if we have the strings $\lambda \lambda$ and $\lambda \lambda \lambda$, the difference would be the string $\lambda$. Given two strings $r$ and $s$, \texttt{Difference} is defined recursively as:

\begin{sourcecode}
{\scriptsize \begin{verbatim}
Fixpoint Difference (r s : String) : String :=
  match r, s with
  | lambda, lambda  => lambda
  | lambda, s       => s
  | r     , lambda  => r
  | S r'  , S s'    => Difference r' s'
  end.
\end{verbatim}}
\end{sourcecode}

We say that a string $r$ has smaller \emph{surfeit} than a string $s$ if the string $r$ is shorter, in terms of number of lambdas, than the string $s$. Given two strings $r$ and $s$, the \texttt{Surfeit} function is defined recursively, and returns \texttt{true} if the string $r$ has less lambdas than the string $s$.  Applied to descriptionss, we prefer those with the smaller number of lamdas.

\begin{sourcecode}
{\scriptsize \begin{verbatim}
Fixpoint Surfeit (r s : String) : bool :=
  match r, s with
  | lambda, lambda => false
  | lambda, _      => true
  | _     , lambda => false
  | S r', S s'     => Surfeit r' s' 
  end.
\end{verbatim}}
\end{sourcecode}

The \emph{inaccuracy} of a string $r$ with respect to a target string $t$ is based on the absolute difference between the two strings, that is, how close is the string to the target. Given two strings $r$ and $s$, and a target string $t$, the \texttt{Inaccuracy} function returns \texttt{true} if the absolute difference between the strings $r$ and $t$ contains less lambdas than the absolute difference between the strings $s$ and $t$. Inaccuracy will be applied to the ouput of the models.

\begin{sourcecode}
{\scriptsize \begin{verbatim}
Definition Inaccuracy (r s : String) (t : String) : bool :=
  Surfeit (Difference r t) (Difference s t).\end{verbatim}}
\end{sourcecode}

\emph{Nescience} will be based on the concepts of surfeit and inaccuracy. Intitively, we are looking for very short descriptions (low surfeit) and with very low error (low inaccuracy). The \texttt{Nescience} function gets as input five strings: $mr$, $ms$, $r$, $s$ and $e$, and returns \emph{true} if $mr$ is a shorter string than $ms$, and the inaccuracy of $r$ is smaller than the inaccucay of $s$ with respect to $e$. Intuitively, $mr$ and $ms$ would be a string-based representations of our models (in our case, lambda-terms), $r$ and $s$ are the string-based outputs of these models, and $e$ is a string-based representation of an entity.

\begin{sourcecode}
{\scriptsize \begin{verbatim}
Definition Nescience (mr ms : String) (r s : String) (e : String) : bool :=
  andb (Surfeit mr ms) (Inaccuracy r s e).
\end{verbatim}}
\end{sourcecode}

In practice, we generally do not know a string-based representation $e$ of the entity we are interested in, so an indirect approach must be used to study that entity. \emph{Miscoding} is this approach, and it will be introduced in a later section.

Instead of defining the new type \texttt{String} we could have reused the concept of natural number, that is, we could have introduced descriptions and representations as numbers. In that case, the \texttt{Difference} between two strings $r$ and $s$ would be the absolutute difference $\mid r - s \mid$ between the numbers $r$ and $s$, and the \texttt{Surfeit} could be based on the the strict order relation between numbers $<$. The concepts of \texttt{Inaccuracy} and \texttt{Nescience} would have been defined in the same way with numbers. However, natural numbers require additional properties that are not needed for the theory of nescience. For example, the multiplication of two natural numbers does not make any sense in our theory.  Reusing natural numbers would have made our theory unnecerarily complex.

In the rest of this section, we will see how we can derive our theory of nescience using only these fundamental concepts. We will also prove the most significant results and derive algorithms for applying the theory in practice.

% Surfeit

\subsubsection*{Surfeit}

Surfeit allow us to compare two strings. Recall that the surfeit of two strings $r$ and $s$ is true if, and only if, $s$ is composed by more lambdas than $r$. Surfeit allow us to order the models (string based representations of the models) by its length. We are interested in those models with the lowest possible complexity. In the rest of this section we are going to review the properties of surfeit.

The surfeit of a string does not increases when we conditions that string to another one. Intuitively, assuming some previous background knowledge already known as true allow us to reduce the complexity of our models.

\begin{sourcecode}
{\scriptsize \begin{verbatim}
Proposition SurfeitConditional : forall r s : String, 
  Surfeit r (r |c s) = false.
Proof.
intros.
induction r as [| r' IHr'].
- simpl.
  reflexivity.
-
Admitted.
\end{verbatim}}
\end{sourcecode}

From a theoretical point of view, the limit to the proccess of conditioning would be to assume as true the current model.

\begin{sourcecode}
{\scriptsize \begin{verbatim}
Proposition SurfeitConditionalLambda : forall r s: String, 
  Surfeit lambda (r |c r) = false.
Proof.
Admitted.
\end{verbatim}}
\end{sourcecode}

The surfeit of a string does not decreases when it is concatenated with another string. Intuitively, the concatenation of two models increases our uknown. This process of concatenating models can be used as an exploratory mechanism to discover new research topics (previously unknown entities).

\begin{sourcecode}
{\scriptsize \begin{verbatim}
Proposition SurfeitConcatenation : forall r s : String, 
  Surfeit r (r <+> s) = false.
Proof.
intros.
Admitted.
\end{verbatim}}
\end{sourcecode}

From the point of view of surfeit, the operation of concatenation can be distributed over the operation of conditioning, as next proposition shows ({\color{red} TODO: provide the intuition behind this distributive law}).

\begin{sourcecode}
{\scriptsize \begin{verbatim}
Proposition DistributiveLawSurfeit : forall r s t  : String,
  Surfeit ((r |c s) <+> t) ((r <+> t) |c (s <+> t)) = true.
Proof.
Admitted.
\end{verbatim}}
\end{sourcecode}

% Inaccuracy

\subsubsection*{Inaccuracy}

{\color{red} Definition and results about inaccuracy}

{\color{red} Inaccuracy does not increases with conditional}

\begin{sourcecode}
{\scriptsize \begin{verbatim}
Proposition InaccuracyConditional : forall r s e : String, 
  Inaccuracy r (r |c s) e = false.
Proof.
Admitted.
\end{verbatim}}
\end{sourcecode}

{\color{red}  The limit would be conditioning a string to itself}

\begin{sourcecode}
{\scriptsize \begin{verbatim}
Proposition InaccuracyConditionalLambda : forall r s: String, 
  Inaccuracy lambda (r |c r) = false.
Proof.
Admitted.
\end{verbatim}}
\end{sourcecode}

{\color{red} Distributive Law}

\begin{sourcecode}
{\scriptsize \begin{verbatim}
Proposition DistributiveLawInaccuracy : forall r s t  : String,
  Inaccuracy ((r |c s) <+> t) ((r <+> t) |c (s <+> t)) = true.
Proof.
Admitted.
\end{verbatim}}
\end{sourcecode}

% Entities, Representations and Descriptions

\subsubsection*{Entities, Representations and Descriptions}

After we have described the fundamental concepts of the theory of nescience, in this section we are going to introduce the remaining elements of the theory, that is, the concepts of entity, representation and description.

We introduce the concept of \emph{entity} recursively as a finite list of strings. Those strings correspond to the valid representations of the entity. We consider that the empty entity, denoted by \emph{nil}, is also an entity.

\begin{sourcecode}
{\scriptsize \begin{verbatim}
Inductive Entity : Set :=
  | nil       : Entity
  | add_repr : String -> Entity -> Entity.
\end{verbatim}}
\end{sourcecode}

A \emph{universe} is a finite list of entities. A universe correspond to the particular reasearch area in which we are interested. We consider that the empty universe, denoted by \emph{empty}, is also a universe. The recursive definition of universe is given by:

\begin{sourcecode}
{\scriptsize \begin{verbatim}
Inductive Universe : Set :=
  | empty      : Universe
  | add_entity : Entity -> Universe -> Universe.
\end{verbatim}}
\end{sourcecode}

A description is a pair composed by a recursive funcion (a $\lambda$-term) from strings to strings, what we call a \emph{model}, and an input string to that model.

\begin{sourcecode}
{\scriptsize \begin{verbatim}
Definition Description (model : String -> String) (input : String) : String :=
  model input.\end{verbatim}}
\end{sourcecode}

% Miscoding

\subsubsection*{Miscoding}

{\color{red} Definition and results about miscoding}


% Properties of Strings

\subsubsection*{Properties of Strings}

Before we move into the details of the theory of nescience, we are going to prove some basic properties that our concept of string satisfies. Also, besides to the already introduced concept of string difference, we are going to introduce two other strings operators: concatenation and conditional.

We say that two strings are \emph{equal} if, and only if, they have the same number of sigmas. String equality is defined recursively as follows:

\begin{sourcecode}
{\scriptsize \begin{verbatim}
Fixpoint Equality (r s : String) : bool :=
  match r, s with
  | lambda, lambda => true
  | lambda, _      => false
  | _     , lambda => false
  | S r'  , S s'   => Equality r' s'
  end.
\end{verbatim}}
\end{sourcecode}

It is convenient to introduce a new infix operator to represent the string equality concept. That will helps us to simplify new definitions and proofs.

\begin{sourcecode}
{\scriptsize \begin{verbatim}
Notation "x =? y"  := (Equality x y)
\end{verbatim}}
\end{sourcecode}

In the same way, we introduce another infix operator to represent the concept of string difference.

\begin{sourcecode}
{\scriptsize \begin{verbatim}
Notation "x <d> y"  := (Difference x y)
\end{verbatim}}
\end{sourcecode}

Strings with the difference operator form an abelian group. That is: it has a neutral element, it is conmutative, associative and has an inverse element.

The neutral element for strings is the $\lambda$ symbol. That $\lambda$ is the neutral elment with respect to the operation of difference is a direct consequence of the definitions of string and difference.

\begin{sourcecode}
{\scriptsize \begin{verbatim}
Proposition DifferenceNeutral : forall r : String,
  r <d> lambda = r /\ lambda <d> r = r.
Proof.
intros.
split.
- destruct r.
  * reflexivity.
  * reflexivity.
- destruct r.
  * reflexivity.
  * reflexivity.
Qed.
\end{verbatim}}
\end{sourcecode}

The property of being conmutative of the difference operator is proved by ... {\color{red} TODO}

\begin{sourcecode}
{\scriptsize \begin{verbatim}
Proposition DifferenceConmutative : forall r s : String,
  r <d> s = s <d> r.
Proof.
Admitted.
\end{verbatim}}
\end{sourcecode}

In the same way, the property of being conmutative is shown by ... {\color{red} TODO}

\begin{sourcecode}
{\scriptsize \begin{verbatim}
Proposition DifferenceAsociative  : forall r s t  : String,
  r <d> (s <d> t) = (r <d> s) <d> t.
Proof.
Admitted.
\end{verbatim}}
\end{sourcecode}

Given an arbitrary string $r$, its inverse element is the string itself, as next proposition shows. The proposition is proved by induction over $r$.

\begin{sourcecode}
{\scriptsize \begin{verbatim}
Proposition DifferenceInverse : forall r : String,
  r <d> r = lambda.
Proof.
intros.
induction r as [| r' IHr'].
- reflexivity.
- simpl.
  apply IHr'.
Qed.
\end{verbatim}}
\end{sourcecode}

The operation of \emph{concatenation} of two strings returns a new string composed by one of the strings appened at the end of the other. The operation of concatenation is defined recursively as:

\begin{sourcecode}
{\scriptsize \begin{verbatim}
Fixpoint Concatenate (r s : String) : String :=
  match r, s with
  | lambda, _     => s
  | S r'  , _     => S (Concatenate r' s)
  end.
\end{verbatim}}
\end{sourcecode}

The infix notation for the concatenation operation is given by:

\begin{sourcecode}
{\scriptsize \begin{verbatim}
Notation "x <+> y" := (Concatenate x y)
\end{verbatim}}
\end{sourcecode}

The pair composed by strings and the concatenation operation form a conmutative monoid. That is, it has a neural element, and it satisfies the properties of being conmutative and associative.

The neutral element of the operation of concatenation is $\lambda$. In order to prove that $\lambda$ is indeed the neutral element we ... {\color{red} TODO}

\begin{sourcecode}
{\scriptsize \begin{verbatim}
Lemma s_plus_lambda : forall s : String,
  s <+> lambda = s.
Proof.
intros.
induction s as [| s' IHs'].
- simpl.
  reflexivity.
- simpl.
  rewrite -> IHs'.
  reflexivity.
Qed.
\end{verbatim}}
\end{sourcecode}

Given the above lemma we can now prove that $\lambda$ is the neutral element ... {\color{red} TODO}

\begin{sourcecode}
{\scriptsize \begin{verbatim}
Proposition ConcatenationNeural : forall r : String,
  r <+> lambda = r /\ lambda <+> r = r.
Proof.
Admitted.
\end{verbatim}}
\end{sourcecode}

{\color{red} TODO: string concatenation is conmutative, and its proof requires to additional lemmas.}

\begin{sourcecode}
{\scriptsize \begin{verbatim}
Lemma plus_r_Ss : forall r s: String,
  S (r <+> s) = r <+> S s.
Proof.
intros.
induction r as [| r' IHr'].
- simpl.
  reflexivity.
- simpl.
  rewrite -> IHr'.
  reflexivity.
Qed.
\end{verbatim}}
\end{sourcecode}

\begin{sourcecode}
{\scriptsize \begin{verbatim}
Lemma S_equal : forall n m : String,
  n = m -> S n = S m.
Proof.
intros.
induction m as [| m' IHm'].
- rewrite -> H.
  reflexivity.
- rewrite -> H.
  reflexivity.
Qed.
\end{verbatim}}
\end{sourcecode}

\begin{sourcecode}
{\scriptsize \begin{verbatim}
Proposition ConcatenationConmutative : forall r s : String,
  r <+> s = s <+> r.
Proof.
intros.
induction s as [| s' IHs'].
- simpl.
  apply s_plus_lambda.
- simpl.
  rewrite <- IHs'.
  rewrite <- plus_r_Ss.
  reflexivity.
Qed.
\end{verbatim}}
\end{sourcecode}

{\color{red} Associative property of concatenation ... }

\begin{sourcecode}
{\scriptsize \begin{verbatim}
Proposition ConcatenationAsociative  : forall r s t  : String,
  r <+> (s <+> t) = (r <+> s) <+> t.
Proof.
intros.
induction r as [| r' IHr'].
- simpl.
  reflexivity.
- simpl.
  rewrite <- IHr'.
  reflexivity.
Qed.
\end{verbatim}}
\end{sourcecode}

{\color{red} Introduce the operator of string conditional, as a recursive definition.}

\begin{sourcecode}
{\scriptsize \begin{verbatim}
Fixpoint Conditional (r s : String) : String :=
  match r, s with
  | lambda, _      => lambda
  | s     , lambda => s
  | S r'  , S s'   => Conditional r' s
  end.
\end{verbatim}}
\end{sourcecode}

{\color{red} Infix notation.}

\begin{sourcecode}
{\scriptsize \begin{verbatim}
Notation "x |c y"  := (Conditional x y).
\end{verbatim}}
\end{sourcecode}

{\color{red} Algebraic structure of the conditional operator.}

{\color{red} Left Neutral Element}

\begin{sourcecode}
{\scriptsize \begin{verbatim}
Proposition ConditionalLeftNeutral : forall r : String,
  r |c lambda = r.
Proof.
intros.
destruct r.
- reflexivity.
- reflexivity.
Qed.
\end{verbatim}}
\end{sourcecode}

{\color{red} Inverse Element}

\begin{sourcecode}
{\scriptsize \begin{verbatim}
Proposition ConditionalInverse : forall r : String,
  r |c r = lambda.
Proof.
intros.
induction r as [| r' IHr'].
- simpl.
  reflexivity.
- simpl.
Admitted.
\end{verbatim}}
\end{sourcecode}

Having introduced the operations of difference, concatenation and conditional, we can study which of these operators can be distributed over the others, since not all possible combinations are valid. In fact, only three distributive laws are true in our theory of nescience.

The operation of concatenation can be distributed to the operation of conditional, as the next proposition shows. The proposition is proved by ... {\color{red} TODO}.

\begin{sourcecode}
{\scriptsize \begin{verbatim}
Proposition DistributiveConditionalConcatenation : forall r s t  : String,
  Surfeit ((r |c s) <+> t) ((r <+> t) |c (s <+> t)) = true.
Proof.
Admitted.
\end{verbatim}}
\end{sourcecode}

The concatenation operator can also be distributed to the difference operator. The proposition is proved by ... {\color{red} TODO}.

\begin{sourcecode}
{\scriptsize \begin{verbatim}
Proposition DistributiveDifferenceConcatenation : forall r s t  : String,
  Surfeit ((r <d> s) <+> t) ((r <+> t) <d> (s <+> t)) = true.
Proof.
Admitted.
\end{verbatim}}
\end{sourcecode}

Finally, we have a third distributive law, that says that the difference operator can be distributed to the concatenation. Th proposition is proved by ... {\color{red} TODO}.

\begin{sourcecode}
{\scriptsize \begin{verbatim}
Proposition DistributiveConcatenationDifference : forall r s t  : String,
  Surfeit ((r <+> s) <d> t) ((r <d> t) <+> (s <d> t)) = true.
Proof.
Admitted.
\end{verbatim}}
\end{sourcecode}

%
% Section: Scientific Method
%

\section{Scientific Method}

Next definition formally introduces the concept of scientific methodology in the context of the theory of nescience.

\begin{definition}
A \emph{scientific methodology} is an effective procedure that produces a sequence of $t_1, t_2, \ldots, t_n, \ldots$ where $t_i \in \mathcal{D}$ such that $N(t_i) < N(t_{i+1})$.
\end{definition}

Note that we do not require that in a scientific methodology the collection of $t_i$ refer to the same entity.


{\color{red} Describe our proposal of scientific method. Short story: based on a exploration/exploitation approach, where the exploration is based in the concept of joint descriptions, and the exploitation in the concept of conditional description.}

{\color{red} Compare against another proposals of scientific method (inductive-deductive, hypothetico-deductive, etc) and with other techniques for knowledge discovery and creativity (triz, etc.)}

\subsection{Science as a Language}

{\color{red} TODO: Provide an alternative definition of the set of descriptions, and prove that it is equivalent to our definition based on the description function}

Since we require computable descriptions, we would like to know if the set of all possible descriptions of a topic is computable as well.

\begin{proposition}
Study if $D_{t}$ is Turing-decidable, Turing-recognizable or none.
\end{proposition}
\begin{proof}
{\color{red} TODO}
\end{proof}

Although we know that it is not computable, we are interested in the set composed by the shortest possible description of each topic.

\begin{definition}
We define the set of \emph{perfect descriptions}, denoted by $\mathcal{D}^\star$, as:
\[
\mathcal{D}^\star = \{ d_t^\star : t \in \mathcal{T} \}
\]
\end{definition}

Since the set $\mathcal{D}$ includes all the possible descriptions of all the possible (describable) topics, we can see this set as a kind of language for science. We do not call it universal language since it depends on the initial set of entities $\mathcal{E}$ and the particular encoding used for these entities.

\begin{proposition}
The set $\mathcal{D}$ is not Turing-decidable.
\end{proposition}
\begin{proof}
{\color{red} TODO: Because it depends on the set $\mathcal{T}$ that it could be not computable}
\end{proof}

Say something here

\begin{proposition}
The set $\mathcal{D}$ is Turing-recognizable.
\end{proposition}
\begin{proof}
{\color{red} TODO: The same argument as the previous proposition}
\end{proof}

A universal language is determined by a universal Turing machine. Given Two different universal Turing machines $\delta_{a}$ and $\delta_{b}$ defines two different universal languages $\mathcal{L}_{a}$ and $\mathcal{L}_{b}$. Let $\mathcal{L}_{a=b}=\left\{ \left\langle d_{a},d_{b}\right\rangle \,,\,d_{a},d_{b}\in\mathcal{D}\mid\delta_{a}\left(d_{a}\right)=\delta_{b}\left(d_{b}\right)\right\}$.

\begin{proposition}
Study if $\mathcal{L}_{a=b}$ is Turing-decidable, Turing-recognizable or none.
\end{proposition}
\begin{proof}
{\color{red} TODO}
\end{proof}

Let $\mathcal{L}_{\nexists t}$ the laguage of valid descriptions (from a formal point of view) that do not describe any topic, that is, $\mathcal{L}_{\nexists t}=\left\{ d\in\mathcal{D}\mid\nexists t\in\mathcal{T}\,,\,\delta\left(d\right)=t\right\}$.

\begin{proposition}
Study if $\mathcal{L}_{\nexists t}$ is Turing-decidable, Turing-recognizable or none.
\end{proposition}

Let $\mathcal{L}_{\nexists d}$ the laguage topics that are not described by any description, that is, $\mathcal{L}_{\nexists d}=\left\{ t\in\mathcal{T}\mid\nexists d\in\mathcal{D}\,,\,\delta\left(d\right)=t\right\}$.

\begin{proposition}
Study if $\mathcal{L}_{\nexists d}$ is Turing-decidable, Turing-recognizable or none.
\end{proposition}

{\color{red} TODO: Extend the concept of conditional description to multiple topics.}

{\color{red} TODO: Introduce the concept of "independent topics" based on the complexity of the conditional description. Study its properties.}

{\color{red} TODO: Define a topology in $\mathcal{T}$ and $\mathcal{D}$. Study the continuity of $\delta$. Study the invariants under $\delta$.}


%
% Section: The Inaccuracy - Surfeit Trade-off
%

\section{The Inaccuracy - Surfeit Trade-off}

{\color{red} TODO: Explain that given a miscoding, there is a trade-off between inaccuracy and surfeit, in the sense that there exists an optimal point beyond it the more we decrease the inaccuracy, the more we increase the surfeit, and so, the nescience keep constant. Explain how this trade-off imposes a limit to knowledge.}

%
% Section: Science vs. Pseudoscience
%

\section{Science vs. Pseudoscience}

{\color{red} TODO: Provide a characterization of the difference between science and pseudoscience. In science, nescience decreases with time, in pseudoscience not.}

%
% Section: Graspness
%
\section{Graspness}

There are some topics whose nescience decrease with time much faster than others, even if the amount of research effort involved is similar. A possible explaination to this fact is that there are some topics that are inherently more difficult to understand.

We define the \emph{graspness} of a topic as the entropy of the set of possible descriptions of that topic. A high graspness means a difficult to understand topic. Intuitively, a research topic is difficult if it has no descriptions much shorter than the others, that is, descriptions that significantly decrease the nescience. For example, in physics there have been a sucession of theories that produced huge advances in our understanding of how nature works (Aristotelian physics, Newton physics, Einstein physics), meanwhile in case of philosophy of science, new theories (deductivism, inductivism, empirism, falsation, ...) have a similar nescience than previous ones.

\begin{definition}[Graspness]
Let $D_t$ the set of descriptions of a topic $t \in T$. The \emph{graspness} of topic $t$, denoted by $G(t)$, is defined by:
\[
G(t) = \sum_{d \in D_t} 2^{-l(d)} l(d)
\]
\end{definition}

Grapsness is a postive quantity, whose maximum is reached when all the descriptions of the topic have the same length:

\begin{proposition}
Let $D_t = \{ d_1, d_2, \ldots, d_q \}$ the set of descriptions of a topic $t \in T$, then we have that $G(t) \leq \log q$, and $G(t) = \log q$ if, and only if, $l(d_1) = l(d_2) = \ldots = l(d_q)$.
\end{proposition}
\begin{proof}
Replace $P(s_i)$ by $2^{-l(d_i)}$ in Proposition \ref{prop:maximum_entropy}.
\end{proof}

If $G(t) = \log q$ then we have that $N_t = 0$ for all $\hat{d}_t$. In that case, it does not make any sense to do research, since no knew knowledge can be adquired. This is the case of pseudosciences, like astrology, where the nescience of descriptions does not decrease with time. If fact, graspness can be used as a distintive element of what constitutes \emph{science} and what does not.

\begin{definition}
A topic $t \in T$ is \emph{scientable} if $G(t) < \log d(D_t) - \epsilon$, where $\epsilon \in \mathbb{R}$ is a constant.
\end{definition}

We can extend the concept of graspness from topics to areas, for example, by means of computing the average graspness of all the topics included in the area.

\begin{definition}
Let $A \subset T$ a research area. The \emph{graspness} of area $A$, denoted by $G(A)$, is defined by:
\[
G(A) = \frac{1}{d(A)} \sum_{t \in A} G(t)
\]
\end{definition}

%
% Section: Effort
%
\section{Effort}

{\color{red} TODO: Provide a characterization of the effort, measured in terms of number of operations, or time, to reduce the nescience. Based in the concept of computational complexity. Provide a physical interpretation in terms of information.}

%
% Section: Human Understanding
%
\section{Human Understanding}

In his landmark paper \emph{"On Computable Numbers with an Application to the Entscheidungsproblem"}, where the concept of computable function was proposed for the first time, when the author Alan M. Turing talked about computers, he was thinking about human computers, not machines. In this sense, according to Turing, everything that is computable, can be computed by a human, at least in theory.

The fist limitation is about computation time. We expect that a human is able to find a solution to a particular instance of a problem in order of seconds, maybe minutes or hours, but definitely, in less than a life time, otherwise another human have to start again from scratch to solve the problem. So, given the average computing speed of a human brain, we identify as human solvable problems only those problems with a complexity smaller than a fixed number of steps.

The second limitation is about program size. It might happen that the algorithms to solve a problem is simply too big to fit in our brains. Of course, we could argue that {\color{red} as we saw in Example XX, only X states and Y tape symbols} are sufficient to implement a universal Turing machine capable of solving any computable problem, that is, any problem for which exist a Turing machine that can solve it. However, by just following a set of instruction we do not mean that we understand a problem. We understand a problem when we have made the problem for ourselves, in the sense, that the problem is somehow stored in our brain in our own language. So this limits the problem to those whose length, including the necessary background, can be stored in our brain.

We are looking for solutions that minimize at the same time the computational complexity and the Kolmogorov complexity.

\begin{definition}
We say that a problem $P$ is \emph{human solvable} if there exist an algorithm $TM$ to solve $P$ such that $t(n)$ and $K(P) < l$.
\end{definition}

Given the above definition, we could argue that most of the problems we know are not human solvable, but in fact, they have been solved by human. We use two strategies to deal with too complex problems for our individual brains. The fist strategy is that those time-comsuming mechanical parts of the problems are left for computers, so we can reduce the computing time. The second one is that we split the problems into subproblems and each of use specializes in those subproblems.

In this section we are interested in to study the nature of these problems in which this strategy cannot be applied, and so, they are out of reach of individual, nor groups of, humans.

%
% Section: Areas in Decay
%

\section{Areas in Decay}

{\color{red} Provide a model of the decay in the interest of research areas. For example, a good explanatory variable could be the number of interesting questions: the less interesting questions, the more the area is near to its end as a interesting research area, of course, as long as its topics are not used as tools.}

%
% Section: References
%

\section*{References}

{\color{red} Mention the polemic between Hilbert and Fredge given a reference to the book of Mosterin.}


