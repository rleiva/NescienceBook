%
% Preface
%

\chapterimage{Ramon_Llull_-_Ars_Magna_Fig_1.pdf} % Chapter heading image

\chapter*{Preface}

\begin{quote}
\begin{flushright}
\emph{Perfection is achieved not when there is nothing more to add, \\
but when there is nothing left to take away.}\\
Antoine de Saint-Exupéry\\
\end{flushright}
\end{quote}
\bigskip

%
% Why:  We want to venture into the unknown by breaking the limits of science.
% How:  By developing a rigorous mathematical theory based on computability and randomness.
% What: A collection of tools to discover what is hidden in the unknown unknown.
%

We live in an era that places a high value on knowledge and celebrates scientific advancement. The development of vaccines in record time, the detection of gravitational waves, and the use of artificial intelligence to model protein structures are just a few examples of the extraordinary progress science has made in recent years. However, this celebration of progress should not obscure the structural limitations within the scientific enterprise itself. Despite its accomplishments, science is constrained by the methodological and conceptual frameworks it employs. For example, the "publish or perish" culture in academia often results in a flood of low-quality publications, which can dilute the impact of meaningful scientific work. Another major constraint lies in the allocation of research funding, which often fails to prioritize investigations with the highest potential societal return.

This book is driven by a central aspiration: to overcome the methodological constraints of science in order to challenge established knowledge, explore the unknown, and progress towards the limits of scientific understanding. Our aim is to investigate not only well-known unsolved problems but also those that remain outside our current awareness, the known unknowns and the unknown unknowns. But this pursuit is not merely an academic curiosity; it is a practical necessity. Rather than developing a purely theoretical framework, our goal is to create an approach that can be applied in real-world scientific contexts.

Our assumption is that to explore and ultimately reduce what we do not yet know, we need a structured framework for understanding ignorance itself. To this end, we propose a rigorous mathematical theory, named the Theory of Nescience, grounded in the principles of computability, randomness, and artificial intelligence. The theory builds upon a striking insight: perfect knowledge implies randomness. Although this may initially appear counterintuitive, given that science is traditionally associated with structure, order, and explanation, it becomes clearer when we consider the process of theory refinement. As scientific understanding improves, our descriptions of phenomena become more concise.  Eventually, a theory becomes so concise that it cannot be simplified any further. Its representation becomes incompressible, which aligns with the mathematical definition of a random string.

Randomness sets the ultimate limit to our knowledge, since a random description cannot be refined any further and, assuming the theory is accurate, our understanding must be perfect. Far from being a handicap, the constraints that randomness imposes on knowledge pave the way for new possibilities in science and technology. By comprehending these limitations, we can address the most challenging open problems and discover completely new research topics.

From this theoretical foundation emerges a new mathematical framework for understanding nescience, or human ignorance, and the processes by which knowledge is acquired, organized, and refined. Some fo the contributions of this book are:

\medskip

\begin{itemize}
 
\item A mathematical theory to quantify our lack of scientific knowledge, based on computability and randomness, and on the assumption that measuring how much we do not know is easier than measuring how much we do know.

\item A new collection of metrics to measure how much we do not know, whether about individual research topics or broader research areas, and how new research contributions either reduce or fail to reduce that ignorance.

\item A practical framework to address some of the most relevant challenges in science, such as defining what constitutes perfect knowledge, identifying the limits of science, and discovering new, previously unknown, research topics.

\item A software library that combines the Theory of Nescience with principles of artificial intelligence to automatically derive new knowledge and make predictions based on data.

\end{itemize}

\medskip

The Theory of Nescience challenges us to rethink the aims of scientific inquiry. Instead of striving to maximize what we know, it encourages us to minimize what we do not know. By shifting our focus from accumulation to reduction, we open the door to more meaningful measures of scientific progress. The chapters that follow lay the theoretical groundwork for this new approach, one that begins with ignorance and ends in knowledge.

%
% Section: Research Agenda
%

\subsection*{Research Agenda}

In this section, we present a focused list of research questions aimed at addressing important gaps in our current understanding of science and the scientific method. Our goal is to stimulate thoughtful investigation by drawing from a variety of academic perspectives. By pursuing these questions, we hope to push the boundaries of human knowledge and inspire innovative solutions that can benefit both scientific inquiry and society more broadly.

\emph{Can we provide a quantitative characterization of our ignorance regarding a research topic?} Developing such a metric would give us a way to measure not just what we know, but how much we are still missing. This would be especially useful for evaluating scientific contributions, as we could measure how much each new idea or publication actually improves our understanding. By combining this with relevance metrics, we would gain a powerful tool for assessing the true value of scientific work.

\emph{Can we compare the extent of our ignorance across disparate scientific fields?} If this is possible, we could evaluate and prioritize research based on how much there is left to understand, regardless of the field. This approach could help distribute scientific attention and funding more effectively, highlighting areas of science that are in greater need of exploration while still valuing fundamental research.

\emph{Can we establish a systematic procedure to enhance our knowledge?} While the scientific method has long served as the cornerstone of research, it varies significantly across disciplines and often lacks clear, measurable criteria for success. Developing a unified and precise approach could improve the consistency and efficiency of scientific discovery. If successful, it would allow us to evaluate and refine how knowledge is generated, leading to more reliable and accelerated progress across all areas of inquiry.

\emph{Can we devise a method for discovering new, previously unknown, and intriguing research entities and problems?} Many major discoveries arise from questions we had not thought to ask. If we could build a systematic way to identify these unknown unknowns, we could unlock entirely new areas of research and significantly accelerate scientific progress.

\emph{What constitutes perfect knowledge?} Understanding what it means to know something completely is essential to defining the limits of science. If we could precisely define and recognize perfect knowledge, we would know when a field is complete and when it is time to shift our focus elsewhere. Clarifying whether such completeness is always possible would also help set realistic goals for scientific inquiry.

\emph{What effort is required to fully comprehend an unfamiliar subject?} Measuring the cost of understanding could fundamentally change how we plan and fund research. For example, knowing the minimal effort needed to improve our grasp of cancer treatment by a small percentage would help us allocate resources more wisely. Even an estimate would be useful for setting priorities and managing expectations.

\emph{Do some research topics inherently possess a higher degree of complexity than others?} This question addresses a long-standing debate about intellectual differences across disciplines. If we could objectively measure topic complexity, we might dispel myths of superiority and develop more targeted educational strategies. It would also help explain why some areas advance faster than others.

\emph{Are there research topics beyond the scope of human comprehension?} Human cognition has limits, and it is possible that some problems are fundamentally beyond our capacity to solve. Acknowledging these limits could help us better delegate scientific exploration to machines where appropriate, especially as artificial intelligence becomes more capable of original thought.

\emph{How can we differentiate between science and pseudo-science?} Many fields present themselves as scientific but lack rigorous foundations. A mathematically grounded method for identifying what qualifies as science would have major implications for public policy, education, and research funding. It would also help protect scientific integrity by distinguishing valid inquiry from unsupported speculation.

Each chapter in this book engages with these questions from both theoretical and practical standpoints. Some offer detailed responses, while others lay the groundwork for future research. This openness is by design. The Theory of Nescience is not a closed doctrine but a platform for further exploration—an invitation to investigate the limits of science and to imagine new pathways of understanding. In this light, the book is not merely a treatise, but a research agenda, a provocation to conventional thinking, and a call to those who are driven to explore the boundaries of knowledge itself.

%
% Section: Origins of the Theory of Nescience
%

\subsection*{Origins of the Theory of Nescience}

It was in 1991, when I was eighteen years old, that I first encountered the statement, \emph{"Computers are useless, they can only give you answers."} This quote, attributed to Pablo Picasso, struck me as profoundly true. Of course, Picasso was referring to the early calculators of his time, not modern computers. But the underlying idea remains relevant: machines are designed to process predefined tasks, not to generate new and meaningful questions on their own. That realization stayed with me for years. However, it wasn't until 2014—more than two decades later—that I began to explore the implications of Picasso's observation from a practical and computational perspective.

The core ideas behind the Theory of Nescience came together during one particularly restless night. Concepts such as nescience, relevance, and the unknown unknown suddenly aligned. In hindsight, my long-standing interests in information theory and Kolmogorov complexity had likely prepared me for this moment. These disciplines proved essential in articulating the mathematical foundation for a theory that had first emerged as a series of intuitive insights.

Over the following weeks, I conducted a series of computer experiments to test these concepts. The results were promising, but the theory needed time, several years, to develop into a rigorous mathematical framework. Initially, my goal was quite focused: to devise a method for identifying interesting and underexplored scientific questions. But as I examined how ignorance, or nescience, changes over time within scientific disciplines, my scope expanded. I began to wonder whether it was possible to define perfect knowledge and to determine whether such a state could be formally described.

This line of inquiry led to an unexpected and striking insight: perfect knowledge could be expressed in terms of randomness. Specifically, when a theory's description cannot be compressed further, when it becomes algorithmically random, it may indicate that the theory is as complete as possible. This realization broadened my original focus into a general framework for studying the structure of ignorance, the development of understanding, and the mechanisms that drive scientific progress.

Encouraging early feedback from colleagues and researchers helped me refine the theory and explore new applications, particularly in data science and machine learning. Its potential to shed light on long-standing questions in the philosophy of science was especially motivating. For instance, it offered new ways to compare our understanding across fields like mathematics and sociology, and to examine why some research areas appear intrinsically more difficult than others.

Still, something was missing. Although the theory provided compelling explanations, it initially lacked the ability to make testable predictions. To remedy this, I developed a predictive model: a function describing how nescience diminishes as research effort increases. This allowed me to estimate the expected gain in knowledge based on the resources devoted to studying a topic.

Yet even this was not enough. I sought a surprising prediction, one that could reshape how we think about inquiry. Continued mathematical development eventually led to such a discovery: in certain types of topics, additional research can actually increase our ignorance. In these cases, there may exist a critical threshold beyond which further investigation does not improve understanding, but instead introduces greater uncertainty.

This deepened my belief that grappling with ignorance is as fundamental as pursuing knowledge. The Theory of Nescience represents my response to Picasso's challenge: not merely to construct systems that answer questions, but to build frameworks capable of identifying which questions are most worth asking.

These developments and insights have shaped what has become a comprehensive and mature theory. One that I hope will not only reframe how we understand knowledge, but also inspire readers to question more deeply, think more broadly, and search more boldly. The chapters that follow present this journey in both its theoretical depth and practical implications.

%
% Section: About the book
%

\subsubsection*{About the Book}

The Theory of Nescience draws on concepts from multiple academic disciplines, including computability, complexity theory, artificial intelligence, and the philosophy of science. Despite the breadth of its foundations, this book is designed to be self-contained. Readers are expected to have only a basic understanding of first-year calculus and some experience with programming. The content is crafted to serve a wide technical audience, including mathematicians, computer scientists, engineers, and other scientifically inclined readers. The mathematical level is suitable for graduate students and advanced undergraduates.

The book is organized into three main parts: Foundations, Applications, and Mathematical Prerequisites. Readers who already have a background in the mathematics covered in the Mathematical Prerequisites may wish to begin directly with the Foundations. However, we recommend at least a brief review of the notation and key concepts introduced in those chapters. Once readers are familiar with the core ideas presented in the Foundations, they can proceed to the Applications. A detailed understanding of the underlying formalism is not essential; a general grasp of the main concepts and results is sufficient to engage with the practical examples and insights explored in that part of the book.

\bigskip

\begin{itemize}

\item \emph{Chapter \ref{chap:Introduction} Introduction} provides a gentle entry point to the theory of nescience, presenting a brief overview of its main concepts and results. While it avoids the use of advanced mathematics, the ideas are introduced in a semi-formal manner. Although it is not recommended as a substitute for the full theoretical exposition, readers who find the mathematics challenging may choose to read only this chapter before proceeding directly to the Applications.

\end{itemize}

\bigskip

\emph{PART I Foundations} presents a comprehensive account of the theory of nescience, including formal definitions of its core concepts and proofs of key theoretical results. This section forms the core of the book. Readers with prior knowledge in computability, complexity, information theory, probability, and artificial intelligence may choose to begin here directly.

\begin{itemize}

 \item \emph{Chapter \ref{cha:Topics-and-Descriptions} Entities, Representations and Descriptions} includes the initial step toward quantifying our lack of knowledge, which involves the precise identification of the research entities under examination, determining how to represent them as strings of symbols, and identifying suitable models to explain them. The chapter introduces these fundamental components of the theory of nescience: entities, representations, and descriptions. It examines their properties and the relationships among them. The chapter also discusses how various representations and descriptions can be combined, how background knowledge influences research, and explores the link between perfect knowledge and randomness. It concludes by proposing a novel concept of a research area.

\item \emph{Chapter \ref{chap:Miscoding} Miscoding} explores the challenge of representing both abstract and concrete research entities as strings of symbols for research purposes. It formally introduces the concept of miscoding and examines its theoretical properties. Miscoding serves as a measure of the error introduced by inaccurate or inappropriate encodings of the entities being studied. The chapter also discusses strategies for minimizing the errors introduced by poor representations, thereby improving the accuracy and utility of symbolic encodings in research.  Furthermore, it investigates issues associated with targetless representations, cases where a symbolic encoding exists without a clear or well-defined entity it aims to represent.

\item \emph{Chapter \ref{chap:Error} Inaccuracy} presents a new interpretation of the classical concept of error, specifically how accurately a description reflects an entity. The concept is generalized to apply to a wide range of topics, including abstract ones. The chapter also introduces joint and conditional variants of inaccuracy and examines their theoretical properties. It investigates techniques to reduce inaccuracy and explores how miscoding (errors resulting from poor representations) influences the degree of inaccuracy observed.

\item \emph{Chapter \ref{chap:Redundancy} Surfeit} investigates the redundancy present in a description, specifically how many unnecessary elements it contains. Surfeit serves as an indicator of how well we currently understand research topics and areas, since our lack of knowledge about the entity is typically reflected in the length of our prevailing description. The chapter also introduces joint and conditional variants of surfeit and derives a practical approximation that can be applied in real-world scenarios. Finally, it examines the relationship between miscoding, inaccuracy, and surfeit, and how these three components can be minimized simultaneously.

\item \emph{Chapter \ref{chap:Mismodel} Mismodel} introduces the alternative metric of mismodel. The concept is designed to offer a simplified approach to understanding and evaluating the quality of descriptions or models in practical applications, particularly in situations where no representation of the entity under investigation is available. Based on the idea that descriptions can function as representations, mismodel provides a practical assessment of how well a description or model captures the essential features of an entity while avoiding unnecessary redundancy. The properties of mismodel, and its relation to miscoding and inaccuracy, are also presented.

\item \emph{Chapter \ref{chap:Nescience} Nescience} serves as the core of the book, presenting the mathematical foundations of the theory. It defines science as a nonlinear multiobjective optimization problem in which the conflicting metrics of miscoding, inaccuracy, and surfeit are minimized simultaneously. A new metric, nescience, is introduced as a function of these three components. The chapter also explores key properties of this metric, including its evolution over time, the concept of perfect knowledge (zero nescience), and methods for identifying our current best model. In addition, it introduces a definition for the frontier of human knowledge and offers a characterization of what lies beyond that boundary.

\item \emph{Chapter \ref{chap:Interesting-Research-Questions} Interesting Questions} presents a methodology for identifying new research ideas, based on combinatorics and computational creativity, and focusing on how to address challenging open problems. It introduces two new metrics to measure a topic's relevance and its applicability to existing problems, and examines the properties of these metrics. The chapter also outlines a systematic approach to uncovering what lies hidden in the unknown unknown, illustrating how previously unrecognized research directions may be revealed.

\end{itemize}

\bigskip

\emph{PART II Applications} presents a collection of practical uses of the concept of nescience in areas such as machine learning, the philosophy of science, and the discovery of new research topics. The included examples have been selected to illustrate the broad applicability of the theory, spanning from abstract research questions to more tangible problems grounded in datasets.

\begin{itemize}

\item \emph{Chapter \ref{chap:Machine-Learning} Machine Learning} explores how the concept of nescience can be applied to entities represented by collections of measured samples. We introduce mnplib, a software library that can be used to analyze datasets, select relevant features, identify optimal model hyperparameters, and compute the errors of trained models. In addition, the chapter presents novel machine learning algorithms, including an innovative method for deriving optimal decision trees and for the automated construction of machine learning models.

\item \emph{Chapter \ref{chap:philosophy-science} Analysis of Science} investigates how well we understand current research topics by applying the proposed metrics. Our aim is to assess the degree of understanding across different areas of science. To this end, we compare research topics within the same academic discipline, as well as across multiple disciplines. The chapter also addresses major open questions in the philosophy of science, including the demarcation problem (how to distinguish science from pseudoscience) and the nature of scientific progress.

\item \emph{Chapter \ref{chap:computational-creativity} The Discovery of the Unknown} demonstrates the practical application of the theory of nescience for identifying promising research questions. Specifically, we show how nescience can be leveraged to generate new research ideas aimed at solving the most difficult open problems. We also propose a methodology for identifying new research topics—that is, for uncovering what lies hidden in the unknown unknown. Multiple examples of such research questions and novel research areas are provided.

\end{itemize}

\bigskip

\emph{PART III Mathematical Prerequisites}  introduces the mathematical foundations necessary to quantify our lack of knowledge about a research topic and to assess the randomness of a string. Its primary aim is to establish consistent notation, formally define key concepts, and present important theoretical results. While no prior expertise is required to follow the material, readers are encouraged to consult the standard references provided at the end of each chapter for deeper understanding. Additional mathematical elements are discussed in the appendices.

\begin{itemize}

\item \emph{Chapter \ref{chap:Discrete_Mathematics} Discrete Mathematics}  offers a summary of the fundamentals of discrete mathematics needed to understand the more advanced topics discussed in the book. This chapter serves as a quick review of these concepts without providing formal definitions or proofs. Topics covered include sets, relations, strings, graphs, and counting methods. A section on linear algebra (matrices and vectors) is also included.

\item \emph{Chapter \ref{chap:Probability Theory} Discrete Probability} introduces the foundational concepts of probability related to discrete events. Topics covered include conditional probability, random variables, distribution characterization, common distributions, and large random samples. This chapter aims to equip readers with the necessary background in probability to understand the more advanced statistical learning discussed later in the book.

\item \emph{Chapter \ref{chap:Computability} Computability} presents a formal definition of the concept of algorithm. It introduces the idea of a universal Turing machine and shows that certain well-defined mathematical problems cannot be solved by computers. The chapter also examines the essential tools of oracle Turing machines and Turing reducibility. Key results in computational complexity, relevant to later chapters, are briefly reviewed.

\item \emph{Chapter \ref{chap:Coding} Coding} explores how codes function and how they enable us to compress text by eliminating redundant patterns without losing essential information. It shows that there is a limit to how much text can be compressed using this technique, and that this limit is determined by the entropy of the source. The relationship between optimal codes and discrete probabilities is also discussed.

\item \emph{Chapter \ref{chap:Algorithmic_Information} Complexity} introduces an absolute metric known as Kolmogorov complexity, which measures the amount of information contained in a string by calculating the length of the shortest computer program that can produce it. The chapter studies the properties of this metric in detail and explores the relationship between string complexity and randomness.

\item \emph{Chapter \ref{ch:Learning} Learning} offers a concise overview of the field of statistical learning, presenting key results from statistical inference and machine learning. It also examines the relationship between codes and probabilities, focusing on practical approaches that apply the concept of minimum string length. Additionally, the chapter introduces the concepts and notation associated with nonlinear multiobjective optimization problems.

\item \emph{Chapter \ref{chap:Philosophy} Philosophy of Science} provides a brief introduction to the field from a philosophical perspective. It reviews key concepts such as scientific representations, models, and theories, and identifies the essential components that any formal theory of science should include. The chapter also offers an overview of the current state of the scientific method.

\end{itemize}

\bigskip

Finally, the Appendices provide additional information that complements the content of the book.

\begin{itemize}

\item \emph{Appendix \ref{apx:Properties-Nescience} Research Agenda} contains a collection of all those elements of the theory of nescience that are still under heavy development. Some of these elements are more advanced than others, but all of them are insufficilently mature to be included in the main corpus of this book. They are also presented here as an invitation to those interested readers to contribute to their development.

\item \emph{Appendix \ref{apx:math} Advanced Mathematics} offers a set of in-depth analyses that support the results presented in the preceding chapters. While these analyses are necessary to validate our findings, their inclusion in the main text would have disrupted the flow of the narrative. For this reason, they have been grouped together in this appendix.

Finally, \emph{Appendix \ref{apx:photos} About the Photos} explains the origin and intended meaning of the carefully selected photographs featured at the beginning of each chapter.

\end{itemize}

%
% Section: Acknowledgements
%

\section*{Acknowledgements}

I would like to express my gratitude to everyone who has contributed their comments and ideas to the development of the theory of nescience. In particular, I am grateful to Antonio Fernández, Vincenzo Mancuso, and Paolo Casari, who believed in and supported this project from its very beginning when it was merely a far-fetched idea (although it may still be). Others who have provided contributions and valuable feedback include Héctor Cordobés, Luis F. Chiroque, Agustín Santos, Marco Ajmone, Pablo Rojo, Manuel Cebrián, Andrés Ortega, Emilio Amaya, Mattis Choummanivong, Alexander Lynch, Andrés Carrillo, and Simon Bihoreau. The \texttt{mnplib} library described in Chapter \ref{chap:Machine-Learning} has been partially funded by the IMDEA Networks Institute, the European Union's Horizon 2020 research and innovation programme under grant agreement No 732667 RECAP, and Nokia Spain through the project NetPredict.

I would like to express my sincere gratitude to the open source community. This book would not have been possible without the extensive use of open source tools, which provided both the technical foundation and the flexibility required throughout its development. From the writing process, carried out using \TeX{} and \LaTeX{}, to the data analysis and machine learning experiments—powered by libraries such as \texttt{scikit-learn}, \texttt{statsmodels}, \texttt{pandas}, \texttt{NumPy}, and \texttt{Matplotlib}, the contributions of countless developers and researchers who share their work openly have been indispensable. Their dedication to building and maintaining high-quality, freely available software is a testament to the collaborative spirit of scientific progress.

I would also like to acknowledge the role of ChatGPT in the preparation of this book. As an AI assistant, ChatGPT provided valuable support throughout the writing process, helping to refine ideas, clarify language, structure arguments, and review technical content. While all decisions and final content were ultimately my own, the ability to engage in thoughtful dialogue, receive constructive feedback, and explore alternative phrasings and formulations greatly enhanced the clarity and coherence of the work. I am grateful for this tool, which has proven to be both efficient and intellectually stimulating.

Finally, I am grateful to my parents, who gave me the opportunities they never had in life, and to my wife and three children, who give ultimate meaning to my existence.

%
% Section: Disclaimer
%

\section*{Disclaimer}

I would like to clarify that the vast majority of the ideas presented in this book are not my own. The inspiration comes from the brilliant minds of history—thinkers such as Occam, Llull, Leibniz, and Newton, as well as philosophers like Plato, Popper, Feyerabend, and Wittgenstein. I have also built upon the mathematical foundations laid by Turing, Church, Post, Shannon, Solomonoff, Chaitin, Kolmogorov, and many others. My original contribution, if any, lies in connecting some of these ideas and offering what I hope is a compelling reinterpretation of established concepts. The References section at the end of each chapter contains brief descriptions of the sources that have influenced my thinking.

Throughout the text, I use the passive voice ("it is defined") when referring to concepts whose origins I recognize, and the active voice ("we define") when I am unaware of any prior formulation.

