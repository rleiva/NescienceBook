%
% CHAPTER: Miscoding
%

\chapterimage{Escher.pdf} % Chapter heading image

\chapter{Miscoding}
\label{chap:Miscoding}

\begin{quote}
    \begin{flushright}
        \emph{All great work is the fruit of patience and perseverance,\\
            combined with tenacious concentration on a subject\\
            over a period of months or years.}\\
        Santiago Ram√≥n y Cajal
    \end{flushright}
\end{quote}
\bigskip

In many areas of science, the entities we aim to study (the set $\mathcal{E}$) often include abstract concepts or complex phenomena that are difficult to investigate directly. These may be ideas or processes that resist straightforward description or modeling. To gain insight into such entities, we must often rely on indirect methods. As discussed in the previous chapter, the theory of nescience suggests using representations, that is, sequences of symbols, rather than attempting to interact directly with the entities themselves.

However, this approach introduces its own challenges. Because our understanding of the elements in $\mathcal{E}$ is incomplete (otherwise, further research would be unnecessary), the representations we construct are typically imperfect, they lack the completeness and precision we would ideally desire. These imperfections can lead to significant problems: inaccuracies in representation can propagate into the models derived from them, potentially distorting our interpretation and understanding. It is therefore essential to recognize this source of error and to carefully consider its implications.

To address this issue, we introduce the concept of \emph{miscoding}, a measure used to quantify the error that arises from misrepresenting or inaccurately encoding entities. Miscoding is defined in terms of the length of the shortest computer program capable of transforming an incorrect representation into a correct one. In essence, it measures the amount of effort, as reflected by the program's length, required to correct a faulty representation.

However, there is a significant complication: applying this idea in practice is not straightforward, since the perfect representations of entities are unknown. As a result, we cannot directly measure the gap between a given representation and an ideal one. Nevertheless, we propose a theoretical framework based on the oracle machine (an abstract construct) used to define the set $\mathcal{E}$. This oracle machine is assumed to be capable of recognizing valid representations for all entities in the set. It is important to note, however, the limitations of this approach; for instance, we cannot query the oracle about a specific entity unless we already possess a valid representation of it.

Getting a better grasp on scientific representation and the challenges in reducing miscoding could really push forward scientific research, helping us create better, more thorough models of the natural world. In this chapter, we are going to properly introduce the idea of miscoding and look into its various characteristics. We will examine how miscoding behaves when it comes to combined representations and discuss methods to reduce miscoding. We will delve into the idea that there are strings that do not represent any entity. And we will dig into why miscoding is important in different research areas and talk about its potential to open up new lines of inquiry.

Gaining a deeper understanding of scientific representation and the difficulties involved in reducing miscoding can significantly advance scientific research, enabling the development of more accurate and comprehensive models of the natural world. In this chapter, we formally introduce the concept of \emph{miscoding} and explore its key properties. We will analyze how miscoding behaves in the context of combined representations and consider strategies for reducing it. We will also examine the notion that some strings fail to represent any entity and investigate the implications of this idea. Finally, we will highlight the relevance of miscoding across various research domains and discuss its potential to inspire new lines of inquiry.

%
% Section: Miscoding
%
\section{Miscoding}
\label{sec:miscoding}

In an ideal scenario, we would ask the oracle to determine how far a particular string $r$ is from perfectly encoding an entity $e$. This, however, presents a complication: we can only refer to entity $e$ through a valid representation in the set $\mathcal{R}^\star_e$. Unfortunately, we typically do not have access to these perfect representations and, therefore, cannot use them in our query.

To overcome this limitation, we propose an alternative approach. Rather than asking the oracle to assess the discrepancy between our current representation $r$ and a valid representation of the specific entity $e$, we instead ask the oracle to identify the smallest distance between $r$ and all valid representations of all entities in the set $\mathcal{E}$, that is, the elements of $\mathcal{R}^\star_\mathcal{E}$. As discussed in detail in Section \ref{sec:invalid_representations}, this type of query can, in principle, be handled by the oracle.

\begin{definition} [Miscoding]\index{Miscoding}
\label{def:miscoding}
Let $r \in \mathcal{B}^\ast$ be a representation. We define the \emph{miscoding} of $r$, denoted by $\mu(r)$, as:
\[
\mu(r) = \overset{o}{ \underset{ r^\star_e \in \mathcal{R}^\star_\mathcal{E} } \min} \frac{ \max\{ K \left( r \mid r^\star_e \right), K \left( r^\star_e \mid r \right) \} } { \max\{ K \left( r \right), K \left( r^\star_e \right) \} }
\]
where $\overset{o}{\min}$ indicates that the minimum is to be computed by an oracle.
\end{definition}

Intuitively, our lack of knowledge about an entity is reflected in a higher miscoding value of its current representation. Conversely, a deeper understanding of the entity should lead to an encoding that is closer to a valid representation, and thus exhibits lower miscoding.

Miscoding is computed using a bidirectional approach: we require the oracle to determine both the length of the shortest computer program that can generate the valid representation $r^\star_e$ from our current representation $r$ (i.e., $K \left( r^\star_e \mid r \right)$), and the length of the shortest program that can generate $r$ from $r^\star_e$ (i.e., $K \left( r \mid r^\star_e \right)$). This bidirectionality captures the maximum difficulty of transforming one representation into the other. A high-quality representation should allow for an easy reconstruction of the correct representation and vice versa, implying that both of these conditional complexities are low. In other words, an ideal representation contains all the information needed to recover the correct encoding of the entity, without introducing any erroneous or irrelevant symbols.

While miscoding concerns whether the symbols in a representation are relevant, that is, whether they correctly refer to the intended entity, it is not concerned with how many symbols are used. In contrast, surfeit (as discussed in Chapter \ref{chap:Redundancy}) focuses on whether the symbols are essential, aiming to minimize the number of unnecessary or redundant symbols. In this sense, miscoding relates to the correctness of the content, while surfeit relates to the efficiency of its expression. Although both concepts address flaws in representation, they capture fundamentally different types of representational inefficiency.

Our definition of miscoding is formulated as a relative measure rather than an absolute one. Instead of providing an isolated score for a single representation, it quantifies how far a representation is from the nearest valid representation, normalized by their respective lengths. This relative formulation allows us to meaningfully compare the miscoding of different representations of the same entity, and also to compare the miscoding values across representations of different entities, regardless of their size or complexity.

The miscoding value of a representation $r$ always lies within the interval $[0, 1]$.

\begin{proposition}
\label{prop:range_miscoding}
For all $r \in \mathcal{B}^\ast$, it holds that $0 \leq \mu(r) \leq 1$.
\end{proposition}
\begin{proof}
This follows directly from the inequality $0 \leq \frac{ \max\{ K(x \mid y), K(y \mid x) \} }{ \max\{ K(x), K(y) \} } \leq 1$ which holds for all $x, y \in \mathcal{B}^\ast$, as stated in Proposition \ref{prop:ncd_between_zero_and_one}.
\end{proof}

Miscoding is zero if, and only if, the representation $r$ is a valid representation of some entity $e$.

\begin{proposition}
\label{prop:perfect_encoding}
Given a representation $r \in \mathcal{B}^\ast$, we have $\mu(r) = 0$ if, and only if, $r \in \mathcal{R}^\star_\mathcal{E}$.
\end{proposition}
\begin{proof}
If $r \in \mathcal{R}^\star_\mathcal{E}$, then there exists an entity $e \in \mathcal{E}$ such that $r = r^\star_e$. In this case, $K \left( r \mid r^\star_e \right) = 0$, and thus $\mu(r) = 0$.

Conversely, if $\mu(r) = 0$, then there must exist some $r^\star_e \in \mathcal{R}^\star_\mathcal{E}$ such that $K \left( r \mid r^\star_e \right) = 0$ and $K \left( r^\star_e \mid r \right) = 0$, which implies that $r = r^\star_e$, and hence $r \in \mathcal{R}^\star_\mathcal{E}$.
\end{proof}

According to Proposition \ref{prop:perfect_encoding}, a miscoding value of zero implies that $r$ perfectly encodes some entity $e$. However, identifying the exact entity that $r$ represents remains a challenge. While scientific intuition may offer plausible hypotheses about the encoded entity, such guesses cannot be confirmed mathematically. Moreover, as scientific understanding evolves, our interpretation of what $r$ encodes may also change over time (see Example \ref{ex:polywater}).

It has been observed that an entity $e \in \mathcal{E}$ may possess multiple valid representations, as captured by the set $\mathcal{R}^\star_e$. Fortunately, the value of miscoding is invariant under the choice of valid representation (see the discussion on style in Section \ref{sec:scientific_representation}).

\begin{proposition}
For any valid representation $r^\ast_e \in \mathcal{R}^\star_\mathcal{E}$, it holds that $\mu\left( r^\star_e \right) \leq \mu\left( r \right)$ for all $r \in \mathcal{B}^\star$.
\end{proposition}
\begin{proof}
This follows from the fact that $\mu\left( r^\star_e \right) = 0$ and $\mu\left( r \right) \geq 0$ for all $r \in \mathcal{B}^\star$.
\end{proof}

For a given entity $e$, all valid representations in the set $\mathcal{R}^\star_e$ are equally adequate with respect to miscoding, as each yields a miscoding value of $0$. From a practical standpoint, however, the most suitable representation is the one that best facilitates the discovery of new knowledge about the entity‚Äîspecifically, the representation that most effectively supports the construction of explanatory models.

%
% Section: Miscoding of Joint Representations
%

\section{Joint Miscoding}
\label{sec:joint_miscoding}

Section \ref{sec:descriptions_joint_topic} introduced the notion of a \emph{joint representation}\index{Joint representation}, which arises when two representations $s, t \in \mathcal{B}^\ast$ are concatenated to form a new string $st$. This section explores the properties of miscoding as they apply to such joint representations.

Since the concatenated string $st$ is itself a valid representation, it is not necessary to introduce a separate
definition of miscoding for joint representations. The miscoding of the joint representation is given by:
\[
\mu(st) = \overset{o}{ \underset{ r^\star_e \in \mathcal{R}^\star_\mathcal{E} } \min} \frac{ \max\{ K \left( st \mid r^\star_e \right), K \left( r^\star_e \mid st \right) \} } { \max\{ K \left( st \right), K \left( r^\star_e \right) \} }
\]
Consistent with Proposition \ref{prop:range_miscoding}, the miscoding of a joint representation is a value between $0$ and $1$, i.e., $0 \leq \mu(st) \leq 1$.

It is important to note that supplementing an incomplete representation, that is, one with a positive miscoding value, with additional symbols does not necessarily lead to a reduction in miscoding. This is because the added symbols may introduce irrelevant or incorrect information. Conversely, miscoding does not necessarily increase either, since incorporating relevant and accurate symbols can reduce the miscoding of an incomplete representation.

From a formal perspective, given two arbitrary representations $s, t \in \mathcal{B}^\ast$, there is no guarantee that any of the following inequalities will always hold: $\mu(ts) \geq \mu(t)$, $\mu(ts) \leq \mu(t)$, $\mu(ts) \geq \mu(s)$, or $\mu(ts) \leq \mu(s)$.

\begin{example}
Consider the text $r$ of a biology research article that succinctly and accurately describes a newly discovered specimen, resulting in a low miscoding value $\mu(r)$. However, when additional text $s$, taken from a completely unrelated article about a second specimen from a different species, is appended, the resulting concatenated representation $rs$ muddles the original focus. This inclusion of unrelated content increases the miscoding value to $\mu(rs)$, illustrating a case in which $\mu(rs) \geq \mu(r)$. Although the added text is scientifically valid on its own, it dilutes the clarity and precision of the original article, thereby increasing its miscoding.

Conversely, in a second scenario, consider another research article $r'$ that exhibits a relatively high miscoding value $\mu(r')$, due to an incomplete description of the specimen. If this article is supplemented with additional text $s'$, containing essential information previously omitted, the resulting concatenated representation $r's'$ becomes significantly more informative and coherent. As a result, the miscoding value decreases, demonstrating a case where $\mu(r's') \leq \mu(r')$. This highlights that enriching an incomplete representation with relevant and focused content can yield a more accurate and lower-miscoding representation.
\end{example}

Furthermore, it should not be assumed that the miscoding of a joint representation is less than or equal to the sum of the miscodings of the individual representations, i.e., $\mu(st) \leq \mu(s) + \mu(t)$. This inequality does not necessarily hold, even when both $s$ and $t$ encode the same entity. The reason is that the joint representation \$st\$ may end up encoding an entirely different entity from those represented by $s$ and $t$ individually.

\begin{example}
In a medical research context, representation $r$ describes a new drug compound $A$ for treating a specific type of cancer, while representation $s$ outlines a genetic mutation $B$ associated with that cancer type. Both $r$ and $s$ have low miscoding values, denoting accurate, focused content. However, when concatenated, the combined representation $rs$ unintentionally suggests a third entity $C$, implying a causal relationship between $A$ and $B$. This unintended implication stems from the mixture of distinct information, leading to a higher miscoding value. In this instance, each of $r$, $s$, and $rs$ essentially represents different research entities. $r$ and $s$ are clear in their individual contexts, but $rs$ is ambiguous, exemplifying a case where concatenated information can inadvertently create a representation of an entirely different, unintended entity, thus increasing miscoding.
\end{example}

Given the non-commutative nature of joining two representations, it is not guaranteed that $\mu(ts) = \mu(st)$. This is because the composite strings $ts$ and $st$ may encode entirely different entities. This property holds true even when we restrict our attention to valid representations of a specific entity $e$. For example, if $r^\star_e, s^\star_e \in \mathcal{R}^\star_{e}$ are two valid representations of the entity $e$, there is no assurance that the concatenated string $r^\star_e s^\star_e$ will itself be a valid representation of $e$.

\begin{example}
In environmental science, representation $r$ thoroughly examines microplastics, their nature and harmful impacts on marine ecosystems, while representation $s$ focuses on specific technologies and methodologies for detecting these pollutants in water. The concatenation $rs$ presents a logical progression: first describing the pollutant and its effects, then outlining detection methods. This creates a coherent representation of a broader entity, one concerned with the pollutant, its impact, and how to detect it, an entity which may not yet be fully understood, hence yielding a higher miscoding value.

Conversely, the concatenation $sr$ begins with technical methodologies for detection and then provides the contextual background on microplastics and their environmental effects. This ordering may be more familiar within a methodological framework and results in a more coherent and well-understood entity, yielding a lower miscoding value.

In this particular case, we observe that $\mu(rs) > \mu(sr)$.
\end{example}

The concept of miscoding can be naturally extended to joint representations formed from any finite collection of representations. Let $r_1, r_2, \ldots, r_n \in \mathcal{B}^\ast$ be a finite collection of representations. The miscoding of their concatenation, denoted by $r_1 r_2 \ldots r_n$, is defined as:
\[
\mu(r_1 r_2 \ldots r_n) = \overset{o}{ \underset{ r^\star_e \in \mathcal{R}^\star_\mathcal{E} } \min} \frac{ \max\{ K \left( r_1 r_2 \ldots r_n \mid r^\star_e \right), K \left( r^\star_e \mid r_1 r_2 \ldots r_n \right) \} } { \max\{ K \left( r_1 r_2 \ldots r_n \right), K \left( r^\star_e \right) \} }
\]
As in the case of concatenating two representations, the miscoding of a joint representation composed of \$n\$ elements remains bounded within the unit interval $0 \leq \mu(r_1 r_2 \ldots r_n) \leq 1$. However, several caveats must be noted. There is no guarantee that $\mu(r_1 r_2 \ldots r_n) \leq \mu(r_i) \quad \text{or} \quad \mu(r_1 r_2 \ldots r_n) \geq \mu(r_i)$ for any $i = 1, \ldots, n$. Moreover, the miscoding of the joint representation is not necessarily less than or equal to the sum of the individual miscodings $\mu(r_1 r_2 \ldots r_n) \nleq \mu(r_1) + \mu(r_2) + \cdots + \mu(r_n)$. Finally, no general conclusions can be drawn regarding how the miscoding of a joint representation is affected by permutations of its components. That is, reordering the representations may increase, decrease, or leave unchanged the overall miscoding.

%
% Section: Decreasing Miscoding
%

\section{Decreasing Miscoding}

A valid representation of an entity refers to a string that encapsulates all the vital information needed by the oracle to reproduce the given entity, and solely that information. Conversely, an invalid representation‚Äîsignified by a miscoding exceeding zero‚Äîmay stem from either a lack of critical information, the presence of incorrect symbols, or the inclusion of irrelevant symbols. To decrease the miscoding of a representation, one can supplement missing information or eliminate incorrect or non-pertinent symbols. Determining in advance whether any information is absent or if certain symbols require removal is not possible. Nonetheless, as the ensuing theorem demonstrates, one of these scenarios must inevitably be true.

\begin{theorem}
\label{th:reduce_miscoding}
Let $r \in \mathcal{B}^\ast$ be a representation such that $\mu(r) >0$, then one or both of the following conditions must hold:
\begin{enumerate}[label=(\roman*)]
\item There exists a $s \in \mathcal{B}^\ast$ such that $\mu(rs) < \mu(r)$ or $\mu(sr) < \mu(r)$,
\item There exists an $s \in \mathcal{B}^\ast$ in the form $r = \alpha s \beta$ with $\alpha, \beta \in \mathcal{B}^\ast$ such that $\mu(s) < \mu(r)$.
\end{enumerate}
\end{theorem}
\begin{proof}
{\color{red} To be completed}
Assuming that $\mu(r) >0$, we find that
\[
\overset{o}{ \underset{ r^\star_e \in \mathcal{R}^\star_\mathcal{E} } \min} \frac{ \max\{ K \left( r \mid r^\star_e \right), K \left( r^\star_e \mid r \right) \} } { \max\{ K \left( r \right), K \left( r^\star_e \right) \} } > 0
\]
Let $r^\star_e = \text{arg}\,\min \left( \mu(r) \right)$. Hence, $\max\{ K \left( r \mid r^\star_e \right), K \left( r^\star_e \mid r \right) \} > 0$. If $K \left( r \mid r^\star_e \right) > 0$, it indicates that $r$ includes non-relevant symbols. Conversely, if $K \left( r^\star_e \mid r \right) > 0$, it implies that $r$ omits some relevant symbols.
\end{proof}

\begin{example}
\label{ex:lung_cancer}
Suppose that the research entity $e$ in which we are interested is the causes of lung cancer. In order to understand this entity, we have measured a collection of risk factors in a random sample of the population (smooking, exercise, diet, age, etc.). However, due to a problem with the sampling procedure, all the samples correspond to a subset of the population, for example, males. This dataset would be a representation $s$ for our entity $e$, but a very bad one, since it is strongly biased. If we have a second representation, corresponding the sample data of females $t$, the joint representation $st$ will be a better one that any of them, $s$ or $t$, isolated.
\end{example}

Next example describes a case in which removing some symbols from a representation can decrease its miscoding.

\begin{example}
A historian compiles representation $r$, aiming to narrate the events surrounding the signing of a pivotal treaty. However, the inclusion of speculative statements and personal interpretations about the involved parties‚Äô intentions, not backed by primary sources, leads to a high miscoding value. The document, while rich in information, is clouded by content that is erroneous, making it an invalid representation of the historical event. By removing these speculative and unverified segments, a refined version $r‚Äô$ emerges, offering a concise, factual account based solely on verifiable data and primary sources. This refinement leads to a decrease in the miscoding value, transforming $r‚Äô$ into a more valid representation that accurately reflects the historical event without the noise of uncorroborated interpretations.
\end{example}

%
% Section: Targetless Representations
%

\section{Targetless Representations}
\label{sec:targetless_representations}

In the most extreme scenario, the miscoding value could escalate to its maximum limit of 1. This situation transpires when our prevailing representation $r$ does not contain a single symbol that corresponds to the encoding of any entity within the set of entities $\mathcal{E}$. In this case, $r$ would be a targetless representation\index{Targetless representation}, an abstract construct without a concrete or meaningful interpretation. We could assign ramdomly the targetless representations to an entity, but that would violate the highly desirable property of subgetive reasoning.

Next proposition formalices this idea.

\begin{proposition}
\label{prop:miscoding_upper_bound}
Given a representation $r \in \mathcal{B}^\ast$, the miscoding $\mu(r)$ reaches its maximum value of 1 if and only if there is no symbol in $r$ that contributes to the encoding of any of the entities of $\mathcal{E}$.
\end{proposition}
\begin{proof}
Assume that $r$ does not contain any symbol that contributes to the encoding of $e$. Let $r^\star_e$ be any valid representation of $e$. Then the shortest program capable of generating $r^\star_e$ from $r$ would need to append every symbol in $r^\star_e$ to $r$, effectively resulting in $r^\star_e$. Hence, $K(r^\star_e | r) = K(r^\star_e)$, indicating no symbolic overlap between $r$ and $r^\star_e$.

Following the definition of miscoding, we have $\mu(r) = \max{ K(r | r^\star_e), K(r^\star_e | r) } / \max{K(r), K(r^\star_e)}$. Because $K(r | r^\star_e) = K(r)$ and $K(r^\star_e | r) = K(r^\star_e)$, we get $\mu(r) = 1$, assuming that $K(r) \neq 0$.

The converse also holds. If $\mu(r) = 1$, this means that there's no information in $r$ that assists in generating $r^\star_e$ or vice versa, which implies that $r$ does not contain any symbol that contributes to the encoding of $e$.
\end{proof}

For every finite or countable infinite set of entities $\mathcal{E}$, there exists a infinite number of targetless represention. We will prove this property using a constructive method. That is, we will prove that there exists at least one targetless representation and define a method to construct more targetless representations given the original one.

\begin{proposition}
For every finite or countably infinite set of entities $\mathcal{E}$, there exists an uncountably infinite set of targetless representations.
\end{proposition}
\begin{proof}
Let $\mathcal{R}$ denote the set of all possible representations for entities in $\mathcal{E}$, such that for each entity $e \in \mathcal{E}$, there exists a unique representation $r \in \mathcal{R}$ and vice versa. Since $\mathcal{E}$ is finite or countably infinite, so is $\mathcal{R}$.

Consider the set $\mathcal{B}^\ast$ of all possible binary strings of finite length. This set is uncountably infinite, because it includes all possible sequences of two symbols ('0' and '1') of finite length.

Since $\mathcal{R}$ is countable (either finite or countably infinite), and $\mathcal{B}^\ast$ is uncountably infinite, there must exist some strings in $\mathcal{B}^\ast$ that are not in $\mathcal{R}$. We can select any such string and call it $r_0$. By definition, $r_0$ is a targetless representation, as it does not correspond to any entity in $\mathcal{E}$.

Given a targetless representation $r_i$, we can construct a new targetless representation $r_{i+1}$ by appending either a '0' or a '1' to $r_i$. Since $r_i$ does not correspond to any entity in $\mathcal{E}$, $r_{i+1}$, being a lengthened version of $r_i$, also cannot correspond to any entity in $\mathcal{E}$. Therefore, $r_{i+1}$ is also a targetless representation.

By repeating this process, we can construct an infinite sequence of targetless representations $\{r_0, r_1, r_2, \ldots\}$, demonstrating that there exists an uncountably infinite set of targetless representations for any finite or countably infinite set of entities $\mathcal{E}$. 
\end{proof}

What it is a targetless representation for an oracle is not necesarily a target representation for another oracle, as next example shows.

\begin{example}
Imagine two machines, A and B, each controlling a robotic arm adept at crafting nuts and bolts. Machine A operates on a low-level assembly language, while Machine B utilizes a more sophisticated high-level programming language. Consequently, a particular set of instructions that proves inadequate and fails to yield a finished product with Machine A could be perfectly executed by Machine B, resulting in a completed bolt.
\end{example}

The normalized compression distance between a targetless representation and the closest non-targetless representation might be less that one, meaning that the target-less representation contains some information about the non-targetless one. However, this is not sufficient to guarantee scientific progress, given the size of the Turing machine needed to benefit from this knowledge.

%
% Section: Miscoding of Areas
%
\section{Miscoding of Areas}
\label{sec:miscoding_areas}

The concept of miscoding can be extended to research areas in order to quantitative measure the amount of effort required to fix an inaccurate representation of an area. Unfortunately, as we have discussed in Section \ref{sec:areas}, there is no way to check if the strings included in a $n$-fold representation correspond to entities of that area, or to avoid the fact there may be instances where some of these strings represent the same entity.

Let's consider the strings $r_1, r_2, \ldots, r_n$, where each $r_i \in \mathcal{B}^\ast$ for $i=1, 2, \ldots, n$. Recall that when we write $r_1 r_2 \ldots r_n$, we refer to the concatenation of these strings. This operation could potentially meld the individual strings in such a way that they cannot be separated back into their original components. Conversely, by $\langle r_1, r_2, \ldots, r_n \rangle$ we denote a re-encoding of the individual strings $r_i$ into a single string, but with the provision that it retains the ability to decompose into the original strings. Moreover, the joint representation $r_1 r_2 \ldots r_n$ encodes a single entity, while the $n$-folded representation $\langle r_1, r_2, \ldots, r_n \rangle$ might encode to up to $n$ distinct entities.

The following defintion extend the concept of miscoding to $n$-fold representations.

\begin{definition}
Let $R = \left( r_1, r_2, \ldots, r_n \right) \in \mathcal{B}^\ast \times \mathcal{B}^\ast \times \overset{n} \ldots \times \mathcal{B}^\ast$  be an $n$-fold representation. We define the \emph{miscoding} of $R$, denoted by $\mu(R)$, as:
\[
\mu(R) = \overset{o}{ \underset{ (r^\star_{e_1}, \ldots, r^\star_{e_n}) \in \mathcal{R}^\star_\mathcal{E} \times \overset{n} \ldots \times \mathcal{R}^\star_\mathcal{E} } \min} \frac{ \max\{ K \left( \langle r_1, \ldots, r_n \rangle \mid \langle r^\star_{e_1}, \ldots, r^\star_{e_n} \rangle \right), K \left( \langle  r^\star_{e_1}, \ldots, r^\star_{e_n} \rangle \mid \langle r_1, \ldots, r_n \rangle \right) \} } { \max\{ K \left( \langle r_1, \ldots, r_n \rangle \right), K \left( \langle r^\star_{e_1}, \ldots, r^\star_{e_n} \rangle \right) \} }
\]
where $\overset{o}{\min}$ denotes that the minimum has to be computed by an oracle.
\end{definition}

The miscoding of the representation of an area falls within the range of $0$ and $1$, as illustrated by the following proposition.

\begin{proposition}
\label{prop:inaccuracy:inaccuracy:range}
For all known subsets $R = \left( r_1, r_2, \ldots, r_n \right) \in \mathcal{B}^\ast \times \mathcal{B}^\ast \times \overset{n} \ldots \times \mathcal{B}^\ast$, we have that $0 \leq \mu(R) \leq 1$.
\end{proposition}
\begin{proof}
Given that $\langle r_1, r_2, \ldots, r_n \rangle$ is a string and Proposition \ref{prop:ncd_between_zero_and_one}.
\end{proof}

By extending the concept of miscoding to encompass areas, we can quantitatively evaluate the quality of representations for specific subsets of entities. This mathematical framework offers a robust tool to assess and rectify inaccuracies in both individual entities and broader research areas.


%
% Section: References
%

\section*{References}

Misrepresentation or inaccuracies in scientific representation carry substantial implications for scientific discovery, technological advancement, policymaking, among others. However, no book or paper explicitly addresses the subject of "incorrect representations in science," from the perspective adopted in this book, in which we dissect the issue of scientific representation into two complementary subproblems: representation of entities and description of representations. Despite the absence of a direct focus, a variety of researchers have ventured into this domain indirectly. Their discussions often touch on concerns such as scientific fraud, the replication crisis, and the usage of incorrect models, to name a few. 

