%
% CHAPTER 7.- Interesting Questions
%

\chapterimage{thinker.pdf}

\chapter{Interesting Questions}
\label{chap:Interesting-Research-Questions}

\begin{quote}
\begin{flushright}
\emph{It is not the answer that enlightens,\\
but the question. \\}
Eugène Ionesco
\end{flushright}
\end{quote}
\bigskip

In this chapter, we introduce a set of metrics for classifying research topics according to their potential to generate interesting problems, along with a methodology for the assisted discovery of new research questions. The objective is to propose new directions, novel research ideas, that contribute to reducing nescience, that is, to diminishing the extent of the scientific unknown. The proposed methodology supports both the identification of new applications for existing tools to address open problems (the known unknown\index{Known unknown}) and the discovery of entirely new and previously unexplored research directions (the unknown unknown\index{Unknown unknown}). While the methodology is applicable to both intradisciplinary and interdisciplinary topics, the most impactful results typically arise in the latter case. In Chapter \ref{chap:computational-creativity}, we demonstrate the methodology in practice and propose several new questions and research topics.

We have already examined three dimensions for classifying research topics: miscoding (Chapter \ref{chap:Miscoding}), inaccuracy (Chapter \ref{chap:Error}), and surfeit (Chapter \ref{chap:Redundancy}). These metrics allow us to quantitatively assess our level of understanding of a topic, a breoader concept we refer to as nescience. In this section, we introduce two additional metrics for characterizing topics: relevance (Section \ref{sec:relevance}) and applicability (Section \ref{sec:applicability}). Relevance measures the impact a topic has on people's lives and complements the existing dimensions used to quantify nescience. Applicability quantifies how frequently a topic has been applied in other domains and helps identify new uses for existing technologies.

What is proposed in this chapter is an algebraic approach to the assisted discovery of potentially interesting research questions, grounded in the theory of nescience. On the one hand, it aims to support researchers in their day-to-day work. The methodology can be used to uncover novel tools that may be applied to a given problem, or to identify new problems where existing tools could be effectively used. In its more advanced form, the methodology facilitates the exploration of the unknown unknown, that is, research areas that have not yet been conceptualized, described, or even imagined.

On the other hand, because the methodology is based on well-defined mathematical principles, it lends itself to automation. This opens the door for artificial intelligence systems to move beyond their current limitations in autonomously generate truly novel research directions. By formalizing the process of question discovery, the methodology enables AI to propose interesting and previously unexplored research questions, and even to discover entirely new topics of scientific inquiry.

%
% Integrative Depth
%

\section{Integrative Depth}
\label{sec:integrative_depth}

In addition of the metrics that compose nescience, further metrics are required in order to characterize the role that different research topics play within the scientific knowledge. Such metrics are useful not only for classifying individual topics, but also for identifying promising directions for inquiry (Section~\ref{sec:intro_interesting_questions}), and guiding the combination of topics in the discovery of new research questions (Section~\ref{sec:New_Research_Topics}).

A new metric of \emph{integrative depth} is introduced to capture the multiplicity of nescience-reducing relation among topics. Intuitively, some research topics admit a substantial reduction of nescience by conditioning on a small number of other topics, whereas others admit reductions along many distinct directions. In the latter case, there exist multiple background knowledge bases such that conditioning on each of them yields a decrease in the nescience of the topic, even though none of these backgrounds is individually necessary. 

\begin{definition}\index{Integrative depth}
Given the nescience dependency graph $NDG = (\mathcal{T}, E_N)$ we define the \emph{integrative depth}\index{Integrative depth} of a research topic $t \in \mathcal{T}$ as its indegree in $NDG$, that is,
\[
ID(t) = indeg(t)
\]
\end{definition}

\noindent
Recall that a directed edge from B to A in the nescience dependency graph indicates that conditioning on the knowledge background associated with B reduces the nescience of A. This does not imply that such background knowledge is necessary to understand A, nor that it is the only background capable of reducing its nescience.

Integrative depth measures the extent to which understanding a research topic requires the integration of knowledge originating from other topics. A topic with low integrative depth can be substantially understood in relative isolation, whereas a topic with high integrative depth might require to understand many other independent sources of knowledge.

In practice, topics with high integrative depth often benefit from combining insights drawn from several contributing areas (see Section XXX), although the existence of multiple nescience-reducing directions does not, by itself, imply that such combination is necessary.

\begin{example}
Consider the research topic of cancer. Conditioning on knowledge from genetics reduces nescience by clarifying the role of mutations and oncogenes, while conditioning on cell biology reduces nescience by explaining mechanisms of uncontrolled proliferation. Knowledge from immunology further reduces nescience by accounting for immune surveillance and evasion, and insights from tissue mechanics and the tumor microenvironment contribute by explaining how physical and structural factors influence tumor growth. Each of these background topics independently yields a reduction in the nescience associated with cancer, even though none of them is individually necessary or sufficient to achieve a comprehensive understanding. The high integrative depth of this topic therefore reflects the existence of multiple distinct directions along which ignorance can be reduced, rather than a single required sequence of prerequisites.
\end{example}

The integrative depth metric inherits several basic properties directly from its graph-theoretic definition: \emph{i)} for any research topic $t \in \mathcal{T}$, the integrative depth $D(t)$ is a non-negative integer; \emph{ii)} a research topic $t$ has integrative depth $D(t) = 0$ if and only if there is no other topic whose representations reduce the nescience of $t$.

Topics with zero integrative depth are autonomous in the sense that their nescience cannot be reduced by conditioning on other topics alone.

Integrative depth is independent of the current level of nescience of a topic. A topic may have high integrative depth and low nescience, corresponding to a well-understood domain that nonetheless requires the integration of many different areas. Conversely, a topic may have high integrative depth and high nescience, indicating a complex, unresolved problem whose understanding depends on progress across multiple topics.

% Subsubsection: Weighted integrative depth

\subsubsection*{Weighted integrative depth}
\label{subsec:weighted_integrative_depth}

In some cases, it is not sufficient to know how many topics contribute to reducing the nescience of a given topic; it is also important to quantify \emph{how much} each contributing topic reduces nescience. For this purpose, we consider the weighted version of the nescience dependency graph.

\begin{definition}\index{Integrative depth}
Given the weighted nescience dependency graph $WNDG = (\mathcal{T}, E_N, w)$ we define the \emph{weighted integrative depth}\index{Weighted integrative depth} of a research topic $t \in \mathcal{T}$ as 
\[
D_w(t) \;=\; \sum_{A : (A,t) \in E_N} w(A,t)
\;=\; \sum_{A : (A,t) \in E_N} \bigl( N(t \mid A) - N(t) \bigr).
\]
\end{definition}

\noindent
The weighted integrative depth of a topic measures the total reduction in nescience obtained by integrating all topics that contribute to its understanding.

While integrative depth counts the number of distinct topics whose representations reduce the nescience of a given topic, weighted integrative depth captures the overall magnitude of that reduction. A topic may have a high integrative depth but a modest weighted integrative depth if each contributing topic yields only a small reduction in nescience. Conversely, a topic with moderate integrative depth may exhibit a large weighted integrative depth if a few incoming topics provide substantial explanatory power.

Weighted integrative depth therefore quantifies the \emph{strength of integration} required to understand a topic, complementing the purely structural information provided by integrative depth.

\begin{example}
Consider again the entity corresponding to \emph{climate change}. Its integrative depth is high, since many topics contribute to reducing its nescience. However, the magnitude of these contributions may vary substantially. Conditioning on atmospheric physics may yield a large reduction in nescience, while conditioning on a narrowly scoped economic model may yield a smaller one. The weighted integrative depth aggregates these heterogeneous contributions into a single measure of total epistemic gain.
\end{example}

The weighted integrative depth satisfies several immediate properties: \emph{i)} For any research topic $t \in \mathcal{T}$, the weighted integrative depth $D_w(t)$ is a non-negative real number. {\color{red} Add another property derived from graph theory.}

{\color{red}Introduce this propostion}

\begin{proposition}
A research topic $t$ has weighted integrative depth $D_w(t)=0$ if and only if it has integrative depth $D(t)=0$.
\end{proposition}
\begin{proof}
If $D(t)=0$, there are no incoming edges, and the defining sum for $D_w(t)$ is empty, yielding $D_w(t)=0$. Conversely, if $D_w(t)=0$, there can be no incoming edges with positive weight, and hence $D(t)=0$.
\end{proof}

Integrative depth and weighted integrative depth capture complementary aspects of epistemic integration. Integrative depth reflects the number of distinct sources that must be combined to reduce the nescience of a topic, while weighted integrative depth reflects the total magnitude of the reduction achieved by those sources. Together, these metrics distinguish between topics that depend on many weakly informative contributors and those that depend on a smaller number of highly informative ones.

In later chapters, weighted integrative depth will be used to refine the classification of research topics and to guide the construction of composite research directions that balance epistemic feasibility with the potential for substantial nescience reduction.

% Subsection: Normalized weighted integrative depth

\subsubsection*{Normalized weighted integrative depth}
\label{subsec:norm_weighted_integrative_depth_subset}

In many practical situations, we are not interested in the full set of research topics $\mathcal{T}$, but rather in a restricted collection $S \subseteq \mathcal{T}$ corresponding, for instance, to a discipline, a research program, or the scope of a particular organization. In this case, it is natural to evaluate integrative metrics relative to the weighted nescience dependency graph restricted to $S$.

Assume that the restriction of the weighted nescience dependency graph to a subset $S$ has been defined elsewhere in the book. We denote the resulting restricted weighted graph by
\[
G_{N,S}^w = (S, E_{N,S}, w),
\]
where $E_{N,S} \subseteq S \times S$ is the set of directed edges between topics in $S$, and each edge $(A,t)\in E_{N,S}$ satisfies $w(A,t) = N(t\mid A) - N(t) > 0$.

\begin{definition}\index{Weighted integrative depth!restricted to a subset}
Let $S \subseteq \mathcal{T}$ and let $G_{N,S}^w = (S, E_{N,S}, w)$ be the restricted weighted nescience dependency graph. The \emph{weighted integrative depth of $t$ restricted to $S$} is defined as
\[
D_{w,S}(t) \;=\; \sum_{A : (A,t) \in E_{N,S}} w(A,t),
\qquad t \in S.
\]
\end{definition}

This quantity measures the total reduction in nescience of $t$ obtained by integrating only those topics that lie within $S$.

Since the absolute scale of $D_{w,S}(t)$ depends on the size and composition of $S$, it is often useful to normalize the weighted integrative depth within $S$ so that values lie in the unit interval and are comparable across subsets.

\begin{definition}\index{Normalized weighted integrative depth on a subset}
Let $S \subseteq \mathcal{T}$ be finite. The \emph{min--max normalized weighted integrative depth on $S$} is defined for each $t \in S$ by
\[
\overline{D}_{w,S}(t)
\;=\;
\frac{D_{w,S}(t) - \min_{u \in S} D_{w,S}(u)}
{\max_{u \in S} D_{w,S}(u) - \min_{u \in S} D_{w,S}(u)}.
\]
\end{definition}

\noindent
In the degenerate case where $\max_{u \in S} D_{w,S}(u) = \min_{u \in S} D_{w,S}(u)$, all normalized values are set to $0$.

\begin{proposition}
Let $S \subseteq \mathcal{T}$ be finite. For any topic $t \in S$, the restricted weighted integrative depth satisfies $D_{w,S}(t) \ge 0$.
\end{proposition}

\begin{proof}
By construction, each edge in $E_{N,S}$ has strictly positive weight $w(A,t)>0$. Therefore, $D_{w,S}(t)$ is a sum of non-negative terms, and hence non-negative.
\end{proof}

\begin{proposition}
Let $S \subseteq \mathcal{T}$ be finite. For any topic $t \in S$, the normalized weighted integrative depth satisfies
\[
0 \le \overline{D}_{w,S}(t) \le 1.
\]
Moreover, $\overline{D}_{w,S}(t)=0$ for at least one topic in $S$, and $\overline{D}_{w,S}(t)=1$ for at least one topic in $S$, whenever the denominator is non-zero.
\end{proposition}

\begin{proof}
If the denominator is non-zero, then $\min_{u \in S} D_{w,S}(u) \le D_{w,S}(t) \le \max_{u \in S} D_{w,S}(u)$, and the stated bounds follow immediately. The extreme values are attained by any minimizer and maximizer of $D_{w,S}$ on $S$.
\end{proof}

\begin{proposition}
Let $S \subseteq \mathcal{T}$ be finite and let $a>0$ and $b\in \mathbb{R}$. Define a rescaled depth
\[
D'_{w,S}(t) = a\,D_{w,S}(t) + b,
\qquad t \in S.
\]
If $\max_{u \in S} D_{w,S}(u) \neq \min_{u \in S} D_{w,S}(u)$, then the min--max normalized values are invariant under this transformation:
\[
\overline{D}'_{w,S}(t) = \overline{D}_{w,S}(t)
\qquad \text{for all } t\in S.
\]
\end{proposition}

\begin{proof}
Substituting $D'_{w,S}(t)=aD_{w,S}(t)+b$ into the min--max normalization formula shows that the factor $a$ cancels and the shift $b$ subtracts out in numerator and denominator.
\end{proof}

\begin{proposition}
Let $S \subseteq \mathcal{T}$ be finite and let $t \in S$. If new incoming edges pointing to $t$ are added to the restricted weighted graph $G_{N,S}^w$ (or if the weight of an existing incoming edge is increased), then $D_{w,S}(t)$ can only increase. Consequently, if the minimum and maximum of $D_{w,S}$ over $S$ remain unchanged, then $\overline{D}_{w,S}(t)$ can only increase.
\end{proposition}

\begin{proof}
Each new incoming edge contributes an additional positive term to the sum defining $D_{w,S}(t)$, and increasing an existing incoming weight increases that sum. If $\min_{u \in S} D_{w,S}(u)$ and $\max_{u \in S} D_{w,S}(u)$ remain fixed, then the normalization is an increasing affine transformation of $D_{w,S}(t)$, and the same monotonicity carries over to $\overline{D}_{w,S}(t)$.
\end{proof}

The restricted quantity $D_{w,S}(t)$ measures the degree to which a topic $t$ can be clarified by integrating knowledge \emph{available within} the subset $S$. This is particularly important when $S$ represents the effective scope of a research team or organization: a topic may have large global weighted integrative depth, but small restricted weighted integrative depth if most of its supporting topics lie outside the subset.

The normalized score $\overline{D}_{w,S}(t)$ provides a dimensionless ranking of topics within $S$, enabling comparisons across different subsets and supporting portfolio-level analyses in later chapters.

%
% Applicability
%

\section{Applicability}
\label{sec:applicability}

In addition to nescience and integrative depth, it is useful to characterize the extent to which a research topic can serve as a tool for reducing ignorance in other topics. Some topics play a primarily enabling role: conditioning on them yields reductions in nescience across a broad range of other topics. The metric of \emph{applicability} is introduced to capture this structural property.

\begin{definition}\index{Applicability}
Let $NDG = (\mathcal{T}, E_N)$ be the nescience dependency graph. We define the \emph{applicability}\index{Applicability} of a research topic $t \in \mathcal{T}$ as its out-degree in $NDG$, that is,
\[
A(t) = outdeg(t)
\]
\end{definition}

Applicability measures the breadth of the nescience-reducing influence of a research topic. A topic with low applicability contributes to the reduction of nescience in few other topics, whereas a topic with high applicability admits many distinct directions along which it can be used to reduce ignorance elsewhere.

\begin{example}
As an example of a topic with high applicability, consider \emph{linear algebra}. Conditioning on linear algebra reduces the nescience of a wide range of topics, including numerical analysis, machine learning, quantum mechanics, signal processing, and control theory. In the nescience dependency graph, this corresponds to many outgoing arcs, and hence a high applicability.

By contrast, a narrowly scoped descriptive topic, such as the \emph{maximum recorded jump distance of a specific flea species}, may reduce the nescience of few or no other topics. Such a topic therefore exhibits low applicability.
\end{example}

Applicability inherits several immediate properties from its graph-theoretic definition: \emph{i)} for any research topic $t \in \mathcal{T}$, the applicability $A(t)$ is a non-negative integer; \emph{ii)} A research topic $t$ has applicability $A(t) = 0$ if and only if conditioning on $t$ does not reduce the nescience of any other topic.

% Subsubsection: weighted applicability

\subsubsection*{Weighted applicability}

\begin{definition}\index{Weighted applicability}
Let $G_N^w = (\mathcal{T}, E_N, w)$ be the weighted nescience dependency graph. The \emph{weighted applicability} of a research topic $t \in \mathcal{T}$ is defined as
\[
A_w(t) \;=\; \sum_{u : (t,u) \in E_N} w(t,u).
\]
\end{definition}

Weighted applicability measures not only how many topics benefit from conditioning on $t$, but also the total magnitude of the nescience reductions it provides.

% Subsubsection: Normalized applicability

\subsubsection{Normalized applicability}

To facilitate comparison across topics, applicability values can be normalized using min-max normalization.

\begin{definition}\index{Normalized applicability}
Let $\mathcal{T}$ be finite. The \emph{min--max normalized applicability} of a topic $t \in \mathcal{T}$ is defined as
\[
\overline{A}(t) \;=\;
\frac{A(t) - \min_{u \in \mathcal{T}} A(u)}
{\max_{u \in \mathcal{T}} A(u) - \min_{u \in \mathcal{T}} A(u)}.
\]
\end{definition}

\noindent
In the degenerate case where all topics have the same applicability, all normalized values are set to $0$.

An analogous normalization can be applied to weighted applicability by replacing $A(t)$ with $A_w(t)$.

Applicability and integrative depth capture complementary structural aspects of research topics within the nescience dependency graph. Integrative depth characterizes the plurality of directions along which the nescience of a topic can be reduced, whereas applicability characterizes the plurality of directions along which a topic can reduce the nescience of others.

In later chapters, these metrics will be used jointly to distinguish between research topics that primarily function as tools and those that primarily function as problems, and to guide the construction of research portfolios that balance enabling power with epistemic challenge.

%
% Section: Maturity
%

\section{Maturity}
\label{sec:maturity}

Given an unknown topic $A$, a natural strategy for reducing its nescience is to rely on background topics $B$ such that conditioning on $B$ yields a reduction in nescience, that is,
\[
N(A \mid B) < N(A).
\]
However, not all background topics satisfying this condition are equally suitable to be used as tools. In particular, the usefulness of a background topic depends not only on how much it reduces the nescience of $A$, but also on how well understood the background topic itself is.

To capture this trade-off, we adopt the following guiding principle: a background topic $B$ is considered preferable for reducing the nescience of $A$ when the combined unresolved nescience associated with using $B$ is smaller than the original nescience of $A$. Formally, this corresponds to requiring that
\[
N(A \mid B) + N(B) < N(A).
\]
This condition expresses that the reduction in nescience obtained by conditioning on $B$ is large enough to compensate for the remaining nescience of $B$ itself.

This principle is particularly relevant in situations where errors propagate strongly, commitments are irreversible, or independent means of verification are unavailable. In such contexts, relying on background knowledge that is itself poorly understood may introduce additional uncertainty that outweighs the apparent reduction in nescience of the primary topic.

At the same time, the condition above does not exclude the use of poorly understood background topics in all circumstances. In particular, reliance on such topics may be justified when no better-understood alternative is known to yield a reduction in the nescience of the target topic, or when errors are inexpensive and results can be independently verified. In these situations, even a background topic with high nescience may be used as a provisional tool, provided that it contributes to lowering the nescience of the primary problem.

\begin{example}
\label{ex:llm_maturity}
Large language models illustrate this situation. Conditioning on such models often produces substantial reductions in the nescience of a wide range of tasks, including text generation, code synthesis, and exploratory problem solving. Although these models are themselves only partially understood, they are typically employed in settings where alternative well-understood tools are unavailable, errors are inexpensive, and outputs can be checked or corrected by external means. Under these conditions, reliance on such models can be epistemically productive despite their limited maturity.
\end{example}

To formalize the notion of how well a topic is understood, we introduce the concept of \emph{maturity}. Maturity is defined as a simple reparameterization of nescience, emphasizing its inverse interpretation.

\begin{definition}\index{Maturity}
\label{def:maturity}
Let $t \in \mathcal{T}$ be a topic, and let $N(t)$ denote its nescience.
The \emph{maturity} of $t$, denoted $M(t)$, is defined as
\[
M(t) = 1 - N(t).
\]
\end{definition}

A higher maturity value indicates that a topic is better understood and therefore more suitable to be used as a background tool for reducing the nescience of other topics. Conversely, topics with low maturity should be used with caution, since their own unresolved nescience contributes to the total uncertainty associated with their application.

\begin{example}
\label{ex:linear_regression_maturity}
Linear regression provides an example of a highly mature research topic. Its theoretical assumptions, limitations, and behavior are well characterized, resulting in a low nescience and a correspondingly high maturity. When used as background knowledge, linear regression typically satisfies the condition $N(A \mid B) + N(B) < N(A)$ for a wide range of applied problems, making it a reliable tool in settings where stability and interpretability are important.
\end{example}

Maturity is an intrinsic property of a research topic, reflecting the extent to which its representations are complete and reliable. It is independent of the topic’s applicability or integrative depth, and should therefore not be interpreted as a measure of usefulness or importance. Rather, maturity provides a measure of epistemic stability: mature topics tend to behave predictably when used as background knowledge, whereas immature topics introduce additional uncertainty that must be managed explicitly.

In practice, when comparing maturity values across the topics of a given research area, it is often convenient to work with a normalized scale.

\begin{definition}\index{Normalized maturity}
\label{def:normalized-maturity}
Given a finite set of topics $\mathcal{T}$, the \emph{min--max normalized maturity} of a topic $t \in \mathcal{T}$, denoted $\tilde{M}(t)$, is defined as
\[
\tilde{M}(t) =
\frac{M(t) - \min_{t' \in \mathcal{T}} M(t')}
     {\max_{t' \in \mathcal{T}} M(t') - \min_{t' \in \mathcal{T}} M(t')},
\]
where $M(t)$ is the maturity of $t$ as in Definition~\ref{def:maturity}.
\end{definition}

\noindent
In the degenerate case where all topics have the same maturity, all normalized values are set to $0$. Normalized maturity values will be used in later chapters to guide the selection of background knowledge and to balance nescience reduction against the reliability of the tools employed.

%
% Section: Interestingness
%

\section{Interestingness}
\label{sec:interestingness-metrics}

In many scientific and practical contexts it is necessary to compare research topics and to decide which ones are more promising to pursue, either as tools for solving other problems or as problems worthy of investigation in their own right. In this section, we introduce the notion of \emph{interestingness} as a decision-oriented concept derived from the metrics previously introduced.

The theory of nescience naturally induces several dimensions along which topics may be evaluated, but it does not prescribe a unique way of aggregating them into a single scalar score. As a result, interestingness should be understood as arising from a multi-objective optimization problem (see Section \ref{sec:multiobjective_optimization}), together with a choice of decision rule.

A research topic may be considered interesting as a tool when it can be reliably used to reduce the nescience of other topics. Two theory-derived quantities are relevant in this context: maturity, which measures how well the topic itself is understood and applicability, which measures how widely the topic has been successfully used to reduce nescience in other topics.

\begin{definition}
We define the \emph{interestingness as a tool}\index{Interestingness as a tool} of a topic $t$ as the multi-objective optimization problem:
\[
\text{maximize } \bigl( M(t), A(t) \bigr),
\]
where $M(t)$ denotes the maturity of the topic $t$ and $A(t)$ its applicability.
\end{definition}

This formulation induces a partial order on topics: a topic $t_1$ dominates another topic $t_2$ if $M(t_1) \ge M(t_2)$ and $A(t_1) \ge A(t_2)$, with at least one inequality strict. The set of non-dominated topics forms the pareto frontier\index{Pareto frontier} of interesting tools.

A research topic may also be interesting as a problem, independently of its usefulness as a tool. In this case, two different theory-internal quantities play a central role: nescience, which measures the extent to which the topic is not yet understood, and integrative depth, which measures the number of distinct background topics whose knowledge reduces the nescience of the topic. Together, these quantities characterize both the magnitude of unresolved ignorance and the structural richness of the ways in which that ignorance can be reduced. 

\begin{definition}
We define the \emph{interestingness as a problem}\index{Interestingness as a problem} of a topic $t$ as the multi-objective optimization problem
\[
\text{maximize } \bigl( N(t), D(t) \bigr),
\]
where $N(t)$ is the nescience of topic $t$ and $D(t)$ its integrative depth.
\end{definition}

As in the case of tools, this formulation induces a partial order. Topics with high nescience but low integrative depth correspond to forms of ignorance that admit few known avenues for progress, whereas topics with both high nescience and high integrative depth admit many distinct nescience-reducing directions and are structurally richer as research problems.

In practical applications it is often necessary to produce a total ordering of topics. This requires the introduction of a decision maker, that is, a scalarization of the underlying multi-objective problem.

One possible choice is a balanced \emph{Euclidean scalarization}\index{Euclidean decision rule}. For example, the interestingness of a topic as a tool may be defined as
\[
IT(t) = \frac{\sqrt{\tilde{M}(t)^2 + \tilde{A}(t)^2}}{\sqrt{2}},
\]
where $\tilde{M}(t)$ and $\tilde{A}(t)$ are normalized versions of maturity and applicability. Analogously, interestingness as a problem may be defined as
\[
IP(t) = \frac{\sqrt{\tilde{N}(t)^2 + \tilde{D}(t)^2}}{\sqrt{2}},
\]
where $\tilde{N}(t)$ and $\tilde{D}(t)$ denote normalized nescience and integrative depth.

These metrics correspond to a particular decision method that favors balanced topics over extreme ones. Other decision makers may be more appropriate in different contexts. For instance, a \emph{minimum-based} decision rule\index{Minimum decisions rule}, $\min\{\tilde{M}(t), \tilde{A}(t)\}$, emphasizes robustness by penalizing weaknesses in any dimension, meanwhile a \emph{weighted sum}\index{Weighted sum decision rule} allows explicit prioritization of maturity versus applicability, or nescience versus integrative depth, according to external constraints or strategic goals.

Such decision makers do not alter the underlying theory, but provide practical means of selecting and ranking topics for specific purposes.

%
% Section: Interesting Questions
%

\section{Interesting Questions}
\label{sec:intro_interesting_questions}

In the theory of nescience we distinguish between known unknowns\index{Known unknowns}, that is, problems whose existence is recognized but whose solutions are not known, and unknown unknowns\index{Unknown unknowns}, corresponding to problems that have not yet been identified. In this section we focus on the former, and introduce a formal notion of \emph{interesting questions} aimed at supporting the systematic exploration of known unknowns.

A central observation underlying this approach is that new research questions often arise when existing knowledge is brought to bear on unresolved problems. In the theory of nescience, such situations are naturally captured by the \emph{nescience dependency graph}, which encodes when knowledge of one topic reduces the nescience of another.

\begin{definition}\index{Question}
Let $G_N = (\mathcal{T}, E_N)$ denote the nescience dependency graph. We define \emph{interesting question}\index{Interesting question} as an ordered pair of topics $Q_{t \to p} = (t,p)$ such that $(t,p) \in E_N$.
\end{definition}

\noindent
In other words, a question exists only when the theory predicts that the topic $t$ can be meaningfully used to reduce the nescience of the topic $p$. The directed nature of the dependency graph makes the asymmetry between tools and problems explicit: in general, $Q_{t \to p}$ and $Q_{p \to t}$ represent distinct questions, and only one of them may be well defined.

Operationally, the question $Q_{t \to p}$ can be interpreted as asking whether, and how, the knowledge associated with topic $t$ can be used to make progress on the unresolved aspects of topic $p$.

The nescience dependency graph not only specifies the existence of a question, but also provides a quantitative measure of its potential impact.

\begin{definition}\index{Pair-specific nescience reduction}
Let $Q_{t \to p}$ be a question. The \emph{pair-specific nescience reduction} associated with $Q_{t \to p}$ is defined as
\[
\Delta N(p;t) = N(p) - N(p \mid t),
\]
which is strictly positive by definition of the dependency graph.
\end{definition}

\noindent
The quantity $\Delta N(p;t)$ measures how much of the unresolved ignorance about $p$ can be reduced by assuming the knowledge background associated with $t$. Unlike topic-level metrics, this quantity is intrinsically relational and depends on the specific pairing of tool and problem.

The interestingness of a question cannot, in general, be reduced to a single scalar quantity without introducing additional assumptions. Instead, the theory of nescience naturally induces a multi-objective evaluation of questions based on theory-derived quantities.

Given a question $Q_{t \to p}$, the following dimensions are relevant:

\begin{itemize}
\item $\Delta N(p;t)$, the pair-specific nescience reduction;
\item $M(t)$, the maturity of the tool topic $t$;
\item $A(t)$, the applicability of the tool topic $t$;
\item $N(p)$, the nescience of the problem topic $p$;
\item $D(p)$, the integrative depth of the problem topic $p$.
\end{itemize}

Together, these quantities define the objective vector
\[
\Phi(t,p) = \bigl( \Delta N(p;t),\; M(t),\; A(t),\; N(p),\; D(p) \bigr).
\]

\begin{definition}\index{Interesting question}
A question $Q_{t \to p}$ is said to be \emph{at least as interesting} as another question $Q_{t' \to p'}$ if
\[
\Phi(t,p) \ge \Phi(t',p')
\]
componentwise, with at least one inequality being strict. The set of \emph{interesting questions} is defined as the Pareto frontier of questions under this partial order.
\end{definition}

\noindent
This definition does not impose a total ordering on questions, and naturally allows for the existence of incomparable questions corresponding to different trade-offs between nescience reduction, reliability of tools, and structural richness of problems.

In practical applications, such as research planning, portfolio construction, or automated recommendation systems, it is often necessary to rank questions or to select a subset of them. This requires the introduction of a \emph{decision maker}, understood as a scalarization of the underlying multi-objective problem.

Several decision makers are particularly natural in the present framework:

\begin{itemize}
\item \textbf{Risk-averse decision maker.} Select questions that maximize $\Delta N(p;t)$ subject to a lower bound on tool maturity, $M(t) \ge \tau$, for some threshold $\tau$.
\item \textbf{Exploratory decision maker.} Maximize $\Delta N(p;t) \cdot N(p)$, favoring questions that yield large reductions on highly unresolved problems.
\item \textbf{Scarcity-aware decision maker.} Favor questions associated with problems of low integrative depth $D(p)$, reflecting situations where few alternative nescience-reducing paths are available.
\item \textbf{Balanced scalarization.} Combine normalized versions of the components of $\Phi(t,p)$ using a weighted or Euclidean aggregation, yielding a total ordering suitable for visualization or large-scale comparison.
\end{itemize}

\noindent
The choice of decision maker depends on contextual factors such as acceptable risk, available resources, and strategic goals. Importantly, these choices do not alter the underlying theory, but merely provide different ways of navigating the space of interesting questions it defines.

\medskip
\noindent
In summary, interesting questions are defined in the theory of nescience as graph-grounded objects corresponding to nescience-reducing relationships between topics. Their interestingness emerges from a multi-objective structure inherent in the theory, while scalar rankings arise only at the level of decision making and application.

\begin{example}
\label{ex:interesting_questions_example_cancer}

We illustrate the proposed framework with a simplified example drawn from cancer research. Consider the following topics in the set $\mathcal{T}$:

\begin{itemize}
\item $p =$ \emph{Cancer progression}, understood as the set of mechanisms by which cancer develops, invades tissue, and metastasizes.
\item $t_1 =$ \emph{Genomics}, including gene expression profiling and mutation analysis.
\item $t_2 =$ \emph{Statistical learning}, encompassing classification, regression, and model selection techniques.
\item $t_3 =$ \emph{Cell signaling pathways}, describing biochemical interaction networks inside cells.
\item $t_4 =$ \emph{Immunotherapy}, covering immune-based treatment strategies.
\end{itemize}

Assume that empirical and theoretical work has established the following nescience-reducing relationships:
\[
N(p \mid t_i) < N(p) \quad \text{for } i \in \{1,2,3,4\}.
\]
These relationships define arcs $(t_i,p)$ in the nescience dependency graph $G_N$. Each arc corresponds to a question $Q_{t_i \to p}$ asking whether the knowledge associated with $t_i$ can be used to reduce ignorance about cancer progression.

Suppose further that the estimated pair-specific nescience reductions satisfy
\[
\Delta N(p;t_1) > \Delta N(p;t_2) > \Delta N(p;t_3) > \Delta N(p;t_4),
\]
reflecting the fact that genomic data currently explains a larger fraction of observed variability in cancer progression than the other topics.

At the same time, the maturity values of the tool topics may differ substantially. For instance, statistical learning may have high maturity due to well-established theory and methods, whereas immunotherapy may exhibit lower maturity due to incomplete understanding of immune response dynamics. Integrative depth $D(p)$ is high, since multiple independent background topics reduce the nescience of $p$.

Within this framework, the set of questions
\[
\{ Q_{t_1 \to p}, Q_{t_2 \to p}, Q_{t_3 \to p}, Q_{t_4 \to p} \}
\]
forms the candidate space of graph-grounded questions. Their interestingness is evaluated by comparing the corresponding objective vectors
\[
\Phi(t_i,p) = \bigl( \Delta N(p;t_i),\, M(t_i),\, A(t_i),\, N(p),\, D(p) \bigr).
\]

Different decision makers may select different questions from this set. A risk-averse decision maker may favor $Q_{t_2 \to p}$ due to the high maturity of statistical learning, even if its nescience reduction is not maximal. An exploratory decision maker may prioritize $Q_{t_1 \to p}$, which yields the largest reduction in nescience. A scarcity-aware decision maker would note that $D(p)$ is high, indicating that cancer progression admits many independent lines of inquiry, and may therefore prioritize questions that explore underrepresented connections, such as $Q_{t_4 \to p}$.
\end{example}

This example illustrates how the theory of nescience supports the systematic generation and evaluation of research questions. Questions are not arbitrary combinations of topics, but graph-grounded objects whose interestingness emerges from the interplay between pair-specific nescience reduction, the maturity of available tools, and the structural richness of the underlying problem.

%
% Section: New Research Topics
%


\section{New Topics}
\label{sec:New_Research_Topics}

The region of \emph{unknown unknowns} plays a central role in scientific progress, as it contains those research topics that have not yet been conceptualized or identified. One of the main objectives of the theory of nescience is to provide principled tools for exploring this region and for anticipating the emergence of future research topics. In this section we introduce a formal framework for the identification of \emph{new topics}, understood as topics that lie beyond the current knowledge frontier.

A guiding intuition, illustrated in Figure~\ref{fig:NewTopics}, is that the probability of crossing the knowledge frontier through the combination of existing topics is higher when the topics involved are themselves poorly understood. Well-understood topics are typically embedded in dense and highly explored neighborhoods of the representation space, so their combinations tend to remain within the domain of known knowledge. In contrast, topics with high nescience are associated with sparser and less structured neighborhoods, making combinations involving them more likely to reach unexplored regions.

\subsection{Candidate Topic Combinations}

Let $\mathcal{T}$ denote the set of existing research topics, and let $N(t)$ denote the nescience of topic $t$, with $\tilde{N}(t)$ its normalized version. Let $D(t)$ denote the (normalized) integrative depth of $t$, as introduced in Section~\ref{sec:integrative_depth}.

\begin{definition}\index{Candidate topic combination}
Given two distinct topics $t_1,t_2 \in \mathcal{T}$, a \emph{candidate topic combination} is the unordered pair
\[
C_{\{t_1,t_2\}} = \{t_1,t_2\}.
\]
\end{definition}

\noindent
A candidate topic combination does not, by itself, constitute a new topic. Rather, it represents a potential source from which a new topic may emerge, depending on whether the combination leads beyond the knowledge frontier.

\subsection{Multi-Objective Characterization of New Topics}

The emergence of a new topic from a candidate combination cannot be adequately captured by a single scalar quantity. Instead, it is naturally described as a multi-objective problem involving theory-internal quantities.

Given a candidate combination $C_{\{t_1,t_2\}}$, we associate the following objective vector:
\[
\Psi(t_1,t_2)
=
\bigl(
\tilde{N}(t_1),\;
\tilde{N}(t_2),\;
D(t_1),\;
D(t_2)
\bigr).
\]

Each component has a clear interpretation:
\begin{itemize}
\item $\tilde{N}(t_1), \tilde{N}(t_2)$ measure how close the topics are to the knowledge frontier;
\item $D(t_1), D(t_2)$ measure the structural richness of the topics, in terms of the number of distinct ways background knowledge can reduce their nescience.
\end{itemize}

High values of $\tilde{N}$ indicate proximity to the frontier, while high values of $D$ indicate that the topic participates in many independent nescience-reducing relations. Combinations in which both topics exhibit high nescience and substantial integrative depth are therefore structurally well positioned to give rise to new topics beyond the frontier.

\begin{definition}\index{Potential new topic}
A candidate combination $C_{\{t_1,t_2\}}$ is said to have \emph{high potential as a new topic} if it lies on the Pareto frontier of the set
\[
\{ \Psi(t_i,t_j) : t_i,t_j \in \mathcal{T},\ i \neq j \}
\]
under the componentwise partial order.
\end{definition}

\noindent
This definition avoids imposing an arbitrary total ordering on candidate combinations and reflects the fact that different combinations may represent different trade-offs between proximity to the frontier and structural richness.

\subsection{Decision Makers and Practical Selection}

In practical applications, such as research planning or automated topic discovery systems, it is often necessary to select or rank candidate combinations. This requires introducing a \emph{decision maker}, understood as a scalarization of the multi-objective problem above.

Examples of decision makers include:
\begin{itemize}
\item \textbf{Frontier-seeking decision maker}, which prioritizes combinations maximizing $\tilde{N}(t_1)+\tilde{N}(t_2)$;
\item \textbf{Structure-aware decision maker}, which prioritizes combinations with high $D(t_1)+D(t_2)$, favoring structurally rich topics;
\item \textbf{Balanced decision maker}, which applies a weighted aggregation of the components of $\Psi(t_1,t_2)$.
\end{itemize}

The choice of decision maker depends on contextual factors and does not alter the underlying theoretical framework.

\subsection{Intradisciplinary and Interdisciplinary Combinations}

\begin{definition}\index{Intradisciplinary new topic}\index{Interdisciplinary new topic}
Let $\mathcal{A} \subseteq \mathcal{T}$ be a research area. A candidate combination $C_{\{t_1,t_2\}}$ is said to be \emph{intradisciplinary} if $t_1,t_2 \in \mathcal{A}$; otherwise, it is \emph{interdisciplinary}.
\end{definition}

\noindent
Interdisciplinary combinations often correspond to candidate combinations whose components lie in distant regions of the nescience dependency graph. Such combinations are therefore more likely to explore underconnected regions of the representation space and to contribute to the expansion of the knowledge frontier, although this is not guaranteed in general.

%
% References
%

\section*{References}

The following works provide theoretical and philosophical foundations for the concepts of interestingness, maturity, and the combination of topics as tools and problems.

\cite{chalmers2013thing} An accessible introduction to the philosophy of science, addressing how scientific questions are formulated, evaluated, and justified.

\cite{pearl2019book} Introduces the principles of causal reasoning, crucial for determining whether applying one topic as a tool can effectively address another as a problem.

\cite{popper2014conjectures} Discusses falsifiability, novelty, and the importance of bold conjectures—foundational ideas for the “new and original” criterion.

\cite{shmueli2010explain} Clarifies the distinction between explanatory and predictive goals, helping to differentiate between topics valuable as problems versus tools.

\cite{van1980scientific} Explores the aims of science, model construction, and empirical adequacy, offering a philosophical context for defining “interesting” research.
