%
% CHAPTER 6.- The Theory of Nescience
%

\chapterimage{owl.pdf} % Chapter heading image

\chapter{Nescience}
\label{chap:Nescience}

\begin{quote}
\begin{flushright}
\emph{There are known knowns. These are things we know that we know.
There are known unknowns. That is to say, there are things that we know we don't know.
But there are also unknown unknowns. There are things we don't know we don't know.} \\
Donald Rumsfeld
\end{flushright}
\end{quote}
\bigskip

Following the foundational Chapter \ref{cha:Topics-and-Descriptions}, which introduced the core concepts of entity, representation, and description, and the subsequent Chapters \ref{chap:Miscoding}, \ref{chap:Error}, and \ref{chap:Redundancy}, which developed the new metrics of miscoding, inaccuracy, and surfeit, we are now prepared to delve into the central concept of nescience in this chapter, focusing on its fundamental properties.

Unlike Shannon entropy or Kolmogorov complexity, which measure information, nescience quantifies the absence of information, that is, what remains unknown. The theory of nescience characterizes our ignorance about a research entity through the three previously introduced metrics: miscoding, inaccuracy, and surfeit. Miscoding assesses how accurately an entity is represented as a string of symbols; inaccuracy measures how well our best available model describes this representation; and surfeit evaluates the descriptive efficiency of the model, as reflected in its length or symbol count.

These three metrics are inherently interdependent and often in conflict: reducing one can lead to an increase in another. The central challenge, therefore, is to develop a method for simultaneously minimizing all three. This requirement reflects, in our view, the fundamental nature of scientific inquiry as a multi-objective optimization problem.

One of the most significant outcomes of our definition of nescience, grounded in the metrics of miscoding, inaccuracy, and surfeit, is its capacity to partition the domain of research topics into two distinct areas. The first is the known unknown, which includes topics we are aware we do not fully understand, yet can recognize and acknowledge our incomplete knowledge. The second is the unknown unknown, comprising topics that have not yet been discovered or conceptualized. A key application of the theory of nescience is its use as a methodological framework for identifying and exploring what lies within the unknown unknown.

Another noteworthy implication of the nescience framework is the counterintuitive idea that, for certain topics, continued research may be counterproductive. In these cases, additional investigation may actually increase our ignorance rather than reduce it. This occurs when we reach a critical threshold beyond which our descriptions become more inaccurate, overly complex, or based on flawed representations, preventing any real progress toward understanding. 

%
% Section: Nescience
%

\section{Nescience}

Intuitively, our understanding of an entity should be based in the quality of the model we use to describe it, specifically, its ability to explain why things happen. Within the theory of nescience, we propose a quantitative measure of our ignorance concerning a research entity, based on three components: the miscoding of a string-based representation of the entity, and the inaccuracy and surfeit of the model describing that representation. Miscoding captures how accurately the representation encodes the entity, inaccuracy reflects how well the model describes the representation, and surfeit quantifies the extent of unnecessary effort embedded in the model. We argue that the goal of science should be to minimize all three quantities: miscoding, inaccuracy, and surfeit. Unfortunately, these metrics are inherently conflicting, reducing one may lead to an increase in one or both of the others.

According to the theory of nescience, science can be viewed as a multiobjective optimization problem\footnote{Technically speaking, science is a deterministic, discrete, nonlinear, nonconvex, nondifferentiable multiobjective optimization problem with a single decision maker.} (see Section \ref{sec:multiobjective_optimization}):

\begin{tBox}
\textbf{The Science Problem}
\index{Sicence problem}
\begin{align*}
 & \text{minimize} \quad \{ \mu(r), \iota(d, r), \sigma(d, r)\} \\
 & \text{subject to} \quad (r, d) \in \mathcal{B}^\ast \times \mathcal{D}
\end{align*}
\end{tBox}

A \emph{scientific method}\index{Scientific method}, further discussed in Chapter \ref{chap:Philosophy}, refers to any algorithm or computable procedure capable of solving, or closely approximating a solution to, the above minimization problem. This includes a broad class of techniques and methodologies aimed at systematically reducing the values of miscoding, inaccuracy, and surfeit. In doing so, scientific methods contribute to improving the accuracy and conciseness of our representations and models, thereby advancing our understanding of the world.

The feasible region is the Cartesian product $\mathcal{B}^\ast \times \mathcal{D}$, where $\mathcal{B}^\ast$ denotes the set of finite binary strings and $\mathcal{D}$ the set of descriptions. The decision vectors are pairs $(r, d)$, referred to as \emph{hypotheses}\index{Hypothesis}, consisting of a representation and a description. The objective functions to be minimized are miscoding, surfeit, and inaccuracy. The objective space is the subset $\mathbf{Z} \subset \mathbb{R}^3$, whose elements are the objective vectors.

In our formulation of science and the scientific method, we deliberately exclude the set $\mathcal{E}$ of entities. Requiring direct knowledge of an entity $e \in \mathcal{E}$ would render the scientific problem ill-posed for most research areas. Science, at its core, is a matter of manipulating strings of symbols. From a practical standpoint, it is about discovering strings that have meaningful interpretations in the real world and can be used to solve concrete problems. From a more theoretical perspective, the aim of science can be seen as the attempt to understand the workings of an unknown abstract oracle.

If the set $\mathcal{R}_e$ of representations for a particular entity $e$ is known, or approximately known, we can restrict the science problem to:
\begin{align*}
 & \text{minimize} \quad \{ \mu(r), \iota(d, r), \sigma(d, r)\} \\
 & \text{subject to} \quad (r, d) \in \mathcal{R}_e \times \mathcal{D}
\end{align*}
Within the theory of nescience, our primary focus lies in the decision space $\mathcal{B}^\ast \times \mathcal{D}$, the space of representations and descriptions, rather than in the objective space $\mathbf{Z} \subset \mathbb{R}^3$ of metric values. In the following definitions, we revisit key concepts from multiobjective optimization (see Section \ref{sec:multiobjective_optimization}) as they apply specifically to the science problem.

\subsection*{Pareto Optimality}

If the representation and description currently used to characterize an entity are not perfect, our goal is to find an alternative representation or description that reduces at least one of the metrics miscoding, inaccuracy, or surfeit without increasing the value of any of the others.

\begin{definition}
We say that a hypothesis $(r, d) \in \mathcal{B}^\ast \times \mathcal{D}$ \emph{dominates}\index{Dominate} another hypothesis $(r', d') \in \mathcal{B}^\ast \times \mathcal{D}$ if it improves at least one of the metrics miscoding, inaccuracy, or surfeit without worsening either of the other two.
\end{definition}

For example, we might identify a new representation that encodes the entity more accurately without degrading the quality of its description. Alternatively, we could find a new description that improves accuracy without increasing surfeit, or a more concise description that preserves accuracy.

\begin{example}
\label{ex:nescience_pareto}
Consider an experiment in which we collect a set of observations $r$ and apply a mathematical model $f_1$ from a model family $\mathcal{M}_1$, resulting in an inaccuracy of $i_1$. Later, we fit a second model $f_2$ from a different model family $\mathcal{M}_2$, which is smaller in size (i.e., has lower surfeit) but yields the same inaccuracy $i_1$. In this case, the hypothesis $B = (r, f_2)$ dominates the hypothesis $A = (r, f_1)$, even though it is not better in terms of inaccuracy alone.
\end{example}

For most entities, there does not exist a single solution that simultaneously minimizes all three metrics. Instead, we encounter a set of Pareto optimal solutions that define an optimal frontier.

\begin{definition}
We say that a hypothesis $(r, d) \in \mathcal{B}^\ast \times \mathcal{D}$ is \emph{Pareto optimal}\index{Pareto optimal} if there does not exist another hypothesis $(r', d') \in \mathcal{B}^\ast \times \mathcal{D}$ such that $(r', d')$ dominates $(r, d)$. The set of Pareto optimal solutions, denoted by $\mathbf{P}_{\mathcal{B}^\ast \times \mathcal{D}}$, is called the \emph{Pareto frontier}\index{Pareto frontier}.
\end{definition}

In the realm of scientific research, the concept of the Pareto frontier, as defined by the set of Pareto optimal solutions $\mathbf{P}_{\mathcal{B}^\ast \times \mathcal{D}}$, plays a crucial role. It delineates the boundary of optimal trade-offs among the conflicting metrics of miscoding, inaccuracy, and surfeit, such that none can be improved without worsening at least one of the others. This frontier represents the spectrum of best-achievable balances, guiding researchers to identify models and representations that offer the most scientifically rigorous understanding of their subject matter (see Section \ref{sec:perfect_knowledge}).

However, in certain situations or specific applications, it may be reasonable to adopt a solution that is not Pareto optimal. For instance, one might choose to prioritize a particular metric due to its relevance or importance to the research objectives, accepting less favorable values for the remaining metrics as a necessary trade-off (see Section \ref{sec:minimizing_nescience}).

Building on the concept of Pareto optimality, where a solution is considered optimal if no other solution improves one objective without worsening another, we introduce the notion of weak Pareto optimality. A hypothesis is said to be weakly Pareto optimal if there is no other hypothesis that improves all objectives simultaneously. This concept is broader than Pareto optimality, as it includes solutions that may not be the best in any single objective but are not strictly outperformed in every dimension.

\begin{definition}
We say that a hypothesis $(r, d) \in \mathcal{B}^\ast \times \mathcal{D}$ \emph{weakly dominates}\index{Weakly dominates} another hypothesis $(r', d') \in \mathcal{B}^\ast \times \mathcal{D}$ if it improves all three metrics miscoding, inaccuracy, and surfeit simultaneously. That is, if $\mu(r') < \mu(r)$, $\iota(d', r') < \iota(d, r)$, and $\sigma(d', r') < \sigma(d, r)$.
\end{definition}

A hypothesis is \emph{weakly Pareto optimal} if there does not exist another hypothesis that improves all three metrics: miscoding, inaccuracy, and surfeit.

\begin{definition}
We say that a hypothesis $(r, d) \in \mathcal{B}^\ast \times \mathcal{D}$ is \emph{weakly Pareto optimal}\index{Weakly Pareto optimal} if there does not exist another hypothesis $(r', d') \in \mathcal{B}^\ast \times \mathcal{D}$ such that $(r', d')$ weakly dominates $(r, d)$. The set of weakly Pareto optimal solutions, denoted by $\mathbf{P}\_{\mathcal{B}^\ast \times \mathcal{D}}$, is called the \emph{weakly Pareto frontier}\index{Weakly Pareto frontier}.
\end{definition}

If a hypothesis is weakly Pareto optimal, it means there is no other hypothesis that improves all three metrics simultaneously. However, it is still possible to find a hypothesis that improves one of the metrics without worsening the others, that is, a hypothesis that is Pareto optimal. Thus, the Pareto frontier is a subset of the weakly Pareto frontier. In the theory of nescience, we focus primarily on the set of Pareto optimal solutions rather than the set of weakly Pareto optimal ones.

\begin{example}
Based on the assumptions of Example \ref{ex:nescience_pareto}, hypothesis $A$ could still be weakly Pareto optimal, but it cannot be Pareto optimal, since it is dominated by hypothesis $B$. However, it is not weakly dominated by hypothesis $B$.
\end{example}

The concepts of Pareto and weakly Pareto optimality can also be particuralized to the case in which the set $\mathcal{R}_e$ of representations of a particular entity $e$ is known.

% Range of Solutions

\subsection*{Range of Solutions}

As discussed in Section \ref{sec:range_solutions}, an objective vector that achieves the minimum possible value for all objective functions is termed the ideal objective vector\index{Ideal vector}. For the science problem, this ideal vector is represented by the origin $(0, 0, 0)$, symbolizing the complete elimination of miscoding, inaccuracy, and surfeit.

\begin{proposition}
The ideal objective vector for the science problem is the origin \$(0, 0, 0)\$.
\end{proposition}
\begin{proof}
Proposition \ref{prop:range_miscoding} established that miscoding is greater than or equal to zero, and Proposition \ref{prop:perfect_encoding} showed that it can be equal to zero. Likewise, Proposition \ref{prop:inaccuracy:inaccuracy:range} demonstrated that inaccuracy is non-negative, while Proposition \ref{prop:inaccuracy_perfect_description} confirmed that a value of zero is attainable. Finally, Proposition \ref{prop:range_surfeit} stated that surfeit is at least zero, and Proposition \ref{prop:zero_surfeit} verified that zero surfeit is achievable.
\end{proof}

A hypothesis $(r, d) \in \mathcal{B}^\ast \times \mathcal{D}$ is said to be ideal if it exhibits zero miscoding, zero inaccuracy, and zero surfeit. This implies that the representation $r$ is valid, the model $d$ produces $r$ as output, and there exists no shorter model $d'$ that also achieves zero inaccuracy. Intuitively, a hypothesis $(r, d)$ is ideal if there exists an entity $e \in \mathcal{E}$ such that $r$ perfectly encodes $e$, and $d$ is both an accurate and minimal model of $r$.

Ideal hypotheses embody the notion of perfect knowledge within the theory of nescience. Unfortunately, in most practical applications, reaching the ideal objective vector is not feasible due to the inherently conflicting nature of the metrics: miscoding, inaccuracy, and surfeit.

\begin{example}
A research topic for which it is impossible to reach the ideal objective vector is weather prediction. In this case, the entity under study is the atmosphere over a geographical region. The representation of this entity (typically a set of meteorological measurements such as temperature, pressure, and humidity) is inherently flawed due to the limited spatial and temporal resolution of sensors, noise in the data, and incomplete coverage, particularly over oceans and remote areas. As a result, miscoding is strictly greater than zero. Furthermore, even the most sophisticated atmospheric models, which numerically approximate the physical laws governing weather dynamics, cannot produce perfectly accurate forecasts due to the chaotic nature of the system, the need for simplifying assumptions, and errors in initial conditions, ensuring that inaccuracy also remains greater than zero. Finally, these models are large, complex, and often include redundant components or overly general submodules, making them far from minimal in size; thus, surfeit is also non-zero.
\end{example}

The upper bound of the Pareto optimal set is given by the nadir objective vector\index{Nadir vector}. In the theory of nescience, the nadir vector is the point $(1, 1, 1)$, corresponding to maximum miscoding, maximum inaccuracy, and maximum surfeit.

\begin{proposition}
The nadir objective vector of the science problem is the vector $(1, 1, 1)$.
\end{proposition}
\begin{proof}
Proposition \ref{prop:range_miscoding} demonstrated that miscoding is greater than or equal to zero, and Proposition \ref{prop:perfect_encoding} showed that it can be equal to zero. Similarly, Proposition \ref{prop:inaccuracy:inaccuracy:range} established that inaccuracy is greater than or equal to zero, and Proposition \ref{prop:inaccuracy_perfect_description} indicated that a zero value is attainable. Finally, Proposition \ref{prop:range_surfeit} showed that surfeit is greater than or equal to zero, and Proposition \ref{prop:zero_surfeit} confirmed that it can also reach zero. Therefore, since all three metrics are bounded between 0 and 1, the upper bound of the objective region is $(1, 1, 1)$.
\end{proof}

The nadir vector represents a state of complete ignorance: a hypothesis $(r, d)$ in which the representation $r$ contains no meaningful information about the entity $e$ under study, the description $d$ generates a string entirely unrelated to $r$, and the description is of maximal length. This extreme point illustrates the worst-case scenario in terms of scientific knowledge: maximum miscoding, total inaccuracy, and maximum unnecessary complexity.

\begin{example}
Consider the case of studying the physical law governing the motion of a pendulum. Suppose we define a hypothesis $(r, d)$, where the representation $r$ is a random binary string encoding information entirely unrelated to the pendulum, such as the binary representation of a shuffled deck of cards. The description $d$ is a program that outputs an unrelated string, for example, one billion digits of $\pi$. In this scenario, miscoding is maximal because the representation bears no connection to the entity being studied, inaccuracy is maximal because the description produces a string entirely different from the representation, and surfeit is also maximal since the description is very long compared to the lenght of $r$. This hypothesis $(r, d)$ reaches the nadir objective vector $(1, 1, 1)$, reflecting a state of complete ignorance about the entity.
\end{example}

% Trade-offs

\subsection*{Trade-offs}

In Section \ref{sec:Inaccuracy_Miscoding_Rate_of_Change}, we analyzed the trade-off between inaccuracy and miscoding:
\[
\Delta_{\iota \mu} ( \mathbf{x}_1, \mathbf{x}_2 ) = \frac{\iota(d_2, r_2) - \iota(d_1, r_1)}{\mu(r_2) - \mu(r_1)}
\]
where $\mathbf{x}_1 = (r_1, d_1)$ and $\mathbf{x}_2 = (r_2, d_2)$ are two hypotheses.

This ratio quantifies the rate at which inaccuracy changes relative to miscoding when transitioning between two hypotheses. A positive value of $\Delta_{\iota \mu}$ indicates that both metrics vary in the same direction, either improving or deteriorating together, whereas a negative value reflects a trade-off between them.

In Section \ref{Surfeit_inaccuracy_rate_of_Change}, we similarly studied the trade-off between surfeit and inaccuracy:
\[
\Delta_{\sigma \iota} ( \mathbf{x}_1, \mathbf{x}_2 ) = \frac{\sigma(d_2, r) - \sigma(d_1, r)}{\iota(d_2, r) - \iota(d_1, r)}
\]
This ratio captures how surfeit changes with respect to inaccuracy when the representation remains fixed and only the description changes. Again, a positive value of $\Delta_{\sigma \iota}$ indicates that both metrics are moving in the same direction, either improving or deteriorating together, whereas a negative value reflects a trade-off between them.

These trade-off ratios provide a local, quantitative tool for evaluating whether a change in hypothesis moves us toward Pareto optimality or away from it, and how it relates to the extreme points represented by the ideal and nadir objective vectors.

In this section we introduce a unified framework that provides a global trade-offs.

\begin{definition}
Let $\mathbf{x}_1 = (r_1, d_1)$ and $\mathbf{x}_2 = (r_2, d_2)$ be two hypotheses. We define the \emph{nescience trade-off vector}\index{Trade-off vector} between $\mathbf{x}_1$ and $\mathbf{x}_2$ as:
\[
\boldsymbol{\Delta}_{\text{nescience}}(\mathbf{x}_1, \mathbf{x}_2) =
\left(
\frac{\iota(d_2, r_2) - \iota(d_1, r_1)}{\mu(r_2) - \mu(r_1)},\;
\frac{\sigma(d_2, r_2) - \sigma(d_1, r_1)}{\iota(d_2, r_2) - \iota(d_1, r_1)}
\right)
\]
provided that $\mu(r_2) \neq \mu(r_1)$ and $\iota(d_2, r_2) \neq \iota(d_1, r_1)$.
\end{definition}

This vector $\boldsymbol{\Delta}_{\text{nescience}}(\mathbf{x}_1, \mathbf{x}_2)$ describes yhe rate of change of inaccuracy relative to miscoding, and the rate of change of surfeit relative to inaccuracy.

\begin{definition}
Given two hypotheses $\mathbf{x}_1 = (r_1, d_1)$ and $\mathbf{x}_2 = (r_2, d_2)$, we define the \emph{unified trade-off magnitude}\index{Unified trade-off magnitude}, denoted $\Theta(\mathbf{x}_1, \mathbf{x}_2)$, as:
\[
\Theta(\mathbf{x}_1, \mathbf{x}_2) = 
\sqrt{
\left( \frac{\iota(d_2, r_2) - \iota(d_1, r_1)}{\mu(r_2) - \mu(r_1)} \right)^2 +
\left( \frac{\sigma(d_2, r_2) - \sigma(d_1, r_1)}{\iota(d_2, r_2) - \iota(d_1, r_1)} \right)^2
}
\]
whenever both denominators are non-zero.
\end{definition}

A small $\Theta$ value suggests an efficient trade-off: significant improvement in one metric with minor cost in others. A large $\Theta$ indicates a steep or unbalanced trade-off path in the nescience objective space. This formulation complements the concepts of Pareto dominance and optimality by quantifying how sharply a transition between hypotheses navigates the trade-offs among conflicting objectives.

%
% Minimizing Nescience
%

\section{Minimizing Nescience}
\label{sec:minimizing_nescience}

From a mathematical perspective, any solution within the Pareto optimal set is considered a valid answer to the Science Problem. In fact, the problem is formally solved once all Pareto optimal solutions have been identified. However, in scientific practice, this is often not sufficient. Researchers usually seek a single, most appropriate solution that best aligns with the priorities or goals of the investigation.

In multi-objective optimization, a decision maker (see Section \ref{sec:multiobjective_optimization}) is an entity (either a human agent, a set of predefined criteria, or an algorithm) responsible for selecting one solution from the set of Pareto optimal hypotheses. The decision maker incorporates external preferences, priorities, or domain-specific constraints to guide the selection process. Its role is to introduce a preference relation that induces an ordering over the Pareto set, thereby allowing for the identification of the most suitable hypothesis according to the specific goals or values of the scientific inquiry.

To formalize this within the theory of nescience, we introduce the notion of a nescience decision maker\index{Nescience decision maker}, defined as a scalar-valued function that evaluates and ranks hypotheses based on their levels of miscoding, inaccuracy, and surfeit. This function reflects the relative preference for each hypothesis.

\begin{definition}
Let $(r, d) \in \mathcal{B}^\ast \times \mathcal{D}$ be a hypothesis. A decision maker\index{Science decision maker} for the science problem is a multivariate funcion $V : \mathbb{R}^3 \rightarrow \mathbb{R}$, that assings to each triplet $\left( \mu(r), \iota(d, r), \sigma(d, r) \right)$ the real value $V\left( \mu(r), \iota(d, r), \sigma(d, r) \right)$. 
\end{definition}

The function $V$ is often referred to as a \emph{value function}\index{Value function} or \emph{utility function}\index{Utility function}, and it encodes the preferences or priorities of the scientist or research community. Depending on the application, $V$ may treat the three metrics equally, emphasize one over the others, or apply a more sophisticated transformation to reflect factors such as risk tolerance, interpretability, or domain-specific considerations.

This formalism enables the selection of a single hypothesis from the Pareto frontier, effectively transforming the multi-objective problem into a single-objective one guided by scientific judgment.

% Global Criterion

\subsection{Global Criterion}

The global criterion method (see Section \ref{sub:multiobjective_global_criterion}) is an approach to solving multi-objective optimization problems by minimizing the distance between a reference point and the feasible region in the objective space. The reference point is typically chosen to be the ideal vector, which in our case corresponds to the origin $(0, 0, 0)$.

Different distance metrics can be used in this framework. For example, the global criterion based on the origin and the Euclidean distance leads to the following minimization problem:
\begin{align*}
& \text{minimize} \quad \sqrt{ \mu(r)^2 + \iota(d, r)^2 + \sigma(d, r)^2 } \\
& \text{subject to} \quad (r, d) \in \mathcal{B}^\ast \times \mathcal{D}
\end{align*}

As shown in Proposition \ref{prop:global_criterion_pareto_optimal}, the solutions obtained through the global criterion method are guaranteed to be Pareto optimal. However, it is important to note that this method does not consider all Pareto optimal solutions. In particular, optimal points that lie far from the reference point are excluded.

\begin{example}
Consider the following three Pareto optimal solutions:

\begin{itemize}
\item $A=(0.1,0.8,0.9)$
\item $B=(0.8,0.1,0.9)$
\item $C=(0.5,0.5,0.5)$
\end{itemize}

Although all three solutions are Pareto optimal, a global criterion based on Euclidean distance may select only $C$, as it is closest to the origin. However, $A$ and $B$ represent equally valid trade-offs. In particular, solution $B$ achieves very low inaccuracy, which, in certain contexts, might make it the preferred option.
\end{example}

When working with a global criterion for optimization problems, it is customary to normalize the range of the objective values to prevent objectives with larger scales from disproportionately influencing the result. However, in the case of the theory of nescience, normalization is unnecessary. This is because the metrics we use (miscoding, inaccuracy, and surfeit) are already defined within the normalized range $[0, 1]$. Consequently, all objectives contribute equally to the evaluation of candidate solutions under the global criterion.

Moreover, another important advantage of the theory of nescience is that all three metrics are inherently commensurable, meaning they are measured using the same units: lengths of computer programs. This shared unit of measurement allows for a coherent and meaningful comparison across the metrics, reinforcing the theoretical consistency and interpretability of the optimization framework.

The following are orther metrics that could be used as global criterion to minimize nescience:

\begin{itemize}
\item Arithmetic mean: $\frac{\mu(r) + \iota(d, r) + \sigma(d, r)}{3}$
\item Geometric mean: $\left( \mu(r) \times \iota(d, r) \times \sigma(d, r) \right)^{1/3}$
\item Product: $\mu(r) \times \iota(d, r) \times \sigma(d, r)$
\item Addition: $\mu(r) + \iota(d, r) + \sigma(d, r)$
\item Harmonic mean: $\frac{3}{ \mu(r)^{-1} + \iota(d, r)^{-1} + \sigma(d, r)^{-1} }$
\end{itemize}

Not all of these metrics qualify as distances, as the geometric mean, product, and harmonic mean do not satisfy the triangle inequality. Moreover, some are not even defined when one of the components is zero, for example, the harmonic mean becomes undefined in such cases. The following paragraphs describe the advantages and disadvantages of each of these metrics.

The Euclidean distance to the ideal vector $(0,0,0)$ offers a geometrically intuitive measure of closeness to perfect knowledge. It treats the three components symmetrically and accounts for their joint magnitude. However, it can bias the solution toward more centrally located points in the objective space and may exclude valid Pareto optimal solutions that lie further from the origin but with highly desirable properties in one metric.

The arithmetic mean provides a simple and interpretable way to aggregate the three metrics, treating each equally. It is widely used due to its mathematical convenience and stability. Nevertheless, it allows compensations (poor performance in one metric can be offset by better performance in others) making it unsuitable when balance among all metrics is crucial.

The geometric mean emphasizes balance by being more sensitive to high values than the arithmetic mean. It discourages solutions that perform poorly in any one metric, making it effective for encouraging uniformly low nescience. However, it is less intuitive and returns zero if any component is zero, which might unfairly suggest perfect knowledge even when other metrics are poor.

The product magnifies the penalty for imbalance: a single large value dominates the result, and a single zero collapses the result to zero. It strongly favors evenly low values across all metrics. While this strictness can be advantageous, it is overly sensitive to small changes, especially near zero, and may mask informative differences in otherwise competitive hypotheses.

The addition is mathematically equivalent to the arithmetic mean (up to scaling) and offers the same interpretability and ease of computation. It is particularly useful when metrics are already normalized, as in the theory of nescience. However, like the mean, it permits trade-offs that might be scientifically undesirable when balance across all three aspects is necessary.

The harmonic mean severely penalizes large values, making it ideal for enforcing balance and avoiding outliers. It is particularly well-suited when the worst-performing metric should drive the overall score. However, it is undefined when any component is zero, and it is more difficult to interpret than other averages.

% Weighting Method

\subsection{Weighting Method}

In the weighting method for solving multi-objective optimization problems, the idea is to associate a weighting coefficient to each objective function and minimize the weighted sum of the objectives. The weighting coefficients $w_i$ are real numbers such that $w_i \geq 0$ for all $i = 1, \ldots, k$. We also require that the weights are normalized, meaning $\sum_{i=1}^k w_i = 1$.

According to the weighting mehtod, the science problem is modified into the following problem:
\begin{align*}
     & \text{minimize}    \quad w_\mu \mu(r) + w_\iota \iota(d, r) + w_\sigma \sigma(d, r) \\
     & \text{subject\;to} \quad \mathbf{x} \in \mathbf{S}
\end{align*}
where $w_\mu + w_\iota + w_\sigma = 1$.

A weighting coefficient of zero is not meaningful, as it would imply that one of the objective functions has no significance whatsoever, an assumption that contradicts the principles of the theory of nescience.

As shown in Proposition \ref{prop:weighted_method_pareto_optimal}, the solutions obtained through the weighted method are guaranteed to be Pareto optimal, although this approach does not capture all Pareto optimal solutions. In standard multi-objective optimization, it is customary to normalize the objective functions to prevent those with larger numerical ranges from disproportionately influencing the outcome. In the case of the theory of nescience, as previously discussed in the context of the global criterion, such normalization is unnecessary because the metrics we employ (miscoding, inaccuracy, and surfeit) are intrinsically defined within the normalized interval $[0, 1]$.

If the weighting method is applied as an a priori approach, a natural question arises: what do the weighting coefficients actually represent within the context of the theory of nescience? These coefficients are often said to reflect the relative importance of the three objectives (miscoding, inaccuracy, and surfeit). However, the meaning of importance in this context is not well-defined and may lead to ambiguity. Rather than interpreting the weights as measures of absolute importance, it is more accurate to view them as expressing the rate at which the decision maker is willing to trade off one metric against another. That is, the weighting coefficients indicate how much increase in one metric the decision maker is willing to tolerate in exchange for a decrease in another, thereby quantifying their tolerance for imbalances among the three dimensions of nescience.

\begin{example}
Suppose a scientist is studying the structure of a newly discovered biological molecule. The current best hypothesis $(r, d)$ has a miscoding of $\mu(r) = 0.2$, an inaccuracy of $\iota(d, r) = 0.3$, and a surfeit of $\sigma(d, r) = 0.6$. The scientist is considering the use of the weighting method to guide the selection of the next hypothesis.

If the scientist assigns weights $w_\mu = 0.1$, $w_\iota = 0.7$, and $w_\sigma = 0.2$, this does not necessarily mean that inaccuracy is more important in some absolute sense. Rather, it reflects the scientist's current willingness to tolerate some miscoding or extra descriptive complexity (surfeit) in exchange for a more accurate model. For instance, the scientist might be aiming for predictive precision in experimental outcomes, even if the underlying representation is suboptimal or the model is longer than ideal.

This weighted preference would steer the optimization process toward hypotheses that reduce inaccuracy, even if they slightly increase miscoding or surfeit. In this way, the weighting coefficients quantify the scientist's subjective trade-offs in light of their practical research goals.
\end{example}

Employing the weighting method as an a priori method presumes that the decision maker's unerlying value function is or can be approximated by a linear function. It must be noted that altering the weighting vectors linearly does not have to mean that the values of the objective functions also change linearly. It is difficult to control the direction of the solutions by the weighting coefficients. Because $\mu,\iota,\sigma \in [0,1]$ but interact non-linearly, the drawbacks of the naive weighting scheme are amplified.

%
% Section: Perfect Knowledge
%

\section{Perfect Knowledge}
\label{sec:perfect_knowledge}

According to the theory of nescience, the fundamental aim of scientific research is to systematically reduce our ignorance concerning the topics under investigation. This ignorance is quantitatively expressed through the notion of nescience, which captures the combined deficiencies in our current understanding. Scientific progress, within this framework, is evaluated by the degree to which a hypothesis, defined as a pair consisting of a representation and a description, reduces the three interdependent components of miscoding, inaccuracy and surfeit. Perfect knowledge, in this context, is said to be achieved when further reductions in nescience are no longer possible. At this point, the nescience associated with the topic reaches its minimum value, signifying that our understanding is both complete and optimally efficient, and no further scientific improvement can be made.

We must distinguish between two notions of perfect knowledge. The first, ideal perfect knowledge, is a theoretical construct that represents a state in which all three components of nescience are exactly zero. This would require a representation that perfectly encodes the entity, a description that exactly reproduces the representation, and no shorter or simpler description being possible. However, this ideal is generally unattainable in practice due to limitations in representation, modeling, and the nature of the entities under investigation. In contrast, Pareto perfect knowledge, reflects the practical achievable implementation of the concept. It corresponds to hypotheses that lie on the Pareto frontier, where no further reduction in one component of nescience can be made without increasing at least one of the others. Thus, Pareto perfect knowledge represents the best feasible approximation to the ideal, balancing trade-offs among miscoding, inaccuracy, and surfeit.

Next, we formally define the concept of (theoretical) ideal perfect knowledge, which occurs when a hypothesis achieves zero miscoding, zero inaccuracy, and zero surfeit.

\begin{definition}
Let $(r, d) \in \mathcal{B}^\ast \times \mathcal{D}$ be a hypothesis. We say that we have attained \emph{ideal perfect knowledge}\index{Ideal perfect knowledge} for the hypothesis $(r, d)$ if $\mu(r) = 0$, $\iota(d, r) = 0$, and $\sigma(d, r) = 0$.
\end{definition}

While perfect knowledge can be achieved with respect to a given representation and its description, there is no mathematical or logical procedure to determine with certainty which entity this perfect knowledge pertains to. The mapping between representations and entities is mediated by an oracle, and since oracles are unknown, the identification of the underlying entity remains epistemologically inaccessible. Consequently, although we can verify that a hypothesis satisfies all the formal conditions for perfect knowledge, we cannot be certain of the true nature of the entity being perfectly known.

A consequence of our definition is that perfect knowledge implies randomness, in the sense of incompressible descriptions.

\begin{proposition}
Let $(r, d) \in \mathcal{B}^\ast \times \mathcal{D}$ be a hypothesis that yields ideal perfect knowledge. Then $K(d) = l(d)$.
\end{proposition}
\begin{proof}
Apply Proposition \ref{prop:zero_surfeit}.
\end{proof}

The common intuition is that a random string conveys no meaningful information, as randomness is often associated with noise or disorder. However, within the framework of the theory of nescience, a random description refers to a description that encodes the maximum amount of information in the smallest possible space—that is, one that contains no redundant elements. Such descriptions are incompressible and thus optimal in terms of descriptive efficiency.

The converse, however, does not generally hold, as the following counterexample demonstrates.

\begin{example}
Aristotelian physics provides an inaccurate description of the physical world, as it makes predictions that are inconsistent with empirical observations, for instance, the claim that planets orbit the Earth. Suppose we take a description of Aristotelian physics and compress it using a standard compression algorithm. The resulting file would be a random description in the sense of having zero redundancy (i.e., it is incompressible). However, despite this lack of redundancy, our nescience would not be zero. That is, our knowledge would not be perfect, since the inaccuracy of the description is not zero.
\end{example}

Ideal perfect knowledge is unique in value, but not in representation or description, meaning that although there may be many different hypotheses (i.e., pairs of representations and descriptions) that all yield zero nescience, they are all equivalent in their informational content, they correspond to the same minimal level of uncertainty or ignorance (i.e., zero). However, these hypotheses can differ in their syntactic form: the representation of the entity or the syntax of the description may vary.

When continued research into a particular topic no longer yields improvements in any of these dimensions—i.e., when no further reduction in miscoding, inaccuracy, or surfeit can be achieved without worsening one of the others—we propose to say that a pareto perfect knowledge has been attained. This does not imply absolute or universal truth, but rather that we have reached the limit of what can be improved given our current symbolic framework. In such a state, the hypothesis lies on the Pareto frontier and corresponds to a point of local optimality, where no further refinement is scientifically justified within the constraints of the theory. The concept of perfect knowledge thus provides a formal stopping criterion for inquiry, signaling that the topic has been fully explored with respect to the goals of scientific understanding as defined by the theory of nescience.

\begin{definition}
Let $(r, d) \in \mathcal{B}^\ast \times \mathcal{D}$ be a hypothesis. We say that we have attained \emph{Pareto perfect knowledge}\index{Pareto perfect knowledge} if $(r, d)$ is Pareto optimal.
\end{definition}

When continued research into a particular topic no longer leads to improvement in any of the three components of nescience without worsening at least one of the others, we propose to say that Pareto perfect knowledge has been attained. This state does not imply an absolute or universal truth, but rather marks the boundary of what can be improved within the current symbolic and methodological framework. At this point, the hypothesis lies on the Pareto frontier\index{Pareto frontier}, corresponding to a condition of local optimality where no further refinement is scientifically justified according to the principles of the theory of nescience. The concept of Pareto perfect knowledge therefore serves as a formal stopping criterion for scientific inquiry, indicating that the topic has been thoroughly explored with respect to the epistemic objectives defined by the theory.

\begin{definition}
Let $(r, d) \in \mathcal{B}^\ast \times \mathcal{D}$ be a hypothesis. We say that we have attained \emph{Pareto perfect knowledge}\index{Pareto perfect knowledge} if $(r, d)$ is Pareto optimal.
\end{definition}

It is important to emphasize that reaching Pareto perfect knowledge does not necessarily mean that our total ignorance, as measured by nescience, is zero. However, any attempt to reduce one of the components of nescience would unavoidably increase at least one of the others. In such cases, further scientific inquiry, understood as the pursuit of reduced overall nescience, ceases to be meaningful. Nevertheless, in certain practical contexts, we might still choose to prioritize one dimension over the others. For example, in high-stakes engineering applications, it may be preferable to reduce inaccuracy even at the expense of greater miscoding or increased surfeit. Such trade-offs are driven by external goals or constraints, rather than the internal logic of the theory of nescience.

%
% Current Best Hypothesis
%

\section{Current Best Hypothesis}

Scientific discovery is inherently iterative. As we explore a topic, we accumulate a set of hypotheses, each composed of a representation and a description, aimed at approximating the underlying entity with increasing accuracy and efficiency. Within this evolving set of candidate hypotheses, it is both natural and practically useful to identify a preferred hypothesis. We refer to this distinguished hypothesis as the current best hypothesis. It represents the best approximation to perfect knowledge that we have found so far and serves as a concrete benchmark against which scientific progress can be measured.

\begin{definition}
Let $e \in \mathcal{E}$ be an entity, and let $\hat{\mathcal{H}}_e$ denote the collection of known hypotheses about $e$. We designate a distinguished element of $\hat{\mathcal{H}}_e$ as our \emph{current best hypothesis}\index{Current best hypothesis}.
\end{definition}

Our current best hypothesis should be minimal with respect to at least one of the three components (miscoding, inaccuracy, or surfeit) within the set $\hat{\mathcal{H}}_e$. The selection of a particular metric as the basis for minimization may lead to different hypotheses being identified as the current best. Ideally, the current best hypothesis would be minimal with respect to two, or even all three components simultaneously; however, this is not always attainable given the current set of known hypotheses for every entity.

\begin{example}
Suppose we are studying a physical phenomenon such as planetary motion. We consider three competing hypotheses: (1) a geocentric representation with a descriptive model based on epicycles, (2) a heliocentric representation with elliptical orbits, and (3) a relativistic representation with spacetime curvature. Our current best hypothesis would the third one, as it achieves the lowest nescience given the representations and descriptions we have investigated so far.
\end{example}

In some scientific research scenarios, it is common to fix a particular representation, such as the result of an experiment or a dataset composed of measured data, and search only for the description that best models that representation. This motivates the definition of a related but more restricted notion: the best description for a given representation.

\begin{definition}
Let $r \in \mathcal{R}$ be a representation, and let $\hat{\mathcal{D}}_r$ denote the collection of known descriptions of $r$. We designate a distinguished element of $\hat{\mathcal{D}}_r$ as our \emph{current best description}\index{Current best description}.
\end{definition}

As in the case of the current best hypothesis, the current best description should be minimal with respect to at least one of the two components, inaccuracy and surfeit, within the set $\hat{\mathcal{D}}_r$. For most representations $r$, it is generally not possible to minimize both components simultaneously.

While this approach simplifies the search space and is often motivated by convenience or domain conventions, the theory of nescience discourages fixing the representation in advance. This restriction introduces a significant epistemological risk: one may fall into a local minimum of the nescience landscape, where improvements to the description cannot reduce ignorance further, even though a different representation might unlock a much lower nescience value when paired with an appropriate description. A more robust scientific methodology should simultaneously explore alternative representations and descriptions to maximize the chance of converging to a global minimum of nescience.

Excellent. Here's a revised version of your paragraph that includes a practical example more aligned with your preference—where selecting a different subset of attributes, possibly enhanced with external data, leads to a better model:

\begin{example}
Consider a machine learning task to predict customer churn in a telecommunications company. A standard approach might involve using all available customer attributes, such as service usage metrics, demographic information, and past complaint history, as a fixed representation. A model is then trained to minimize prediction error on this data. Suppose that after exhaustive hyperparameter tuning and model selection, the best model still shows significant error. This may indicate that the current representation is suboptimal. A more insightful representation might focus on a carefully chosen subset of attributes, perhaps augmented with external data such as regional economic indicators or customer sentiment extracted from support call transcripts.
\end{example}

%
% Section: Unknown Unknown
%

\section{Unknonwn Unknown}

In Chapter \ref{chap:Introduction}, we introduced the concept of the unknown unknown region, an area encompassing problems for which we not only lack solutions but are entirely unaware of their existence. Within the framework of the theory of nescience, one of the central objectives is to develop a systematic procedure for identifying and exploring potential research entities hidden within this region (refer to Chapter \ref{chap:Interesting-Research-Questions} for a detailed procedure on how to approach this task). In this section, we provide a formal characterization of the unknown unknown region and examine its properties.

To uncover what lies hidden within the unknown unknown region, we must first establish the boundary of what is already known. We define this boundary not merely by the existence of hypotheses about a topic, but by the quality of our current knowledge.

\begin{definition}
Let $e \in \mathcal{E}$ be an entity, and let $\hat{\mathcal{H}}_e$ denote the collection of known hypotheses about $e$. If there exists a hypothesis $h \in \hat{\mathcal{H}}_e$ that is Pareto optimal we say that $e$ belongs to the set \emph{known knowns}\index{Known knowns} (denoted by $\mathcal{E}_{KK}$).
\end{definition}

This definition identifies as known knowns those entities for which our current best hypotheses are not only available but have achieved a local optimum in the tradeoff between miscoding, inaccuracy, and surfeit. In practice, however, determining the exact set of known known entities is far from straightforward. Assessing whether a given hypothesis lies on the true Pareto frontier is, in general, undecidable. Consequently, our classification of entities as known knowns must be regarded as provisional and subject to revision as our knowledge evolves.

In addition to identifying what we already understand perfectly, we must also recognize the known unknowns, those entities or topics we acknowledge as scientifically relevant but for which our current understanding remains incomplete. These are areas where our ignorance is recognized, and active efforts are being made to reduce it through research.

\begin{definition}
Let $e \in \mathcal{E}$ be an entity, and let $\hat{\mathcal{H}}_e$ be the collection of known hypotheses about $e$. If $\hat{\mathcal{H}}_e \neq \varnothing$ and no hypothesis $h \in \hat{\mathcal{H}}_e$ is Pareto optimal, we say that $e$ belongs to the set \emph{known unknown}\index{known unknown} (denoted by $\mathcal{E}_{KU}$).
\end{definition}

Known unknowns are entities for which we possess hypotheses, but none of them lie on the Pareto frontier. That is, each known hypothesis can be improved in at least one component of nescience without increasing the others. This implies that our current models are suboptimal and that further scientific progress is achievable. As before, identifying the set of known unknowns in practice is challenging. It requires not only recognizing which entities have been explicitly studied, but also verifying that hypotheses have been formally documented, typically through publications, datasets, or other structured records.

The unknown unknowns correspond to entities for which no hypothesis has ever been proposed. These are aspects of reality that lie entirely beyond the scope of our current scientific awareness. We are not only ignorant of their true nature, but also unaware of their very existence.

\begin{definition}
Let $e \in \mathcal{E}$ be an entity, and let $\hat{\mathcal{H}}_e$ be the collection of known hypotheses about $e$. If $\hat{\mathcal{H}}_e = \varnothing$, we say that $e$ belongs to the set \emph{unknown unknown}\index{unknown unknown} (denoted by $\mathcal{E}_{UU}$).
\end{definition}

In the theory of nescience, all entities for which no hypotheses are currently known are considered part of the realm of the unknown unknown. This includes both entities that may become knowable in the future (given improved representations or descriptions), and those that might remain permanently inaccessible (see Section \ref{sec:what-is-an-entity}). The theory of nescience does not distinguish between knowable and unknowable unknowns, as such a distinction is not operationally meaningful within a framework grounded in symbolic representations.

Every knowable entity belongs to exactly one of three epistemic categories: known knowns, known unknowns, or unknown unknowns. The following proposition formalizes this trichotomy.

\begin{proposition}
Let $\mathcal{E}$ be the set of all entities. Then:
\[
\mathcal{E} = \mathcal{E}_{KK} \cup \mathcal{E}_{KU} \cup \mathcal{E}_{UU}
\quad \text{and} \quad
\mathcal{E}_{KK} \cap \mathcal{E}_{KU} = \mathcal{E}_{KK} \cap \mathcal{E}_{UU} = \mathcal{E}_{KU} \cap \mathcal{E}_{UU} = \varnothing
\]
\end{proposition}
\begin{proof}
Let $e \in \mathcal{E}$ be arbitrary. By definition, the hypothesis set $\hat{\mathcal{H}}_e$ associated with $e$ is either empty or non-empty. If $\hat{\mathcal{H}}_e = \varnothing$, then, by definition, $e \in \mathcal{E}_{UU}$. If  $\hat{\mathcal{H}}_e \neq \varnothing$, then two cases are possible: i) if there exists $h \in \hat{\mathcal{H}}_e$ such that $h$ is Pareto optimal, then $e \in \mathcal{E}_{KK}$; ii) if all $h \in \hat{\mathcal{H}}_e$ are not Pareto optimal, then $e \in \mathcal{E}_{KU}$. Therefore, every $e \in \mathcal{E}$ belongs to at least one of the three subsets.

To show that these subsets are pairwise disjoint, assume by contradiction that an entity $e$ belongs to both $\mathcal{E}_{KK}$ and $\mathcal{E}_{KU}$. Then $\hat{\mathcal{H}}_e \neq \varnothing$, and both, $\exists h \in \hat{\mathcal{H}}_e$ that is Pareto optimal (by membership in $\mathcal{E}_{KK}$), and $\forall h \in \hat{\mathcal{H}}_e$, $h$ is not Pareto optimal (by membership in $\mathcal{E}_{KU}$), which is a contradiction.

Similar contradictions arise if $e$ belongs to both $\mathcal{E}_{KU}$ and $\mathcal{E}_{UU}$ or both $\mathcal{E}_{KK}$ and $\mathcal{E}_{UU}$, since $\mathcal{E}_{UU}$ requires $\hat{\mathcal{H}}_e = \varnothing$.
\end{proof}
     
We are concerned not only with what we know or do not know, but also with the structural boundaries that separate these domains. The boundary that separates the set of entities for which at least one hypothesis is currently known (i.e., the known) from those for which no hypotheses exist (i.e., the unknown unknown) is referred to as the knowledge frontier.

Before doing so, we must introduce the concept of an anti-Pareto optimal hypothesis, which is one where no component of nescience can be made worse without improving at least one of the others. This notion mirrors the definition of Pareto optimality, but in reverse.

\begin{definition}
Let $\mathcal{H}_e$ be the collection of hypotheses about an entity $e \in \mathcal{E}$. We say that $(r, d) \in \mathcal{H}_e$ is \emph{anti-Pareto optimal}\index{Anti-Pareto optimal hypothesis} for $e$ if, for all $(r', d') \in \mathcal{H}_e \setminus {(r, d)}$, the following holds: if
\[
\mu(r') > \mu(r),\quad \iota(d', r') \geq \iota(d, r),\quad \text{and} \quad \sigma(d', r') \geq \sigma(d, r),
\]
then at least one of the following is strictly true:
\[
\iota(d', r') < \iota(d, r),\quad \text{or} \quad \sigma(d', r') < \sigma(d, r).
\]
The condition must also hold symmetrically for permutations involving $\iota$ and $\sigma$.
\end{definition}

This definition captures the idea that the hypothesis lies at a point of locally maximal nescience, any attempt to increase ignorance along one dimension (e.g., adding more miscoding) will necessarily force a reduction in ignorance along at least one of the remaining dimensions (e.g., increased accuracy or reduced redundancy).

\begin{definition}
Let $\mathcal{E}_{K}$ be the set of known entities. The \emph{knowledge frontier}\index{Knowledge frontier} is defined as the set:
\[
\mathcal{F} = \left\{ e \in \mathcal{E}_{K} \;\middle|\; \text{the current best hypothesis is anti-Pareto optimal} \right\}.
\]
\end{definition}

This definition situates the knowledge frontier at the outermost edge of our current understanding. These are the entities for which: (i) at least one hypothesis is known; (ii) the best-known hypothesis is anti-Pareto optimal, meaning that any further degradation in one dimension of nescience necessarily leads to an improvement in at least one of the others; and (iii) no meaningful scientific degradation is possible without paradoxically improving the hypothesis. This configuration marks the conceptual boundary between the barely known and the unexplored.

A new research entity is any entity that lies beyond the current knowledge frontier. That is, it is an entity for which no hypothesis has yet been formulated, recorded, or studied. These entities exist within the realm of the unknown unknown, not only do we lack understanding of them, but we are not even aware of their existence. Identifying such entities represents the initial and most foundational step in expanding scientific knowledge, since they mark the points at which our current understanding fails to even formulate a question.

\begin{definition}
Let $\mathcal{E}$ denote the set of all knowable entities, and let $\hat{\mathcal{H}}_e$ be the collection of known hypotheses about an entity $e \in \mathcal{E}$. We say that $e$ is a \emph{new research entity} if $\hat{\mathcal{H}}_e = \varnothing$.
\end{definition}

New research entities are, by definition, members of the unknown unknown region of the knowledge space. They have not been explicitly represented or described, and no attempt has yet been made to understand them through a scientific hypothesis. The identification and formalization of such entities is central to the methodology proposed by the theory of nescience: only by expanding the set of known entities can we ensure the continuous reduction of global ignorance.

A new research entitie refer to those entities for which no hypothesis has yet been proposed. By definition, such entities fall into the class of unknown unknowns. The following proposition formalizes this relationship.

\begin{proposition}
Let $\mathcal{E}_{NRE} \subseteq \mathcal{E}$ be the set of all \emph{new research entities}, defined as entities $e \in \mathcal{E}$ such that $\hat{\mathcal{H}}_e = \varnothing$ and $e$ has not yet been discovered or studied. Let $\mathcal{E}_{UU} \subseteq \mathcal{E}$ be the set of all \emph{unknown unknowns}, defined by $\mathcal{E}_{UU} = \{ e \in \mathcal{E} \mid \hat{\mathcal{H}}_e = \varnothing \}$. Then, $\mathcal{E}_{NRE} \subseteq \mathcal{E}_{UU}$.
\end{proposition}
\begin{proof}
Let $e \in \mathcal{E}_{NRE}$ be an arbitrary new research entity. By the definition of new research entity, we have $\hat{\mathcal{H}}_e = \varnothing$. But this condition is precisely the definition of membership in $\mathcal{E}_{UU}$. Therefore, $e \in \mathcal{E}_{UU}$. Since every element of $\mathcal{E}_{NRE}$ is also in $\mathcal{E}_{UU}$, it follows that: $\mathcal{E}_{NRE} \subseteq \mathcal{E}_{UU}$.
\end{proof}

This result captures the foundational idea that research innovation arises from exploring the unknown unknown region. By definition, any new scientific entity must originate from an epistemically uncharted area, one where no hypotheses currently exist.

%
% Section: Science vs. Pseudoscience
%

\section{Science vs. Pseudoscience}

In the theory of nescience, scientific progress is measured by the systematic reduction of ignorance. As we propose and validate hypotheses about previously unstudied entities, those entities transition from the unknown unknown region to either the known known or known unknown regions. From this perspective, the set of unknown entities should decrease over time.

\begin{proposition}
Let $\mathcal{E}^{(t)}_{UU}$ denote the set of unknown unknown entities at time $t$ and $\mathcal{E}^{(t+1)}_{UU}$ at a posterior time. Then, $\mathcal{E}^{(t+1)}_{UU} \subseteq \mathcal{E}^{(t)}_{UU} \quad \text{for all } t \in \mathbb{N}$.
\end{proposition}
\begin{proof}
At each time step $t$, let the process of scientific discovery introduce new hypotheses about entities in $\mathcal{E}$, thereby moving those entities from the unknown unknow region into the known known region (either known unknowns or known known).
\end{proof}

In addition to the reduction in the cardinality of the unknown unknown region, we can also observe a progressive reduction in the nescience of individual entities as more refined hypotheses are introduced. Recall that the nescience of an entity is defined based on its current best hypothesis.

\begin{proposition}
Let $e \in \mathcal{E}$ be an entity such that $\hat{\mathcal{H}}^{(t)}_e$ and $\hat{\mathcal{H}}^{(t+1)}_e$ are the collections of known hypotheses about $e$ at times $t$ and $t+1$, respectively. Then, if a new hypothesis $h' \in \hat{\mathcal{H}}^{(t+1)}_e \setminus \hat{\mathcal{H}}^{(t)}_e$ is such that $\nu(h') < \nu(h)$ for all $h \in \hat{\mathcal{H}}^{(t)}_e$, the nescience of $e$ satisfies:

$$
\nu^{(t+1)}(e) < \nu^{(t)}(e),
$$

where $\nu^{(t)}(e)$ denotes the nescience of the current best hypothesis at time $t$.
\end{proposition}

\begin{proof}
By definition, we have that $\nu^{(t)}(e) = \min_{h \in \hat{\mathcal{H}}^{(t)}_e} \nu(h)$ and $\nu^{(t+1)}(e) = \min_{h \in \hat{\mathcal{H}}^{(t+1)}_e} \nu(h)$. If a new hypothesis $h' \in \hat{\mathcal{H}}^{(t+1)}_e$ is added such that $\nu(h') < \nu^{(t)}(e)$, then $\nu^{(t+1)}(e) = \nu(h') < \nu^{(t)}(e)$.
\end{proof}

This result reflects the iterative nature of scientific inquiry: as we formulate new hypotheses or improve existing ones, the combined errors associated with our representations and descriptions tend to diminish. Over time, and under continued research, the nescience of most entities should asymptotically approach its minimum, potentially reaching the Pareto frontier, or in rare cases, even ideal perfect knowledge.

This characteristic trend of decreasing nescience offers a powerful criterion for distinguishing scientific disciplines from pseudoscientific ones. In genuine scientific fields, the average nescience of topics demonstrably declines over time as knowledge improves. In contrast, pseudoscientific domains typically exhibit stagnation in nescience: either the number of proposed hypotheses remains static or their quality fails to improve, leading to no measurable reduction in ignorance. Thus, the presence or absence of a decreasing trend in nescience provides a formal, quantitative indicator for demarcating science from pseudoscience.

%
% Section: Nescience of Areas
%

\section{Nescience of Areas}
\label{sec:nescience_areas}

As discussed in Section \ref{sec:areas}, entities can be grouped into research areas, defined as subsets $\mathcal{A} \subset \mathcal{E}$ of the overall entity space. The concept of a research area is meaningful when the entities in $\mathcal{A}$ share a common epistemic domain or possess a unifying property, such as belonging to the same scientific field or addressing a related phenomenon. To quantify how much we do not know about a research area $\mathcal{A}$, we must work with the subset of entities within $\mathcal{A}$ for which at least one hypothesis is currently known $\hat{\mathcal{A}} \subseteq \mathcal{A}$. A representation of the area $\mathcal{A}$ is then a symbolic encoding $R_{\hat{\mathcal{A}}}$ of the known entities in $\hat{\mathcal{A}}$, suitable for further descriptive analysis. Given this representation, we define a description of the area $\mathcal{A}$ as a string $d_{\hat{\mathcal{A}}}$ that models or summarizes the structure or content of $R_{\hat{\mathcal{A}}}$.

The concept of nescience can be extended from individual entities to entire research areas, allowing us to quantitatively assess how well a given area is understood. This extension relies on generalizing the core components of nescience to sets of entities. We use the notions of combined miscoding of the known subset (see Section \ref{sec:miscoding_areas}), combined inaccuracy (see Section \ref{sec:inaccuracy_areas}), and combined surfeit (see Section \ref{sec:surfeit_areas}) to define a composite measure of nescience at the area level.

In practice, due to the difficulty of precisely identifying the entire known subset $\hat{\mathcal{A}} \subseteq \mathcal{A}$, it is often convenient to use approximations. One practical and interpretable approximation is the notion of average nescience, which provides a summary of the epistemic quality of the known entities within the area.

\begin{definition}
Let $\mathcal{A} \subset \mathcal{E}$ be an area, and $\hat{\mathcal{A}}$ be the subset of known entities. The \emph{average nescience of the area} is defined as:
\[
\bar{\nu}(\mathcal{A}) = \frac{1}{|\hat{\mathcal{A}}|} \sum_{e \in \hat{\mathcal{A}}} \nu(e),
\]
where $\nu(e)$ denotes the nescience of the current best hypothesis about entity $e$ given a particular decision maker.
\end{definition}

For instance, when dealing with research topics, a research area may correspond to a broad disciplinary domain, such as biology, mathematics, or physics, each comprising a collection of entities that fall under that domain. In this context, the area of biology would include all research topics formally classified within the biological sciences. This classification allows us to compute and compare the nescience of distinct knowledge domains by aggregating the nescience of the individual topics they encompass (see Section \ref{sec:measuring_research_areas}). Such comparisons provide insight into which areas of human knowledge remain most poorly understood and where future research efforts might be most impactful.

%
% Section: References
%

\section*{References}

Here are some selected references that are particularly relevant to the concept nescience, along with brief explanations of their relevance.

\cite{li2013introduction} is a foundational text in algorithmic information theory, central to defining concepts such as description length, randomness, and information content. These are directly used in our theory of nescience to formalize inaccuracy and surfeit. \cite{chaitin1969simplicity} provides key ideas on the relationship between program length and algorithmic simplicity. This work contributes to the formal underpinnings of inaccuracy and model complexity in the theory of nescience. \cite{cover2012elements} A comprehensive treatment of classical information theory, including entropy, mutual information, and coding theorems. These concepts are foundational for measuring redundancy and assessing the informativeness of representations in our framework. \cite{grunwald2007minimum} is irectly relevant to the concept of surfeit in nescience. The MDL principle formalizes model selection based on description length, which parallels the idea of seeking non-redundant descriptions. \cite{solomonoff1964formal} Solomonoff's work on algorithmic probability underlies the notion of model uncertainty and prediction, both of which are implicitly addressed in our theory's pursuit of minimal ignorance. \cite{kolmogorov1965three} lays the groundwork for the use of Kolmogorov complexity as a measure of information, randomness, and compressibility, all essential in quantifying nescience. \cite{turing1936computable} provides the foundational model of computation used throughout the theory of nescience. The theory's reliance on representations and oracle machines assumes the basic framework established by Turing. \cite{calude2002information} explores algorithmic complexity and randomness in depth, offering a broader perspective that connects well with our treatment of knowledge, representation, and incompleteness in the theory of nescience. \cite{chaitin1995berry} illustrates limits of formal descriptions and links to incompleteness phenomena. This is relevant for understanding the boundaries of compressibility and the epistemological challenges in defining knowledge. \cite{miettinen2012nonlinear} is crucial for our use of Pareto and anti-Pareto frontiers in describing tradeoffs among miscoding, inaccuracy, and surfeit. Provides the theoretical tools for reasoning about optimality in multi-dimensional knowledge spaces. \cite{popper2014conjectures} while not technical, this work provides a philosophical background on how scientific knowledge evolves through falsification, a process aligned with your model's notion of reducing nescience via hypothesis revision. \cite{suppes2002representation} addresses the problem of how scientific structures relate to the entities they describe, an issue directly relevant to your notion of representations, miscoding, and scientific models.
