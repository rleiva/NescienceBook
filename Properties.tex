%
% CHAPTER 8.- Properties of Nescience
%

\chapterimage{Philosophers.pdf}

\chapter{Advanced Properties}
\label{apx:Properties-Nescience}

\begin{quote}
\begin{flushright}
\emph{Invert, always invert.}\\
Carl Gustav Jacob Jacobi\\
\end{flushright}
\end{quote}
\bigskip

This chapter covers more advanced mathematical properties of the concept of nescience. This chapter can be safely skipped by those readers interested only in the applications of nescience. However, it is highly recommended to read it, since if provides a deeper understanding of what nescience is exactly.

{\color{red} TODO: Explain the abstract nature of the axioms vs. the interpretation we have provided in the previous chapters. Mention that perhaps there exists other interpretations.}

Since the time of David Hilbert, mathematics is about the study of the properties of abstract objects and their relations, without paying too much attention to what these objects are or represent. Mathematicians create (or discover) abstract frameworks of logic that can have multiple interpretations. It is up to applied scientists to provide those interpretations. In the same way, we can provide an abstract definition of the concept of nescience, and study its properties, without making any explicit reference to science nor to the scientific method. In doing so, we loose the interpretability of our theory, but, on the other side, we could apply the same results to other disciplines.

{\color{red} Extend this introduction with a very short review of the topics covered in the chapter.}

%
% Section: Axioms
%

\section{The Axioms of Science}

{\color{red} TODO: Say something intelligent here.}

In this section we are going to propose a collection of axioms that formalize what is this thing called science. 

In the previous section we have provided a formalization of the theory of nescience based in set theory and first order logic. Set theory is not the only available framework in which mathematics can be formalized. We could have used type theory or category theory instead. Having meaniful axioms of our theory in multiple formalization frameworks, such as set theory, type theory, and category theory, will constitute strong evidence that nescience is a fundamental concept in mathematics, and not a mere artifact of a particular formalization.

%
% Axioms based on Model Theory
%

\subsection{Model Theory}

Our first approximation to the problem of how to formalize the theory of nescience is a collection of axioms based on first-order logic and the ZFC axioms of set theory with equality (see Appendix \ref{apx:foundations_mathematics}). In this section we will also prove some basic results and explain how these axioms relate to the new ideas we have introduced in this book. For this axiomatization we are not going to follow the approach described in the previous chapters, that is, we are not going to explicitly definine the quantities of miscoding, surfeit and inaccuracy. Instead, we will introduce the concatenation and conditional operations, list their fundamental properties, and explain how nescience is afected by them. The remaining concepts follow naturally from these basic axioms.

\begin{definition}

Let $\mathcal{L}$ be a non-empty set called \emph{language} whose elements are called \emph{strings}. We define \emph{science} as the first-order logic structure $(\mathcal{L} \mid \lambda, \mathcal{O}, <_N, \oplus, \mid)$ where:

\vskip 0.25cm

\begin{enumerate}[label=(\roman*)]
\item $\lambda \in \mathcal{L}$ is distinct element called \emph{neutral},
\item $\mathcal{O}$ is a relation called \emph{oracle},
\item $<_N$ is a relation called \emph{nescience},
\item $\oplus$ is a binary function called \emph{concatenation}, and
\item $\mid$ is a binary function called \emph{conditional}
\end{enumerate}

\vskip 0.25cm

that satisfies the following axioms:

\vskip 0.25cm

\begin{itemize}

% Oracle
\item[A1] $\forall t \in \mathcal{L} \; t \mathcal{O} t$.
\item[A2] $\forall s , t \in \mathcal{L}$ if $s \mathcal{O} t$ then $t \mathcal{O} s$.
\item[A3] $\forall r, s , t \in \mathcal{L}$ if $r \mathcal{O} s$ and $s \mathcal{O} t$ then $r \mathcal{O} t$.

\vskip 0.25cm

% Nescience
\item[A4] $\forall t \in \mathcal{L} \; \lnot t <_N t$.
\item[A5] $\forall s , t \in \mathcal{L}$ if $s <_N t$ then $\lnot t <_N s$.
\item[A6] $\forall r , s, t \in \mathcal{L}$ if $r <_N s$ and $s <_N t$ then $r <_N t$.

\vskip 0.25cm

% Concatenation
\item[A8] $\forall s, t \in \mathcal{L} \; \oplus(s, t) = \oplus(t, s)$.
\item[A9] $\forall s \in \mathcal{L} \; \oplus(s, \lambda) = \oplus( \lambda, s) = s$.
\item[A10] $\forall r, s, t \in \mathcal{L} \; \oplus(\oplus(r, s), t) = \oplus(r, \oplus(s, t))$.

\vskip 0.25cm

% Conditional
\item[A11] $\forall s \in \mathcal{L} \; \mid (s, \lambda) = s$.
\item[A12] $\forall s \in \mathcal{L} \; \mid (s, s) = \lambda$.

\end{itemize}

\end{definition}

Axioms A1, A2 and A3 state that the oracle $\mathcal{O}$ is an equivalence relation; the nescience relation $<_N$ described by Axioms A4, A5 and A6 is a strict partial order; the concatenation operation $\oplus$ defined by Axioms A8, A9 and A10 together with $\mathcal{L}$ forms a free monoid; and Axioms A11 and A12 define the behaviour of the conditional operator $\mid$. 

We still need two more axioms to fully characterize the behaviour of our logic structure. But first we have to introduce some and additional concept.

\begin{definition}
Let $\mathcal{L} / \mathcal{O}$ be the quotation set defined by the oracle relation over the language set. We call \emph{entity}, denoted by $[e]$, to every class of this quotation set, that is, $[e] \in \mathcal{L} / \mathcal{O}$.
\end{definition}

With the next Axiom we require that every entity contains at least one minimal string with respect to the nescience ordering.

\begin{definition}[Axiom A13]
For every entity $[e] \in \mathcal{L} / \mathcal{O}$ there exists at least one $r \in [e]$ such that it is minimal with respect to $<_N$, that is, it does not exists an $s \in [e]$ such that $s <_N r$.
\end{definition}

Our last axiom referts to how nescience decreases.

\begin{definition}[Axiom A14]
Let $t \in \mathcal{L}$ be a non-minimal element, then:
\begin{enumerate}[label=(\roman*)]
 \item there exists $s$ such that $\oplus \left(t, s \right) <_N t$ , or
 \item there exists $s$ such that $\mid \left(t, s \right) <_N t$.
\end{enumerate}
\end{definition}

% Interpretation of the Axioms

\subsubsection*{Interpretation of the Axioms}

The first thing to note about our proposal is that the set $\mathcal{E}$ of entities in which we are interested is not part of the axioms. Instead, the entities are studied indirectly trought a language set $\mathcal{L}$. Furthermore, we have not provided any indication about the nature of the elements of $\mathcal{L}$ besides that it must be a non-empty set. In this sense, $\mathcal{L}$ could be anything that satisfy our axioms. For example, $\mathcal{L}$ could be the set $\mathcal{B}^\ast$ of finite binary strings, in which case nescience will be based on string length; or it could be the set $\mathbb{N}$ of natural numbers, and derive nescience from the ordering of these numbers\footnote{\color{red} TODO: Be a little bit more specific and mention in each case which one is the neutral element, and how concatenation and conditional could be defined. Ideally, provide a third, non-trivial, example.}. This approach of studying the properties of a set without specifying the nature of its elemens (the standard approach used in the mathematics of the last century) has some advantages and disadvantages. The main advantage is that perhaps we could apply our theory to other areas (yet to be discovered) for which the theory is not intended. The limitation is that this abstract nature of the axioms makes more difficult to apply the theory in practice, for example, to derive practical algorithms that compute the new proposed metrics.

The only tool we have at our disposal to match the strings of $\mathcal{L}$ with the entities of $\mathcal{E}$ is the oracle, and this matching has to be done in a indirect way. The oracle defines an equivalence relation that splits the set $\mathcal{L}$ into equivalence classes. Each equivalence class corresponds to an entity of $\mathcal{E}$, and it might happens that not all entities of $\mathcal{E}$ have an associated class (what we have called the unknowable unknown). All the strings are related to some entity, and some of them would be better than others (i.e. lower nescience). No string can be part of two different entities. For each collection of $\mathcal{E}$ there could be more than one valid oracle. The details (inner workings) of how the oracles match strings to entities is not covered by the axioms.

We cannot provide a quantitative measure for the concept of nescience, since numbers are not part of our axioms. Even if we use as underline set $\mathcal{L}$ the set of natural numbers $\mathbb{N}$, the symbol $+$ and its properties are not part of our logic structure. Instead what we have provided is a relative ordering of the different elements of $\mathcal{L}$, intuitively, according to how much we do not known given those strings. The ordering has to be partial, i.e. not every pair of elements of $\mathcal{L}$ can be compared. This partial order is applicable not only in case of strigs that belong to different entities, but also it can happen with strings that belong to the same entity. The order has also to be strict, i.e. nescience equality is not defined. The problem of assuming a non-strict total order for nescience is that if $s <_N t$ and $t <_N s$ then it should be the case that "s = t", that is, if two strings have the same nescience, they should be the same string, and this is not necessarily the case. How nescience is assigned to the elements of $\mathcal{L}$ is not covered by the axioms.

The problem of having multiple styles for the same entity is not explicitly addressed by the axioms, although it is implicit throught the use of minimal elements (each minimal element could be related to each particular style). We do require that each equivalence class has at least one minimal element. An equivalence class could have more than one minimal element, and we do not require that classes have a minimum. Intuitively, each minima would correspond to each of the valid ways of representing the entity. We do not expect strings from different representation styles to be directly comparable. Finally, we do not require the existence of global minimum nor global minimas for the set $\mathcal{L}$.

If a string $s$ is not a local minima for its class with respect to the nescience ordering, there must exists another string $t$ with smaller nescience. There are two ways in which we can find this string, that is, to decrease our nescience about the string: either by concatenating the string with another one, or by conditioning the string to another one.

If the string $s$ is missing some critical informaton required to encode the entity in which we are interested, we could extend $s$ with additional symbols, by means concatenating $s$ with other strings with the relevant symbols. It the string $s$ contains non-relevant or even wrong information, we could get rid of that information by assuming that $s$ is the concatenation of two or more strings, and removing the non-relevant substrings. Concatenation also allow us to discover new entities: concatenating two strings that belong to different entities might lead to a new, previously unknown, entity. In this sense, concatenation would implement the exploration part in this schema of exploration/exploitation in which science is characterized.

Conditioning is the tool that we have to our disposal to leverage on already existing knowledge. The difference between concatenation and conditioning is that concatenation add something to our string, meanwhile conditioning allow us to use something (if needed) without extending our current string. Conditional would implement the exploitation part in this science schema of exploration/exploitation.

% Basic Properties

\subsubsection*{Basic Properties}

First of all we will introduce some notational conventions to simplify the algebraic operations dealing with nescience.

\begin{notation}
We will use the infix notation for the concatenation function, that is, we will write $s \oplus t$ instead of the $\oplus(s, t)$. Moreover, given Axiom A10, we will drop parenthesis in case of multiple concatenations.

We will use the infix notation for the conditional function, that is, we will write $s \mid t$ instead of the $\mid(s, t)$.
\end{notation}

It is also convenient to introduce the symbol $=_N$ to represent the case that our unknown given the strings $s$ and $t$ is the same. We will apply this symbol only if both strings belong to the same equivalence class.

\begin{notation}
Let $[e]$ be an entity, and $s, t \in [e]$ two strings. We denote by $ s =_N t$ the case that $(s, t) \notin <_N$.
\end{notation}

{\color{red} Conditional is non-decreasing wrt nescience}

\begin{proposition}
Let $s$ and $t$ two arbitrary strings, then we have that $s <_N (s \mid t)$.
\end{proposition}
\begin{proof}
{\color{red} TO DO}
\end{proof}

{\color{red} TODO: Introduce the concepts of minimal and valid.}

{\color{red} TODO: Prove that minimal implies valid.}

{\color{red} TODO: Prove that joining two valid strings is a valid string.}

{\color{red} TODO: Distributive Law - ((r |c s) <+> t) <n ((r <+> t) |c (s <+> t)).}

% Axiomatic Definition of the Elements of Nescience

\subsubsection*{Axiomatic Definition of the Elements of Nescience}

As we have said at the introduction of this section, the collection of proposed axioms do not expliclty mention the concepts of miscoding, inaccuracy and surfeit. Moreover, in the set $\mathcal{L}$ we do not distinguish between representations and models. All these elements are introduced as a particular interpretation of the axioms, the one we have been developing in Part II of this book. In this section we are going to prove that our interpretation of science satisfies the science axioms.

We start by assuming that the underline set $\mathcal{L}$ is the set of all finite binary strings $\mathcal{B}^\ast$. We also assume that this set is composed by two kind of strings: representations, that are regular strings, and models, that are strings that encode a particular Turing machine assuming a fixed universal oracle machine. Each equivalence class will contain all possible representations and descriptions of that entity, including the wrong ones. We have also to assume that the oracle knows if a particular string is a representation or a description, and proceeds accordingly. For example, if the string is a representation, the oracle could do nothing, leaving the string as is, but if the string is a model, then the oracle could run the model (using our universal Turing machine) and use the output as a representation. Distinguishing between representations and descriptions also implies that the operation of concatenation has more sense in case of representations, and the operation of conditioning would be intented for descriptions. Concatenation would be used to include in our representations all the information needed to encode the entity  (string concatenation), and conditional would be used to make descriptions shorter, by leveraging on other, already existing, models (conditional complexity).

{\color{red} TODO: Prove that our mododified universal oracle machine is an equivalence relation}

{\color{red} TODO: Introduce the concepts os miscoding, surfeit and inaccuracy, and nescience.}

{\color{red} TODO: Prove that nescience is a strinct partial order.}

{\color{red} TODO: Prove that string concatenation is a free monoid. For the case of regular strings, for the case of models, and for mixed concatenations.}

{\color{red} TODO: Prove that the axioms related to conditional satisfied the axioms. For the case of regular strings, for the case of models, and for mixed concatenations.}

{\color{red} TODO: Prove that each equivalence class has at least one minimal element.}

{\color{red} TODO: Prove that the nescience reduction axiom in fact is satisfied.}

%
% Axioms based on Type Theory
%

\subsection{Type Theory}
\label{sub:ax_type_theory}

In this section we are going to provide a formalization of the theory of nescience in the context of type theory (see Section \ref{sec:lambda_calculus}). Type theory has some advantages over set theory. The most important is that it is a constructive theory, which means that we do not assume the existence of abstract mathematical entities that satisfy some properties, but we show how to construct those entities. For example, there is no need to resort to an abstract, uncomputable, oracle. In type theory, all propositions and proven theorems have an equivalent computable function or algorithm, and thus, we can provide computer programs to solve all problems addressed by our theory (see Section \ref{sec:nescience_library} for a practical implementation of some of these algorithms in the form of a software library).

A second advantage of type theory is that the lambda terms used in the theory are by definition computable functions, and that lambda calculus is a Turing machine capable of universal computation. In the theory of nesciece we require that our models be lambda terms, and that our universal Turing machine be the lambda calculus. In this sense, our models are native elements within the theory, not external artifacts based on an arbitrary, axiomatically defined, universal machine. The models that describe entities are lambda terms executed in the univeral Turing machine of lambda calculus.

The third advantage is that there are software implementations of type theory, such as the Coq proof assistant (see Section \ref{apx:coq}), which allow us to mechanically verify the correctness of our theory. In the rest of this section, we will use the coq syntax for definitions, propositions and theorems so that interested readers can use a computer and a Coq interpreter to verify by themselves that the proofs are correct. We have also included an appendix where we briefly describe the Coq language, so that those readers who prefer traditional mathematics can translate the Coq scripts into classical mathematical definitions and propositions.

% Foundamental Concepts

\subsubsection*{Foundamental Concepts}

We start by introducing a new type, called \texttt{String}. The type string is defined recursively in the following way: the empty string, called \texttt{lambda}\footnote{Do not confuse the $\lambda$ symbol with a $\lambda$-term.}, is a string, and the sucessor of a string, given the function \texttt{S}, is also a string. For us strings are just a list of lambdas, and our theory is based on the collection of all finite strings $\{ \lambda, \lambda \lambda, \lambda \lambda \lambda, \ldots \}$. Both descriptions and representations will be finite strings of lambdas.

\begin{sourcecode}
{\scriptsize \begin{verbatim}
Inductive String : Set :=
  | lambda : String
  | S      : String -> String.
\end{verbatim}}
\end{sourcecode}

Before to introduce the main concepts of the theory of nescience, we have to define a helper funcion called \texttt{Difference}. The \texttt{Difference} function computes the absolute difference between two strings, that is, the excess of lambdas of the longer string with respect to the shortest one. For example, if we have the strings $\lambda \lambda$ and $\lambda \lambda \lambda$, the difference would be the string $\lambda$. Given two strings $r$ and $s$, \texttt{Difference} is defined recursively as:

\begin{sourcecode}
{\scriptsize \begin{verbatim}
Fixpoint Difference (r s : String) : String :=
  match r, s with
  | lambda, lambda  => lambda
  | lambda, s       => s
  | r     , lambda  => r
  | S r'  , S s'    => Difference r' s'
  end.
\end{verbatim}}
\end{sourcecode}

We say that a string $r$ has smaller \emph{surfeit} than a string $s$ if the string $r$ is shorter, in terms of number of lambdas, than the string $s$. Given two strings $r$ and $s$, the \texttt{Surfeit} function is defined recursively, and returns \texttt{true} if the string $r$ has less lambdas than the string $s$.  Applied to descriptionss, we prefer those with the smaller number of lamdas.

\begin{sourcecode}
{\scriptsize \begin{verbatim}
Fixpoint Surfeit (r s : String) : bool :=
  match r, s with
  | lambda, lambda => false
  | lambda, _      => true
  | _     , lambda => false
  | S r', S s'     => Surfeit r' s' 
  end.
\end{verbatim}}
\end{sourcecode}

The \emph{inaccuracy} of a string $r$ with respect to a target string $t$ is based on the absolute difference between the two strings, that is, how close is the string to the target. Given two strings $r$ and $s$, and a target string $t$, the \texttt{Inaccuracy} function returns \texttt{true} if the absolute difference between the strings $r$ and $t$ contains less lambdas than the absolute difference between the strings $s$ and $t$. Inaccuracy will be applied to the ouput of the models.

\begin{sourcecode}
{\scriptsize \begin{verbatim}
Definition Inaccuracy (r s : String) (t : String) : bool :=
  Surfeit (Difference r t) (Difference s t).\end{verbatim}}
\end{sourcecode}

\emph{Nescience} will be based on the concepts of surfeit and inaccuracy. Intitively, we are looking for very short descriptions (low surfeit) and with very low error (low inaccuracy). The \texttt{Nescience} function gets as input five strings: $mr$, $ms$, $r$, $s$ and $e$, and returns \emph{true} if $mr$ is a shorter string than $ms$, and the inaccuracy of $r$ is smaller than the inaccucay of $s$ with respect to $e$. Intuitively, $mr$ and $ms$ would be a string-based representations of our models (in our case, lambda-terms), $r$ and $s$ are the string-based outputs of these models, and $e$ is a string-based representation of an entity.

\begin{sourcecode}
{\scriptsize \begin{verbatim}
Definition Nescience (mr ms : String) (r s : String) (e : String) : bool :=
  andb (Surfeit mr ms) (Inaccuracy r s e).
\end{verbatim}}
\end{sourcecode}

In practice, we generally do not know a string-based representation $e$ of the entity we are interested in, so an indirect approach must be used to study that entity. \emph{Miscoding} is this approach, and it will be introduced in a later section.

Instead of defining the new type \texttt{String} we could have reused the concept of natural number, that is, we could have introduced descriptions and representations as numbers. In that case, the \texttt{Difference} between two strings $r$ and $s$ would be the absolutute difference $\mid r - s \mid$ between the numbers $r$ and $s$, and the \texttt{Surfeit} could be based on the the strict order relation between numbers $<$. The concepts of \texttt{Inaccuracy} and \texttt{Nescience} would have been defined in the same way with numbers. However, natural numbers require additional properties that are not needed for the theory of nescience. For example, the multiplication of two natural numbers does not make any sense in our theory.  Reusing natural numbers would have made our theory unnecerarily complex.

In the rest of this section, we will see how we can derive our theory of nescience using only these fundamental concepts. We will also prove the most significant results and derive algorithms for applying the theory in practice.

% Surfeit

\subsubsection*{Surfeit}

Surfeit allow us to compare two strings. Recall that the surfeit of two strings $r$ and $s$ is true if, and only if, $s$ is composed by more lambdas than $r$. Surfeit allow us to order the models (string based representations of the models) by its length. We are interested in those models with the lowest possible complexity. In the rest of this section we are going to review the properties of surfeit.

The surfeit of a string does not increases when we conditions that string to another one. Intuitively, assuming some previous background knowledge already known as true allow us to reduce the complexity of our models.

\begin{sourcecode}
{\scriptsize \begin{verbatim}
Proposition SurfeitConditional : forall r s : String, 
  Surfeit r (r |c s) = false.
Proof.
intros.
induction r as [| r' IHr'].
- simpl.
  reflexivity.
-
Admitted.
\end{verbatim}}
\end{sourcecode}

From a theoretical point of view, the limit to the proccess of conditioning would be to assume as true the current model.

\begin{sourcecode}
{\scriptsize \begin{verbatim}
Proposition SurfeitConditionalLambda : forall r s: String, 
  Surfeit lambda (r |c r) = false.
Proof.
Admitted.
\end{verbatim}}
\end{sourcecode}

The surfeit of a string does not decreases when it is concatenated with another string. Intuitively, the concatenation of two models increases our uknown. This process of concatenating models can be used as an exploratory mechanism to discover new research topics (previously unknown entities).

\begin{sourcecode}
{\scriptsize \begin{verbatim}
Proposition SurfeitConcatenation : forall r s : String, 
  Surfeit r (r <+> s) = false.
Proof.
intros.
Admitted.
\end{verbatim}}
\end{sourcecode}

From the point of view of surfeit, the operation of concatenation can be distributed over the operation of conditioning, as next proposition shows ({\color{red} TODO: provide the intuition behind this distributive law}).

\begin{sourcecode}
{\scriptsize \begin{verbatim}
Proposition DistributiveLawSurfeit : forall r s t  : String,
  Surfeit ((r |c s) <+> t) ((r <+> t) |c (s <+> t)) = true.
Proof.
Admitted.
\end{verbatim}}
\end{sourcecode}

% Inaccuracy

\subsubsection*{Inaccuracy}

{\color{red} Definition and results about inaccuracy}

{\color{red} Inaccuracy does not increases with conditional}

\begin{sourcecode}
{\scriptsize \begin{verbatim}
Proposition InaccuracyConditional : forall r s e : String, 
  Inaccuracy r (r |c s) e = false.
Proof.
Admitted.
\end{verbatim}}
\end{sourcecode}

{\color{red}  The limit would be conditioning a string to itself}

\begin{sourcecode}
{\scriptsize \begin{verbatim}
Proposition InaccuracyConditionalLambda : forall r s: String, 
  Inaccuracy lambda (r |c r) = false.
Proof.
Admitted.
\end{verbatim}}
\end{sourcecode}

{\color{red} Distributive Law}

\begin{sourcecode}
{\scriptsize \begin{verbatim}
Proposition DistributiveLawInaccuracy : forall r s t  : String,
  Inaccuracy ((r |c s) <+> t) ((r <+> t) |c (s <+> t)) = true.
Proof.
Admitted.
\end{verbatim}}
\end{sourcecode}

% Entities, Representations and Descriptions

\subsubsection*{Entities, Representations and Descriptions}

After we have described the fundamental concepts of the theory of nescience, in this section we are going to introduce the remaining elements of the theory, that is, the concepts of entity, representation and description.

We introduce the concept of \emph{entity} recursively as a finite list of strings. Those strings correspond to the valid representations of the entity. We consider that the empty entity, denoted by \emph{nil}, is also an entity.

\begin{sourcecode}
{\scriptsize \begin{verbatim}
Inductive Entity : Set :=
  | nil       : Entity
  | add_repr : String -> Entity -> Entity.
\end{verbatim}}
\end{sourcecode}

A \emph{universe} is a finite list of entities. A universe correspond to the particular reasearch area in which we are interested. We consider that the empty universe, denoted by \emph{empty}, is also a universe. The recursive definition of universe is given by:

\begin{sourcecode}
{\scriptsize \begin{verbatim}
Inductive Universe : Set :=
  | empty      : Universe
  | add_entity : Entity -> Universe -> Universe.
\end{verbatim}}
\end{sourcecode}

A description is a pair composed by a recursive funcion (a $\lambda$-term) from strings to strings, what we call a \emph{model}, and an input string to that model.

\begin{sourcecode}
{\scriptsize \begin{verbatim}
Definition Description (model : String -> String) (input : String) : String :=
  model input.\end{verbatim}}
\end{sourcecode}

% Miscoding

\subsubsection*{Miscoding}

{\color{red} Definition and results about miscoding}


% Properties of Strings

\subsubsection*{Properties of Strings}

Before we move into the details of the theory of nescience, we are going to prove some basic properties that our concept of string satisfies. Also, besides to the already introduced concept of string difference, we are going to introduce two other strings operators: concatenation and conditional.

We say that two strings are \emph{equal} if, and only if, they have the same number of sigmas. String equality is defined recursively as follows:

\begin{sourcecode}
{\scriptsize \begin{verbatim}
Fixpoint Equality (r s : String) : bool :=
  match r, s with
  | lambda, lambda => true
  | lambda, _      => false
  | _     , lambda => false
  | S r'  , S s'   => Equality r' s'
  end.
\end{verbatim}}
\end{sourcecode}

It is convenient to introduce a new infix operator to represent the string equality concept. That will helps us to simplify new definitions and proofs.

\begin{sourcecode}
{\scriptsize \begin{verbatim}
Notation "x =? y"  := (Equality x y)
\end{verbatim}}
\end{sourcecode}

In the same way, we introduce another infix operator to represent the concept of string difference.

\begin{sourcecode}
{\scriptsize \begin{verbatim}
Notation "x <d> y"  := (Difference x y)
\end{verbatim}}
\end{sourcecode}

Strings with the difference operator form an abelian group. That is: it has a neutral element, it is conmutative, associative and has an inverse element.

The neutral element for strings is the $\lambda$ symbol. That $\lambda$ is the neutral elment with respect to the operation of difference is a direct consequence of the definitions of string and difference.

\begin{sourcecode}
{\scriptsize \begin{verbatim}
Proposition DifferenceNeutral : forall r : String,
  r <d> lambda = r /\ lambda <d> r = r.
Proof.
intros.
split.
- destruct r.
  * reflexivity.
  * reflexivity.
- destruct r.
  * reflexivity.
  * reflexivity.
Qed.
\end{verbatim}}
\end{sourcecode}

The property of being conmutative of the difference operator is proved by ... {\color{red} TODO}

\begin{sourcecode}
{\scriptsize \begin{verbatim}
Proposition DifferenceConmutative : forall r s : String,
  r <d> s = s <d> r.
Proof.
Admitted.
\end{verbatim}}
\end{sourcecode}

In the same way, the property of being conmutative is shown by ... {\color{red} TODO}

\begin{sourcecode}
{\scriptsize \begin{verbatim}
Proposition DifferenceAsociative  : forall r s t  : String,
  r <d> (s <d> t) = (r <d> s) <d> t.
Proof.
Admitted.
\end{verbatim}}
\end{sourcecode}

The conmutative property can be generalized to finite collections of strings, such that the use of paraenthesis is not needed ... {\color{red} TODO}

Given an arbitrary string $r$, its inverse element is the string itself, as next proposition shows. The proposition is proved by induction over $r$.

\begin{sourcecode}
{\scriptsize \begin{verbatim}
Proposition DifferenceInverse : forall r : String,
  r <d> r = lambda.
Proof.
intros.
induction r as [| r' IHr'].
- reflexivity.
- simpl.
  apply IHr'.
Qed.
\end{verbatim}}
\end{sourcecode}

The operation of \emph{concatenation} of two strings returns a new string composed by one of the strings appened at the end of the other. The operation of concatenation is defined recursively as:

\begin{sourcecode}
{\scriptsize \begin{verbatim}
Fixpoint Concatenate (r s : String) : String :=
  match r, s with
  | lambda, _     => s
  | S r'  , _     => S (Concatenate r' s)
  end.
\end{verbatim}}
\end{sourcecode}

The infix notation for the concatenation operation is given by:

\begin{sourcecode}
{\scriptsize \begin{verbatim}
Notation "x <+> y" := (Concatenate x y)
\end{verbatim}}
\end{sourcecode}

The pair composed by strings and the concatenation operation form a conmutative monoid. That is, it has a neural element, and it satisfies the properties of being conmutative and associative.

The neutral element of the operation of concatenation is $\lambda$. In order to prove that $\lambda$ is indeed the neutral element we ... {\color{red} TODO}

\begin{sourcecode}
{\scriptsize \begin{verbatim}
Lemma s_plus_lambda : forall s : String,
  s <+> lambda = s.
Proof.
intros.
induction s as [| s' IHs'].
- simpl.
  reflexivity.
- simpl.
  rewrite -> IHs'.
  reflexivity.
Qed.
\end{verbatim}}
\end{sourcecode}

Given the above lemma we can now prove that $\lambda$ is the neutral element ... {\color{red} TODO}

\begin{sourcecode}
{\scriptsize \begin{verbatim}
Proposition ConcatenationNeural : forall r : String,
  r <+> lambda = r /\ lambda <+> r = r.
Proof.
Admitted.
\end{verbatim}}
\end{sourcecode}

{\color{red} TODO: string concatenation is conmutative, and its proof requires to additional lemmas.}

\begin{sourcecode}
{\scriptsize \begin{verbatim}
Lemma plus_r_Ss : forall r s: String,
  S (r <+> s) = r <+> S s.
Proof.
intros.
induction r as [| r' IHr'].
- simpl.
  reflexivity.
- simpl.
  rewrite -> IHr'.
  reflexivity.
Qed.
\end{verbatim}}
\end{sourcecode}

\begin{sourcecode}
{\scriptsize \begin{verbatim}
Lemma S_equal : forall n m : String,
  n = m -> S n = S m.
Proof.
intros.
induction m as [| m' IHm'].
- rewrite -> H.
  reflexivity.
- rewrite -> H.
  reflexivity.
Qed.
\end{verbatim}}
\end{sourcecode}

\begin{sourcecode}
{\scriptsize \begin{verbatim}
Proposition ConcatenationConmutative : forall r s : String,
  r <+> s = s <+> r.
Proof.
intros.
induction s as [| s' IHs'].
- simpl.
  apply s_plus_lambda.
- simpl.
  rewrite <- IHs'.
  rewrite <- plus_r_Ss.
  reflexivity.
Qed.
\end{verbatim}}
\end{sourcecode}

{\color{red} Associative property of concatenation ... }

\begin{sourcecode}
{\scriptsize \begin{verbatim}
Proposition ConcatenationAsociative  : forall r s t  : String,
  r <+> (s <+> t) = (r <+> s) <+> t.
Proof.
intros.
induction r as [| r' IHr'].
- simpl.
  reflexivity.
- simpl.
  rewrite <- IHr'.
  reflexivity.
Qed.
\end{verbatim}}
\end{sourcecode}

{\color{red} Introduce the operator of string conditional, as a recursive definition.}

\begin{sourcecode}
{\scriptsize \begin{verbatim}
Fixpoint Conditional (r s : String) : String :=
  match r, s with
  | lambda, _      => lambda
  | s     , lambda => s
  | S r'  , S s'   => Conditional r' s
  end.
\end{verbatim}}
\end{sourcecode}

{\color{red} Infix notation.}

\begin{sourcecode}
{\scriptsize \begin{verbatim}
Notation "x |c y"  := (Conditional x y).
\end{verbatim}}
\end{sourcecode}

{\color{red} Algebraic structure of the conditional operator.}

{\color{red} Left Neutral Element}

\begin{sourcecode}
{\scriptsize \begin{verbatim}
Proposition ConditionalLeftNeutral : forall r : String,
  r |c lambda = r.
Proof.
intros.
destruct r.
- reflexivity.
- reflexivity.
Qed.
\end{verbatim}}
\end{sourcecode}

{\color{red} Inverse Element}

\begin{sourcecode}
{\scriptsize \begin{verbatim}
Proposition ConditionalInverse : forall r : String,
  r |c r = lambda.
Proof.
intros.
induction r as [| r' IHr'].
- simpl.
  reflexivity.
- simpl.
Admitted.
\end{verbatim}}
\end{sourcecode}

Having introduced the operations of difference, concatenation and conditional, we can study which of these operators can be distributed over the others, since not all possible combinations are valid. In fact, only three distributive laws are true in our theory of nescience.

The operation of concatenation can be distributed to the operation of conditional, as the next proposition shows. The proposition is proved by ... {\color{red} TODO}.

\begin{sourcecode}
{\scriptsize \begin{verbatim}
Proposition DistributiveConditionalConcatenation : forall r s t  : String,
  Surfeit ((r |c s) <+> t) ((r <+> t) |c (s <+> t)) = true.
Proof.
Admitted.
\end{verbatim}}
\end{sourcecode}

The concatenation operator can also be distributed to the difference operator. The proposition is proved by ... {\color{red} TODO}.

\begin{sourcecode}
{\scriptsize \begin{verbatim}
Proposition DistributiveDifferenceConcatenation : forall r s t  : String,
  Surfeit ((r <d> s) <+> t) ((r <+> t) <d> (s <+> t)) = true.
Proof.
Admitted.
\end{verbatim}}
\end{sourcecode}

Finally, we have a third distributive law, that says that the difference operator can be distributed to the concatenation. Th proposition is proved by ... {\color{red} TODO}.

\begin{sourcecode}
{\scriptsize \begin{verbatim}
Proposition DistributiveConcatenationDifference : forall r s t  : String,
  Surfeit ((r <+> s) <d> t) ((r <d> t) <+> (s <d> t)) = true.
Proof.
Admitted.
\end{verbatim}}
\end{sourcecode}

% Equivalence

\subsubsection*{Equivalence of Axioms}

In  type theory the underline set $\mathcal{S}$ is the collection of all finite unary strings.

Surfeit is based on string length.

Inaccuracy is based on the length of the absolute difference between the string an the target.

Nescience is based on lower surfeti and lower inaccuracy

 * strict
 * antisymetric
 * transitive

When studying the properties of strings we have shown that the string concatenation operation is conmutative, asociative and has a neutral element, and that  string conditional has a left neutral element and an inverse element.






%
% Category Theory
%

\subsection{Category Theory}

{\color{red} TODO: Interpretation of the theory of nescience in terms of category theory.}


%
% Section: Scientific Method
%

\section{Scientific Method}
\label{sec:scientific_method}

Next definition formally introduces the concept of scientific methodology in the context of the theory of nescience.

\begin{definition}
A \emph{scientific methodology} is an effective procedure that produces a sequence of $t_1, t_2, \ldots, t_n, \ldots$ where $t_i \in \mathcal{D}$ such that $N(t_i) < N(t_{i+1})$.
\end{definition}

Note that we do not require that in a scientific methodology the collection of $t_i$ refer to the same entity.


{\color{red} Describe our proposal of scientific method. Short story: based on a exploration/exploitation approach, where the exploration is based in the concept of joint descriptions, and the exploitation in the concept of conditional description.}

{\color{red} Compare against another proposals of scientific method (inductive-deductive, hypothetico-deductive, etc) and with other techniques for knowledge discovery and creativity (triz, etc.)}

\subsection{Science as a Language}

{\color{red} TODO: Provide an alternative definition of the set of descriptions, and prove that it is equivalent to our definition based on the description function}

Since we require computable descriptions, we would like to know if the set of all possible descriptions of a topic is computable as well.

\begin{proposition}
Study if $D_{t}$ is Turing-decidable, Turing-recognizable or none.
\end{proposition}
\begin{proof}
{\color{red} TODO}
\end{proof}

Although we know that it is not computable, we are interested in the set composed by the shortest possible description of each topic.

\begin{definition}
We define the set of \emph{perfect descriptions}, denoted by $\mathcal{D}^\star$, as:
\[
\mathcal{D}^\star = \{ d_t^\star : t \in \mathcal{T} \}
\]
\end{definition}

Since the set $\mathcal{D}$ includes all the possible descriptions of all the possible (describable) topics, we can see this set as a kind of language for science. We do not call it universal language since it depends on the initial set of entities $\mathcal{E}$ and the particular encoding used for these entities.

\begin{proposition}
The set $\mathcal{D}$ is not Turing-decidable.
\end{proposition}
\begin{proof}
{\color{red} TODO: Because it depends on the set $\mathcal{T}$ that it could be not computable}
\end{proof}

Say something here

\begin{proposition}
The set $\mathcal{D}$ is Turing-recognizable.
\end{proposition}
\begin{proof}
{\color{red} TODO: The same argument as the previous proposition}
\end{proof}

A universal language is determined by a universal Turing machine. Given Two different universal Turing machines $\delta_{a}$ and $\delta_{b}$ defines two different universal languages $\mathcal{L}_{a}$ and $\mathcal{L}_{b}$. Let $\mathcal{L}_{a=b}=\left\{ \left\langle d_{a},d_{b}\right\rangle \,,\,d_{a},d_{b}\in\mathcal{D}\mid\delta_{a}\left(d_{a}\right)=\delta_{b}\left(d_{b}\right)\right\}$.

\begin{proposition}
Study if $\mathcal{L}_{a=b}$ is Turing-decidable, Turing-recognizable or none.
\end{proposition}
\begin{proof}
{\color{red} TODO}
\end{proof}

Let $\mathcal{L}_{\nexists t}$ the laguage of valid descriptions (from a formal point of view) that do not describe any topic, that is, $\mathcal{L}_{\nexists t}=\left\{ d\in\mathcal{D}\mid\nexists t\in\mathcal{T}\,,\,\delta\left(d\right)=t\right\}$.

\begin{proposition}
Study if $\mathcal{L}_{\nexists t}$ is Turing-decidable, Turing-recognizable or none.
\end{proposition}

Let $\mathcal{L}_{\nexists d}$ the laguage topics that are not described by any description, that is, $\mathcal{L}_{\nexists d}=\left\{ t\in\mathcal{T}\mid\nexists d\in\mathcal{D}\,,\,\delta\left(d\right)=t\right\}$.

\begin{proposition}
Study if $\mathcal{L}_{\nexists d}$ is Turing-decidable, Turing-recognizable or none.
\end{proposition}

{\color{red} TODO: Extend the concept of conditional description to multiple topics.}

{\color{red} TODO: Introduce the concept of "independent topics" based on the complexity of the conditional description. Study its properties.}

{\color{red} TODO: Define a topology in $\mathcal{T}$ and $\mathcal{D}$. Study the continuity of $\delta$. Study the invariants under $\delta$.}


%
% Section: The Inaccuracy - Surfeit Trade-off
%

\section{The Inaccuracy - Surfeit Trade-off}

{\color{red} TODO: Explain that given a miscoding, there is a trade-off between inaccuracy and surfeit, in the sense that there exists an optimal point beyond it the more we decrease the inaccuracy, the more we increase the surfeit, and so, the nescience keep constant. Explain how this trade-off imposes a limit to knowledge.}


%
% Section: Graspness
%
\section{Graspness}

There are some topics whose nescience decrease with time much faster than others, even if the amount of research effort involved is similar. A possible explaination to this fact is that there are some topics that are inherently more difficult to understand.

We define the \emph{graspness} of a topic as the entropy of the set of possible descriptions of that topic. A high graspness means a difficult to understand topic. Intuitively, a research topic is difficult if it has no descriptions much shorter than the others, that is, descriptions that significantly decrease the nescience. For example, in physics there have been a sucession of theories that produced huge advances in our understanding of how nature works (Aristotelian physics, Newton physics, Einstein physics), meanwhile in case of philosophy of science, new theories (deductivism, inductivism, empirism, falsation, ...) have a similar nescience than previous ones.

\begin{definition}[Graspness]
Let $D_t$ the set of descriptions of a topic $t \in T$. The \emph{graspness} of topic $t$, denoted by $G(t)$, is defined by:
\[
G(t) = \sum_{d \in D_t} 2^{-l(d)} l(d)
\]
\end{definition}

Grapsness is a postive quantity, whose maximum is reached when all the descriptions of the topic have the same length:

\begin{proposition}
Let $D_t = \{ d_1, d_2, \ldots, d_q \}$ the set of descriptions of a topic $t \in T$, then we have that $G(t) \leq \log q$, and $G(t) = \log q$ if, and only if, $l(d_1) = l(d_2) = \ldots = l(d_q)$.
\end{proposition}
\begin{proof}
Replace $P(s_i)$ by $2^{-l(d_i)}$ in Proposition \ref{prop:maximum_entropy}.
\end{proof}

If $G(t) = \log q$ then we have that $N_t = 0$ for all $\hat{d}_t$. In that case, it does not make any sense to do research, since no knew knowledge can be adquired. This is the case of pseudosciences, like astrology, where the nescience of descriptions does not decrease with time. If fact, graspness can be used as a distintive element of what constitutes \emph{science} and what does not.

\begin{definition}
A topic $t \in T$ is \emph{scientable} if $G(t) < \log d(D_t) - \epsilon$, where $\epsilon \in \mathbb{R}$ is a constant.
\end{definition}

We can extend the concept of graspness from topics to areas, for example, by means of computing the average graspness of all the topics included in the area.

\begin{definition}
Let $A \subset T$ a research area. The \emph{graspness} of area $A$, denoted by $G(A)$, is defined by:
\[
G(A) = \frac{1}{d(A)} \sum_{t \in A} G(t)
\]
\end{definition}

%
% Section: Effort
%
\section{Effort}

{\color{red} TODO: Provide a characterization of the effort, measured in terms of number of operations, or time, to reduce the nescience. Based in the concept of computational complexity. Provide a physical interpretation in terms of information.}

%
% Section: Human Understanding
%
\section{Human Understanding}

In his landmark paper \emph{"On Computable Numbers with an Application to the Entscheidungsproblem"}, where the concept of computable function was proposed for the first time, when the author Alan M. Turing talked about computers, he was thinking about human computers, not machines. In this sense, according to Turing, everything that is computable, can be computed by a human, at least in theory.

The fist limitation is about computation time. We expect that a human is able to find a solution to a particular instance of a problem in order of seconds, maybe minutes or hours, but definitely, in less than a life time, otherwise another human have to start again from scratch to solve the problem. So, given the average computing speed of a human brain, we identify as human solvable problems only those problems with a complexity smaller than a fixed number of steps.

The second limitation is about program size. It might happen that the algorithms to solve a problem is simply too big to fit in our brains. Of course, we could argue that {\color{red} as we saw in Example XX, only X states and Y tape symbols} are sufficient to implement a universal Turing machine capable of solving any computable problem, that is, any problem for which exist a Turing machine that can solve it. However, by just following a set of instruction we do not mean that we understand a problem. We understand a problem when we have made the problem for ourselves, in the sense, that the problem is somehow stored in our brain in our own language. So this limits the problem to those whose length, including the necessary background, can be stored in our brain.

We are looking for solutions that minimize at the same time the computational complexity and the Kolmogorov complexity.

\begin{definition}
We say that a problem $P$ is \emph{human solvable} if there exist an algorithm $TM$ to solve $P$ such that $t(n)$ and $K(P) < l$.
\end{definition}

Given the above definition, we could argue that most of the problems we know are not human solvable, but in fact, they have been solved by human. We use two strategies to deal with too complex problems for our individual brains. The fist strategy is that those time-comsuming mechanical parts of the problems are left for computers, so we can reduce the computing time. The second one is that we split the problems into subproblems and each of use specializes in those subproblems.

In this section we are interested in to study the nature of these problems in which this strategy cannot be applied, and so, they are out of reach of individual, nor groups of, humans.

%
% Section: Areas in Decay
%

\section{Areas in Decay}

{\color{red} Provide a model of the decay in the interest of research areas. For example, a good explanatory variable could be the number of interesting questions: the less interesting questions, the more the area is near to its end as a interesting research area, of course, as long as its topics are not used as tools.}

%
% Section: References
%

\section*{References}

{\color{red} Mention the polemic between Hilbert and Fredge given a reference to the book of Mosterin.}


