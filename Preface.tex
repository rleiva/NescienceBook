%
% Preface
%

\chapterimage{Ramon_Llull_-_Ars_Magna_Fig_1.pdf} % Chapter heading image

\chapter*{Preface}

\begin{quote}
\begin{flushright}
\emph{Perfection is achieved not when there is nothing more to add, \\
but when there is nothing left to take away.}\\
Antoine de Saint-Exupéry\\
\end{flushright}
\end{quote}
\bigskip

% An explanation of the main assumption behind the book

The core premise of this book asserts that perfect knowledge implies randomness. This notion may seem highly counterintuitive at first glance, given that much of scientific endeavor focuses on naming, organizing, and classifying our intricate and chaotic world. It would appear that science is anything but random. However, that is not the case.

A lengthy explanation of a scientific concept often indicates an incomplete understanding. The calculus of derivatives serves as a fitting example. In the era of Newton and Leibniz, comprehending the concept of a function's derivative necessitated substantial space for definition and was grasped only by a select group of specialists. In contrast, today's definition of derivative is concisely explained in a single paragraph and taught in high schools.

Long explanations tend to be superfluous, filled with redundancies, extraneous concepts, improperly identified relationships, and poor notation. As our understanding deepens, often through extensive research, we can eliminate the unnecessary elements from theories, eventually achieving a state of perfect knowledge. When a theory is perfect and nothing remains to be removed, its description becomes an incompressible string, which aligns with the mathematical definition of a random string - an incompressible sequence of symbols. A scientific theory is deemed random when it encompasses the maximum amount of information within the smallest possible space.

Far from being an obstacle, the limitations that randomness imposes on our knowledge unlock up new possibilities in science and technology. By comprehending these limitations, we can address the most challenging open problems and discover fascinating new research questions.

This book introduces the new "Theory of Nescience," a mathematical framework that reexamines the nature of science and the acquisition of scientific knowledge. We begin with the assumption that it is easier to measure our ignorance than to quantify our understanding, as randomness sets the ultimate boundary on our knowledge. We also posit that the computer, as a conceptual model, is the ideal tool to measure this elusive quantity. The book also explores the practical applications of the theory of nescience in scientific research, artificial intelligence, computational creativity, and software engineering.

%
% Section: Research Agenda
%

\subsection*{Research Agenda}

In this section we present a comprehensive list of research questions that aim to address critical gaps in our current understanding of science and the scientific method. With the objective of fostering intellectual curiosity and scientific progress, our interdisciplinary approach will bring together knowledge from multiple and diverse fields, combining their unique perspectives and methods. In pursuit of answers to these pressing questions, we aim to expand the boundaries of human understanding and contribute to the development of innovative solutions that have the potential to transform our society and the world around us.

\emph{Q1: Can we provide a quantitative characterization of our ignorance regarding a research topic?} Utilizing this metric would enable us to not only gauge the extent of our lack of knowledge on a specific subject, such as climate change, but also to measure the degree to which a new development or idea (typically published in a research paper) contributes to enhancing our understanding. By combining this metric with an assessment of the problem's relevance, we could effectively quantify the value of new scientific contributions.

\emph{Q2: Can we compare the extent of our ignorance across disparate scientific fields?} If feasible, this would enable us to classify and compare all open questions based on the extent of our lack of knowledge, independent of the disciplines they belong to (e.g., physics, biology, sociology). Coupling this classification with the previously mentioned relevance metric would allow us to determine where to focus our research efforts. It is important to note that this proposal does not suggest ceasing research in basic or fundamental science; on the contrary, it underscores the necessity of such inquiries.

\emph{Q3: How can we differentiate between science and pseudo-science?} This enduring and unresolved question in the philosophy of science has significant implications. Developing a practical, mathematically-based solution would be highly beneficial, as it would enable us to evaluate the scientific nature of various controversial disciplines that claim to be scientific.

\emph{Q4: Do some research topics inherently possess a higher degree of complexity than others?} Addressing this question would help determine whether researchers in certain disciplines are genuinely more intellectually adept than their counterparts in other fields, as they often claim, or if the perceived difference is merely a consequence of some subjects being easier to comprehend than others.

\emph{Q5: Are there research topics beyond the scope of human comprehension?} What are the boundaries of human understanding? It is possible that certain problems may be unsolvable by humans, and some research topics could be beyond the grasp of our limited cognitive abilities. It might be necessary to accept that progress in specific research areas can only be achieved by relinquishing control and allowing computers to perform the creative scientific work.

\emph{Q6: Can we establish a systematic procedure to enhance our knowledge?} It is possible that the so-called "scientific method" represents an unsolvable problem, with only practical approximations available to us. If this is the case, how can we evaluate and compare different approximations? Could the principles of the theory of nescience be employed to develop a novel and more effective method for expanding our understanding?

\emph{Q7: What effort is required to fully comprehend an unfamiliar subject?} For instance, what would be the cost of increasing our understanding of cancer treatment by 1\%? With such a metric, we could strategize our research activities based on priorities, budget, and the significance of potential outcomes. Naturally, this metric would represent a lower bound, as the actual effort could be greater due to factors such as poor project management.

\emph{Q8: What constitutes perfect knowledge? Is perfect knowledge attainable for all possible entities?} Randomness serves as a necessary condition for perfect knowledge, but additional criteria are required to fully define complete understanding. Furthermore, it is essential to determine whether perfect knowledge is universally achievable or if there are inherent limitations that render perfection in science an unattainable ideal.

\emph{Q9: Can we devise a method for discovering new, previously unknown, and intriguing research entities and problems?} A procedure is needed to explore the unknown unknowns—problems that we not only lack solutions for but are also unaware of their existence. Such a method could enable us to uncover future research topics and bring them to the forefront of current investigation.

Some responses presented in this book are more developed than others. For certain questions, we will provide a comprehensive theoretical answer accompanied by a practical implementation, while for others, we will offer only a rough outline of a potential solution. However, we are confident that with further research, the new theory of nescience can yield satisfactory answers to all the questions posed. In this regard, this book serves more as a research agenda rather than a complete description of a fully-developed theory of nescience.

%
% Section: Origins of the Theory of Nescience
%

\subsection*{Origins of the Theory of Nescience}

I think it was in 1991 (when I was eighteen) that I read for the first time the sentence \emph{"Computers are useless, they can only give you answers"}. The quote is attributed to Pablo Picasso, one of the most creative and influential artists of the 20th century. Soon I realized how terrible right he was, since it is true that computers cannot make interesting, original, questions. But it was more than 20 years later, in 2014, when I started to look seriously to the challenge that Picasso posed to the computer science community.

Most of the concepts behind my methodology for the discovery of interesting questions were formulated in just one night that I could not sleep: nescience, relevance, unknown unknown, and many others. Or perhaps they were developed by my subconscious mind during all those 20 years, since I do not think it was a matter of luck that I decided to pursue subjects like information theory or Kolmogorov complexity long before I was aware that they were the foundation of a future theory of nescience. What it is remarkable is that it took me just one single night to come up with a rough sketch of the most important ideas, a couple of months to develop the initial computer experiments that validated them, and several years to fully develop the mathematics needed to provide the theoretical support.

At the beginning, I was mostly interested in finding interesting scientific questions, that is, to discover what it is hidden in what I call the unknown unknown area, with the aim of bringing to the present the research topics of the future. Later on I started to look into the evolution of the nescience of scientific topics over time, and I asked myself what would happen if we keep improving a theory forever. It is then when I realized that perfect knowledge implies randomness, and the original methodology for the discovery of interesting questions was extended into a full theory of nescience to develop this important idea.

I may confess that the new theory has had, in general, a pleasant welcome form my colleges and those scientists to whom I had the opportunity to talk during the initial development stages. This early success encouraged me to continue with a further improvement of the main ideas and their applications in practice. Meanwhile I was developing the mathematics supporting the concept of nescience, I started to look into other potential applications, including the analysis of computer programs (quality assurance) and raw datasets (machine learning).

{\color{red} TODO: Remove the following paragraph if at the end these results are not included in this version of the book.}

However, I was not satisfied with the status of the theory in spite of its explanatory power. It is true that given the theory I was able to provide solutions to some open questions in the area of philosophy of science, for example, how well we understand mathematics compared to sociology, why some research topics are more difficult that others, what it is the fundamental difference between science and pseudoscience, and many others. But the problem was that the theory did not provide any predictions that could be falsified by means of running an experiment. So I decided to take the risk and further develop the mathematics to provide such kind of predictions. This is when I came up with the function that describes how nescience decreases as we increase our research effort. This function allows us to predict the maximum increment of knowledge that we can gather about a topic given the amount of effort we are willing to put in its understanding. But, still not fully satisfied, I decided to push the theory one step forward and try to find a novel prediction, that is, something that had not been observed before. New developments of the mathematical foundations behind the theory allowed me to discover the highly counterintuitive property that sometimes, for a certain class of topics, further research could be a counterproductive activity. That is, that more research we do, the more confused we get, since for these topics it is not possible to increase our knowledge beyond a critical point, even if this point if far from a perfect knowledge.

%
% Section: About the book
%

\subsubsection*{About the Book}

The theory of nescience borrows concepts from multiple academic disciplines: computability, randomness, information theory, complexity, probability, graph theory, philosophy of science, and many more. However, the book is self-contained, and so, no previous knowledge is required to follow the mathematical developments, beyond familiarity with first year calculus, abstract algebra and some computer programming experience. The contents have been selected to cover the needs of readers with very different backgrounds: mathematicians, computer scientists, engineers, ... The math level is that of a graduate student or advanced undergraduate.

{\color{red} TODO: Review and update once the book is finished.}

The book has been structured into three main parts: Background, Foundations and Applications. Readers already familiar with the mathematics covered by the Background section can directly proceed to the Foundations part. However, it is highly recommended to perform at least a quick review of the notation used in these chapters. After getting acquainted with the details of the theory of nescience described in the Foundations section, the reader can continue with the applications. It is not necessary to fully understand all the details of the theory in order to follow the applications. A basic knowledge of the main concepts and results should be sufficient.

\bigskip

\begin{itemize}

\item \emph{Chapter \ref{chap:Introduction} Introduction} contains a gentle introduction to the theory of nescience, and a short review of the main results. The chapter avoids the use of advanced mathematics, but the concepts are still semi-formally introduced. Although it is not recommended, those readers that cannot follow the mathematics behind the theory could just read this first chapter, the introductory sections of the remaining chapters of the Background and Foundations parts, and then proceed directly to the applications.

\end{itemize}

\bigskip

\emph{PART I Background} is an introduction to the mathematics required to measure how much we do not know about a topic and how random is a string. The goal of this part is to fix notation, formally define concepts, and prove some important results. I do not assume any previous knowledge to follow the covered material, however, to fully understand these topics I recommend to refer to the standard literature (see the References section included at the end of each chapter). Addtional topics are covered in the appendices.

\begin{itemize}

\item \emph{Chapter \ref{chap:Discrete_Mathematics} Discrete Mathematics} is an overview of the basic mathematics required to understand the more advanced topics covered in the book. This chapter is intended as a quick review of these concepts, and so, no formal definitions are provided and theorems are not proved. Among others, the topics covered include sets, relations, strings, graphs and discrete probability.
 
\item \emph{Chapter \ref Discre Probability} {\color{red} TODO}.

\item \emph{Chapter \ref{chap:Computability} Computability} provides a formal definition of the concept of algorithm. We will introduce the concept of universal Turing machine, and we will see that there are well defined mathematical problems that cannot be solved by computers. The very important tools of oracle Turing machine and Turing reducibility are also studied in detail. Computational complexity main results are briefly reviewed.

\item In \emph{Chapter \ref{chap:Coding} Coding} we will study the properties of codes, and in particular, how codes allow us to compress a text without loosing any information by means of removing statistical redundancy. We will see that there exists a limit to how much a text can be compressed by using this technique, and that this limit is given by the entropy of the source.

\item \emph{Chapter \ref{chap:Algorithmic_Information} Complexity} introduces an absolute metric, called Kolmogorov complexity, to measure the amount of information contained in a string, by computing the length of the shortest computer program that can print that string. The properties of this metric are studied in detail. The relation between string complexity and randomness is also discussed.

\item \emph{Chapter \ref{ch:Learning} Learning} studies the relation between codes and probabilities. It provides a short review of the area of statistical learning, with a focus on existing approaches that apply the concept of minimum string length to the problem of stochastic models evaluation and optimal parameters selection. An introduction to the concepts and notation of nonlinear multiobjective optimization problems is included as well. 

\item \emph{Chapter \ref{chap:Philosophy} Philosophy of Science} is a short introduction to the discipline of philosophy of science. We will review concepts like scientific representations, models, theories and many other components of science from a philosophical point of view, identifying the most important elements that any formal theory of science should include. The chapter also contains a review of the current state of the art of what it is the scientific method.

\end{itemize}

\bigskip

\emph{PART II Foundations} contains a detailed description of the theory of nescience, defining formally the concepts involved and proving the main theoretical results. This is the most important part of the book, where the new theory is fully developed. Readers with a solid background in computability, complexity, information theory and probability could proceed directly to this part.

\begin{itemize}

\item \emph{Chapter \ref{cha:Topics-and-Descriptions} Entities, Representations and Descriptions} introduces the basic constituents of the theory of nescience: entities, representations and descriptions. The properties of these elements and how they interlace together are studied. We will see how multiple representations and descriptions can be combined, and how to include background knowledge in a research. The relation between perfect knowledge and randomness is discussed, and a novel concept of research area is proposed.

\item \emph{Chapter \ref{chap:Miscoding} Miscoding} address the difficult problem of how to represent abstract, and non-abstract, research entities as string of symbols that can be used for research. In the chapter we will formally introduce the concept of miscoding and study its properties. Miscoding is a quantity that measures the error introduced due to improper encodings.

\item \emph{Chapter \ref{chap:Error} Inaccuracy} contains a novel interpretation of the classical concept of error, that is, how accurately a description explains an entity. The concept of inaccuracy is extended to deal with all kinds of topics, including abstract ones. The joint and conditional versions of the concept of inaccuracy are introduced and their properties studied.

\item \emph{Chapter \ref{chap:Redundancy} Surfeit} studies how redundant is a description, that is, how many unnecessary elements a description contains. Surfeit can be seen as a measure of how well we currently understand research topics and research areas. The joint and conditional versions of surfeit are provided as well.

\item \emph{Chapter \ref{chap:Nescience} Nescience} is the central chapter of the book, since it contains the mathematical foundations of the new theory. In the chapter is formally defined the concept of nescience and its main properties studied, like for example, how nescience evolves with time, what we mean by perfect knowledge, and how to identified our current best model.

\item \emph{Chapter \ref{chap:Interesting-Research-Questions} Interesting Questions} describes a procedure to find new interesting things in a large collection of measurable objects, and in particular, to find new interesting research questions and new research topics. New concepts like relevance and applicability are defined and studied.

\item \emph{Chapter \ref{chap:Properties-Nescience} Advanced Properties} covers some advanced concepts and properties of the theory of nescience. These properties are not needed to understand the applications of the theory, and so, they can be safely skipped in a first read of the book (but, definitely, not in a second). Among others, new concepts introduced include: an axiomatic version of the theory, graspness as a measure of how difficult is a particular research topic, or the minimum effort required to reduce the nescience of a topic.

\end{itemize}

\bigskip

\emph{PART III Applications} provides a collection of practical applications of the concept of nescience, in the areas of machine learning, software engineering, philosophy of science, and computational creativity. The applications have been selected to cover the entire spectrum of possible kinds of topics, from abstract ones (research topics), real objects and strings (computer programs).

\begin{itemize}

\item \emph{Chapter \ref{chap:Machine-Learning} Machine Learning} describes how the concept of nescience can be applied in the case of entities represented by large datasets. In particular, the methodology will be applied to select relevant features, identify optimal models, and compute errors. Some new machine learning algorithms, like a novel approach to derive optimal decision trees, will be proposed as well.

\item \emph{Chapter \ref{chap:Software-Engineering} Software Engineering} covers how to use the theory of nescience with computer programs, in order to provide a measure of how well we understand current software platforms (operating systems, networking middleware, productivity tools, ...). We will evaluate if current versions of software are better than past versions, or if software is degrading with time. The results are also applied to the automatic discovery of errors, with the aim to improve the quality of software.

\item \emph{Chapter \ref{chap:philosophy-science} Philosophy of Science} studies how to apply the new metrics introduced in this book to study of what it is science and how science is made. Some important open problems in the area of philosophy of science will be addressed, including the demarcation problem (how to distinguish between science from pseudoscience) and the question of how science make progress. Multiple proposals of what it is the scientific method are evaluated in the context of the theory of nescience, and compared against our own proposal.

\item \emph{Chapter \ref{chap:computational-creativity} Computational Creativity} shows how to apply in practice the methodology for the discovery of interesting things. In particular, the methodology will be applied to find new research questions and new research topics, where multiple examples of interesting questions and topics will be provided.

\end{itemize}

\bigskip

\emph{Appendix \ref{apx:foundations_mathematics} Foundations of Mathematics} describes three different theoretical frameworks from which mathematics can be formalized: logic and set theory, dependent type theory, and category theory. These frameworks can also be used to provide a solid foundation to the theory of nescience.

\emph{Appendix \ref{apx:math} Advanced Mathematics} contains a brief description of some mathematical concepts that have been used in the book, but that play a secondary role in the development of the theory; they are included in this appendix for reference.

\emph{Appendix \ref{apx:coq} Mechanical Proofs} provides a mechanical implementation of the axioms of the theory of nescience, and its most relevant results, based on the calculus of inductive constructions, and in particular, in the \texttt{Coq} proof assistant.

Last, but not least, \emph{Appendix \ref{apx:photos} About the Photos} explains the origin and intended meaning of the carefully selected photographs included at the header of each chapter.

%
% Section: Acknowledgements
%

\section*{Acknowledgements}

I would like to give thanks to all the people who has contributed with comments and ideas to the development of the theory of nescience. In particular, I would like to give thanks to Antonio Fernández, Vincenzo Mancuso and Paolo Casari who believed and supported this project since its very beginning, when it was only a crazy nonsense idea (although perhaps it still is). Other people who has provided contributions and useful comments where Héctor Cordobés, Luis F. Chiroque, Agustín Santos, Marco Ajmone, Pablo Rojo, Manuel Cebrián, Andrés Ortega, Emilio Amaya, Mattis Choummanivong, Alexander Lynch, Andrés Carrillo and Simon Bihoreau. The \texttt{fastautoml} library described in Chapter \ref{chap:Machine-Learning} has been partially funded by the IMDEA Networks Institute, the European Union's Horizon 2020 research and innovation programme under grant agreement No 732667 RECAP, and Nokia Spain through the project NetPredict.

Finally, I would like to give thanks to my parents who gave me the opportunities in life they didn't have, and to my wife and my three kids who provide ultimate meaning to my life.

%
% Section: Disclaimer
%

\section*{Disclaimer}

I would like to leave it clear that the overwhelming majority of the ideas contained in this book are not mine. The intuition comes form the great minds of our history: Occam, Llull, Leibniz, Newton, etc., and from philosophers like Plato, Popper, Feyerabend, Wittgenstein, etc. Also, I have leveraged on the mathematical theories developed by scientists like Turing, Church, Post, Shannon, Solomonof, Chaitin, Kolmogorov, and many others. My only original contribution with this book is that I have, perhaps, connected some dots, and that I have provided a, perhaps, interesting reinterpretation of some old ideas. In the References sections included at the end of each chapter there is a description of the works I have used to write the book. In the text I use passive voice ("it is defined") whenever I know that a concept is not mine, and active voice ("we define") when I am not aware of a previous use of this concept by somebody else.

