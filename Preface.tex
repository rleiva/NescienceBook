%
% Preface
%

\chapterimage{Ramon_Llull_-_Ars_Magna_Fig_1.pdf} % Chapter heading image

\chapter*{Preface}

\begin{quote}
\begin{flushright}
\emph{Perfection is achieved not when there is nothing more to add, \\
but when there is nothing left to take away.}\\
Antoine de Saint-Exupéry\\
\end{flushright}
\end{quote}
\bigskip

% An explanation of the main assumption behind the book

The core premise of this book asserts that perfect knowledge implies randomness. This notion may seem highly counterintuitive at first glance, given that much of scientific endeavor focuses on naming, organizing, and classifying our intricate and chaotic world. It would appear that science is anything but random. However, that is not the case.

A lengthy explanation of a scientific concept often indicates an incomplete understanding. The calculus of derivatives serves as a fitting example. In the era of Newton and Leibniz, comprehending the concept of a function's derivative necessitated substantial space for definition and was grasped only by a select group of specialists. In contrast, today's definition of derivative is concisely explained in a single paragraph and taught in high schools.

Long explanations tend to be superfluous, filled with redundancies, extraneous concepts, improperly identified relationships, and poor notation. As our understanding deepens, often through extensive research, we can eliminate the unnecessary elements from theories, eventually achieving a state of perfect knowledge. When a theory is perfect and nothing remains to be removed, its description becomes an incompressible string, which aligns with the mathematical definition of a random string - an incompressible sequence of symbols. A scientific theory is deemed random when it encompasses the maximum amount of information within the smallest possible space.

Randomness sets the ultimate limit to our knowledge, since a random description cannot be refined any further and, assuming the theory is accurate, our understanding must be perfect. Far from being a handicap, the constraints imposed by randomness to knowledge pave the way for new possibilities in science and technology. By comprehending these limitations, we can address the most challenging open problems and discover new research questions. Indeed, this understanding can lead us to innovative approaches and a deeper appreciation for the inherent complexities of scientific discovery.

This book introduces the new "Theory of Nescience," a mathematical framework that reexamines the nature of science and the acquisition of scientific knowledge. We begin with the assumption that it is easier to measure our ignorance than to quantify our understanding, as randomness sets the ultimate boundary on our knowledge. We also posit that the computer, as a conceptual model, is the ideal tool to measure this elusive quantity. The book also explores the practical applications of the theory of nescience in scientific research, artificial intelligence, computational creativity, and software engineering.

%
% Section: Research Agenda
%

\subsection*{Research Agenda}

In this section we present a comprehensive list of research questions that aim to address critical gaps in our current understanding of science and the scientific method. With the objective of fostering intellectual curiosity and scientific progress, our interdisciplinary approach will bring together knowledge from multiple and diverse fields, combining their unique perspectives and methods. In pursuit of answers to these pressing questions, we aim to expand the boundaries of human understanding and contribute to the development of innovative solutions that have the potential to transform our society and the world around us.

\emph{Q1: Can we provide a quantitative characterization of our ignorance regarding a research topic?} Utilizing this metric would enable us to not only gauge the extent of our lack of knowledge on a specific subject, such as climate change, but also to measure the degree to which a new development or idea (typically published in a research paper) contributes to enhancing our understanding. By combining this metric with an assessment of the problem's relevance, we could effectively quantify the value of new scientific contributions.

\emph{Q2: Can we compare the extent of our ignorance across disparate scientific fields?} If feasible, this would enable us to classify and compare all open questions based on the extent of our lack of knowledge, independent of the disciplines they belong to (e.g., physics, biology, sociology). Coupling this classification with the previously mentioned relevance metric would allow us to determine where to focus our research efforts. It is important to note that this proposal does not suggest ceasing research in basic or fundamental science; on the contrary, it underscores the necessity of such inquiries.

\emph{Q3: How can we differentiate between science and pseudo-science?} This enduring and unresolved question in the philosophy of science has significant implications. Developing a practical, mathematically-based solution would be highly beneficial, as it would enable us to evaluate the scientific nature of various controversial disciplines that claim to be scientific.

\emph{Q4: Do some research topics inherently possess a higher degree of complexity than others?} Addressing this question would help determine whether researchers in certain disciplines are genuinely more intellectually adept than their counterparts in other fields, as they often claim, or if the perceived difference is merely a consequence of some subjects being easier to comprehend than others.

\emph{Q5: Are there research topics beyond the scope of human comprehension?} What are the boundaries of human understanding? It is possible that certain problems may be unsolvable by humans, and some research topics could be beyond the grasp of our limited cognitive abilities. It might be necessary to accept that progress in specific research areas can only be achieved by relinquishing control and allowing computers to perform the creative scientific work.

\emph{Q6: Can we establish a systematic procedure to enhance our knowledge?} It is possible that the so-called "scientific method" represents an unsolvable problem, with only practical approximations available to us. If this is the case, how can we evaluate and compare different approximations? Could the principles of the theory of nescience be employed to develop a novel and more effective method for expanding our understanding?

\emph{Q7: What effort is required to fully comprehend an unfamiliar subject?} For instance, what would be the cost of increasing our understanding of cancer treatment by 1\%? With such a metric, we could strategize our research activities based on priorities, budget, and the significance of potential outcomes. Naturally, this metric would represent a lower bound, as the actual effort could be greater due to factors such as poor project management.

\emph{Q8: What constitutes perfect knowledge? Is perfect knowledge attainable for all possible entities?} Randomness serves as a necessary condition for perfect knowledge, but additional criteria are required to fully define complete understanding. Furthermore, it is essential to determine whether perfect knowledge is universally achievable or if there are inherent limitations that render perfection in science an unattainable ideal.

\emph{Q9: Can we devise a method for discovering new, previously unknown, and intriguing research entities and problems?} A procedure is needed to explore the unknown unknowns—problems that we not only lack solutions for but are also unaware of their existence. Such a method could enable us to uncover future research topics and bring them to the forefront of current investigation.

Some responses presented in this book are more developed than others. For certain questions, we will provide a comprehensive theoretical answer accompanied by a practical implementation, while for others, we will offer only a rough outline of a potential solution. However, we are confident that with further research, the new theory of nescience can yield satisfactory answers to all the questions posed. In this regard, this book serves more as a research agenda rather than a complete description of a fully-developed theory of nescience.

%
% Section: Origins of the Theory of Nescience
%

\subsection*{Origins of the Theory of Nescience}

It was in 1991, when I was eighteen years old, that I first encountered the statement, \emph{"Computers are useless, they can only give you answers"}. This quote is attributed to Pablo Picasso, one of the most creative and influential artists of the 20th century. I quickly realized the profound truth in his words, as it is indeed accurate that computers cannot generate original and interesting questions. However, it wasn't until more than 20 years later, in 2014, that I began to seriously consider the challenge Picasso's observation presented to the computer science community.

Much of the foundation for my methodology in discovering interesting questions emerged during a single sleepless night: nescience, relevance, the unknown unknown, and various other novel concepts. It's possible that my subconscious mind had been developing these ideas over the course of 20 years, as I believe it's no coincidence that I chose to study subjects like information theory and Kolmogorov complexity long before I realized their significance to my future theory of nescience. Remarkably, it took just one night to conceive a rough outline of the key ideas, a couple of months to conduct initial computer experiments that validated them, and several years to develop the necessary mathematics for a robust theoretical framework.

Initially, my primary interest was in uncovering interesting scientific questions, delving into what I call the unknown unknown area to reveal future research topics. As my focus shifted to the evolution of nescience in scientific subjects over time, I began to ponder the implications of perpetually refining a theory. That's when I discovered the connection between perfect knowledge and randomness, which led to the expansion of my original methodology for identifying interesting questions into a comprehensive theory of nescience that further explored this crucial concept.

I must admit that the new theory received a warm reception from my colleagues and other scientists with whom I had the chance to discuss it during the initial development stages. This early success spurred me to refine the core ideas and their practical applications. While developing the mathematics underpinning the concept of nescience, I began exploring other potential applications, such as analyzing computer programs for quality assurance and examining raw datasets for machine learning purposes.

Despite the explanatory power of the theory, I remained unsatisfied with its status. It's true that the theory enabled me to address some open questions in the philosophy of science, such as the extent to which we understand mathematics compared to sociology, why certain research topics are more challenging than others, and the fundamental differences between science and pseudoscience, among others. However, the problem was that the theory did not yield any predictions that could be falsified through experimentation. As a result, I chose to take a risk and further develop the mathematics to generate such predictions. This led to the creation of a function that describes how nescience decreases as research effort increases. This function allows us to predict the maximum increase in knowledge about a topic based on the amount of effort we are willing to invest in understanding it.

Yet, I still wasn't entirely satisfied, so I decided to push the theory even further and seek a novel prediction—something that had not been observed before. New advancements in the mathematical foundations of the theory enabled me to uncover a highly counterintuitive property: sometimes, for certain classes of topics, additional research can be counterproductive. In other words, the more research we do, the more confused we become, as it is not possible to increase our knowledge beyond a critical point for these topics, even if that point is far from perfect knowledge.

%
% Section: About the book
%

\subsubsection*{About the Book}

The theory of nescience draws upon concepts from various academic disciplines, including computability, randomness, information theory, complexity, probability, graph theory, philosophy of science, and many more. Nevertheless, this book is self-contained, requiring only a basic understanding of first-year calculus, linear algebra, and some programming experience. The content is designed to cater to readers with diverse backgrounds, such as mathematicians, computer scientists, engineers, etc. The mathematical level is suitable for graduate students or advanced undergraduates.

The book is structured into three main parts: Background, Foundations, and Applications. Readers already familiar with the mathematics covered in the Background section may proceed directly to the Foundations part. However, it is highly recommended to at least briefly review the notation used in these chapters. Once acquainted with the details of the theory of nescience described in the Foundations section, the reader can move on to the Applications. A comprehensive understanding of the theory is not necessary to grasp the applications; a basic knowledge of the main concepts and results should suffice.

\bigskip

\begin{itemize}

\item \emph{Chapter \ref{chap:Introduction} Introduction} offers a gentle introduction to the theory of nescience, along with a brief overview of the main results. The chapter avoids the use of advanced mathematics, but the concepts are still introduced semi-formally. Although not advised, readers who find it difficult to follow the mathematics behind the theory can read only this first chapter, the introductory sections of the remaining chapters in the Background and Foundations parts, and then proceed directly to the Applications.

\end{itemize}

\bigskip

\emph{PART I Background} serves as an introduction to the mathematics needed to measure our lack of knowledge about a research topic and the randomness of a string. The goal of this part is to establish notation, formally define concepts, and prove significant results. Although no prior knowledge is assumed for following the material, it is recommended to consult the standard literature (refer to the References section at the end of each chapter) for a thorough understanding of these topics. Additional subjects are covered in the appendices.

\begin{itemize}

\item \emph{Chapter \ref{chap:Discrete_Mathematics} Discrete Mathematics} offers a summary of the fundamental of discrete mathematics needed to grasp the more advanced topics discussed in the book. This chapter serves as a quick review of these concepts, without providing formal definitions or proving theorems. Topics covered include sets, relations, strings, graphs, vectors, matrices and counting methods.

\item \emph{Chapter \ref{chap:Probability Theory} Discrete Probability} provides an introduction to the foundational concepts of probability of discrete events. Topics covered include conditional probability, random variables, characterizing distributions, common distributions, and large random samples. This chapter aims to equip readers with the necessary background in probability to understand more advanced mathematics presented in the book.

\item \emph{Chapter \ref{chap:Computability} Computability} presents a formal definition of the concept of algorithm. We introduce the idea of a universal Turing machine and demonstrate that certain well-defined mathematical problems cannot be solved by computers. The essential tools of oracle Turing machines and Turing reducibility are also examined in detail. Key results in computational complexity are briefly reviewed.

\item In \emph{Chapter \ref{chap:Coding} Coding}, we explore the properties of codes and, specifically, how codes enable us to compress text without losing information by removing statistical redundancy. We will see that there is a limit to how much text can be compressed using this technique, and that this limit is determined by the entropy of the source. The relation between optimal codes and discrite probabilities is also covered.

\item \emph{Chapter \ref{chap:Algorithmic_Information} Complexity} introduces an absolute metric, called Kolmogorov complexity, to measure the amount of information contained in a string by calculating the length of the shortest computer program that can print that string. The properties of this metric are studied in detail. The relationship between string complexity and randomness is also discussed.

\item \emph{Chapter \ref{ch:Learning} Learning} investigates the relationship between codes and probabilities. It also provides a concise overview of the field of statistical learning, focusing on existing approaches that apply the concept of minimum string length to the problem of stochastic model evaluation and optimal parameter selection. An introduction to the concepts and notation of nonlinear multiobjective optimization problems is also included.

\item \emph{Chapter \ref{chap:Philosophy} Philosophy of Science} is a brief introduction to the field of philosophy of science. We will review concepts such as scientific representations, models, theories, and other aspects of science from a philosophical perspective, identifying the crucial elements that any formal theory of science should encompass. The chapter also contains an overview of the current state of the art regarding the scientific method.

\end{itemize}

\bigskip

\emph{PART II Foundations} offers a comprehensive presentation of the theory of nescience, including formal definitions of its concepts and proofs of the key theoretical results. This part of the book represents the core of the new theory. Readers with a strong background in computability, complexity, information theory, and probability may proceed directly to this part.

\begin{itemize}

\item \emph{Chapter \ref{cha:Topics-and-Descriptions} Entities, Representations, and Descriptions} introduces the fundamental components of the theory of nescience: entities, representations, and descriptions. The properties of these elements and their interrelationships are examined. The chapter explores how multiple representations and descriptions can be combined, the incorporation of background knowledge in research, the connection between perfect knowledge and randomness, and proposes a novel concept of research area.

\item \emph{Chapter \ref{chap:Miscoding} Miscoding} addresses the challenging task of representing abstract and non-abstract research entities as strings of symbols for research purposes. The chapter formally introduces the concept of miscoding and investigates its properties. Miscoding quantifies the error introduced due to improper encodings.

\item \emph{Chapter \ref{chap:Mismodel} Mismodel} introduces a new metric called mismodel. The purpose of the concept of mismodel is to provide a unified framework for understanding and evaluating the quality of descriptions or models in the context of research. By combining inaccuracy and surfeit, mismodel offers a comprehensive assessment of how well a description or model captures the essential features of an entity while avoiding unnecessary complexity or redundancy. 

\item \emph{Chapter \ref{chap:Nescience} Nescience} is the central chapter of the book, containing the mathematical foundations of the new theory. The chapter formally defines the concept of nescience and studies its main properties, such as the evolution of nescience over time, the meaning of perfect knowledge, and the identification of our current best model.

\item \emph{Chapter \ref{chap:Interesting-Research-Questions} Interesting Questions} outlines a procedure for identifying interesting aspects within a large collection of measurable objects, particularly for discovering new research questions and topics. New concepts such as relevance and applicability are defined and investigated.

\item \emph{Chapter \ref{chap:Properties-Nescience} Advanced Properties} delves into advanced concepts and properties of the theory of nescience. While not essential for understanding the theory's applications, readers are encouraged to explore these properties during a subsequent reading of the book. Among the new concepts introduced are an axiomatic version of the theory, graspness as a measure of a research topic's difficulty, and the minimum effort required to reduce a topic's nescience.

\end{itemize}

\bigskip

\emph{PART III Applications} presents a collection of practical applications of the concept of nescience in areas such as machine learning, software engineering, philosophy of science, and computational creativity. These applications have been chosen to encompass the entire spectrum of potential topics, ranging from abstract ones (research topics) to real objects and strings (computer programs).

\begin{itemize}

\item \emph{Chapter \ref{chap:Machine-Learning} Machine Learning} explores how the concept of nescience can be applied to entities represented by large datasets. Specifically, the methodology will be used to select relevant features, identify optimal models, and compute errors. Additionally, new machine learning algorithms, such as a novel approach to deriving optimal decision trees, will be proposed.

\item \emph{Chapter \ref{chap:Software-Engineering} Software Engineering} discusses the use of the theory of nescience with computer programs in order to measure our understanding of current software platforms (operating systems, networking middleware, productivity tools, etc.). We will evaluate whether current software versions are superior to past versions or if software quality is deteriorating over time. The results will also be applied to the automatic discovery of errors, with the aim of improving software quality.

\item \emph{Chapter \ref{chap:philosophy-science} Philosophy of Science} examines the application of the new metrics introduced in this book to the study of science and its methods. Some significant open problems in the field of philosophy of science will be addressed, including the demarcation problem (distinguishing science from pseudoscience) and the question of how science progresses. Various proposals of the scientific method will be evaluated in the context of the theory of nescience and compared to our own proposal.

\item \emph{Chapter \ref{chap:computational-creativity} Computational Creativity} demonstrates the practical application of the methodology for discovering interesting things. In particular, the methodology will be applied to find new research questions and topics, with multiple examples of interesting questions and research topics provided.

\end{itemize}

\bigskip

\emph{Appendix \ref{apx:foundations_mathematics} Foundations of Mathematics} describes three distinct theoretical frameworks for formalizing mathematics: logic and set theory, dependent type theory, and category theory. These frameworks can also serve as a solid foundation for the theory of nescience.

\emph{Appendix \ref{apx:math} Advanced Mathematics} provides a concise overview of some mathematical concepts used in the book that play a secondary role in the development of the theory. These concepts are included in this appendix for reference.

\emph{Appendix \ref{apx:coq} Mechanical Proofs} offers a mechanical implementation of the axioms of the theory of nescience and its most significant results, based on the calculus of inductive constructions and, specifically, the \texttt{Coq} proof assistant.

Lastly, \emph{Appendix \ref{apx:photos} About the Photos} explains the origin and intended meaning of the carefully selected photographs featured at the beginning of each chapter.

%
% Section: Acknowledgements
%

\section*{Acknowledgements}

I would like to express my gratitude to everyone who has contributed their comments and ideas to the development of the theory of nescience. In particular, I am grateful to Antonio Fernández, Vincenzo Mancuso, and Paolo Casari, who believed in and supported this project from its very beginning when it was merely a far-fetched idea (although it may still be). Others who have provided contributions and valuable feedback include Héctor Cordobés, Luis F. Chiroque, Agustín Santos, Marco Ajmone, Pablo Rojo, Manuel Cebrián, Andrés Ortega, Emilio Amaya, Mattis Choummanivong, Alexander Lynch, Andrés Carrillo, and Simon Bihoreau. The \texttt{fastautoml} library described in Chapter \ref{chap:Machine-Learning} has been partially funded by the IMDEA Networks Institute, the European Union's Horizon 2020 research and innovation programme under grant agreement No 732667 RECAP, and Nokia Spain through the project NetPredict. Also, I would like to extend my thanks to OpenAI/ChatGPT for their valuable contributions in writing this book, as their assistance has played an important role in writing the text describing the ideas presented in it.

Lastly, I am grateful to my parents, who provided me the opportunities they never had, and to my wife and three children, who give my life fundamental meaning.

%
% Section: Disclaimer
%

\section*{Disclaimer}

I want to clarify that the vast majority of ideas presented in this book are not my own. The inspiration comes from the brilliant minds of our history, such as Occam, Llull, Leibniz, Newton, and philosophers like Plato, Popper, Feyerabend, Wittgenstein, among others. Additionally, I have built upon the mathematical theories developed by scientists like Turing, Church, Post, Shannon, Solomonoff, Chaitin, Kolmogorov, and many more. My sole original contribution with this book may be connecting some dots and offering a potentially interesting reinterpretation of some existing ideas. The References sections at the end of each chapter contain descriptions of the works I have relied upon while writing the book. In the text, I use passive voice ("it is defined") when I know that a concept is not mine, and active voice ("we define") when I am not aware of a previous use of the concept by someone else.

