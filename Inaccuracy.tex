%
% CHAPTER: Inaccuracy
%

\chapterimage{Train_wreck_at_Montparnasse_1895.pdf} % Chapter heading image

\chapter{Inaccuracy}
\label{chap:Error}

\begin{quote}
\begin{flushright}
\emph{A little inaccuracy sometimes saves\\
tons of explanations.}\\
Saki
\end{flushright}
\end{quote}
\bigskip

In Section \ref{sec:descriptions_models}, we introduced the idea of a description, or a model, of an entity as a computer program. When this program is executed, it reproduces one of the representations encoding the entity in question. More precisely, a description $d$ for a representation $r$ of an entity $e$ is a Turing machine that produces the string $r$ when a universal Turing machine $\delta$ interprets it. However, given our typically incomplete understanding of the entity $e$ being studied, the actual output of the description $\delta(d)$, denoted as $r'$, will be similar, but not identical to $r$. In this chapter, we will explore the error brought about by flawed models—specifically, how closely $r'$ approximates the original string $r$. We denote this form of error as the inaccuracy of the description $d$.

Inaccuracy serves as the second metric in assessing our understanding of a research entity. The underlying idea is that the more accurate our model, the better our understanding of the entity. Formally, we calculate the inaccuracy of a description $d$ as the normalized information distance between the original representation $r$ and the output representation $r'$ generated by our description $d$. That is, inaccuracy is quantified as the length of the smallest computer program capable of correcting the erroneous output of our model.

Inaccuracy, serving as the second gauge to measure our comprehension of a research entity, is based on the principle that the more precise our model, the better our grasp of the entity. Formally, the inaccuracy of a description $d$ is computed as the normalized information distance between the original representation $r$ and the output representation $r'$ generated by the description $d$. Thus, inaccuracy is assessed as the extent of the smallest computer program that can rectify the incorrect output of our model.

Inaccuracy evaluates how well the output of our description aligns with the selected representation encoding the entity. However, this representation could be flawed itself, as discussed in the preceding chapter. Inaccuracy focuses solely on the description $d$, neglecting the potential miscoding within the representation $r$. Furthermore, even though it doesn't require an oracle, inaccuracy cannot be calculated for every case, so it needs to be estimated in practical situations, as we will explore in Part III of this book.

In this chapter, we will formally define inaccuracy and examine its characteristics. We will also scrutinize how inaccuracy varies when a conditional description of a representation is used as opposed to an unconditional one. Finally, we will extend the concept of inaccuracy from individual entities to entire research areas.

This study of inaccuracy is not merely academic but has practical implications as well. Accurate models are crucial to many fields, from predicting climate change to designing artificial intelligence systems. Therefore, understanding and quantifying inaccuracy can lead to improvements in these models, allowing us to make better predictions and decisions.

%
% Section: Inaccuracy
%

\section{Inaccuracy}
\label{sec:inaccuracy:inaccuracy}

In the process of studying an entity $e \in \mathcal{E}$ through a representation $r \in \mathcal{R}_e$, we may encounter situations where our proposed description $d$ fails to provide an accurate depiction for $r$. In other words, $d \notin \mathcal{D}_r$ (refer to Definition \ref{def:descriptions_model}). Under such circumstances, when the universal Turing machine $\delta$ receives $d$ as an input, it will yield a string $r'$ that diverges from the original string $r$. On an intuitive level, one could infer that $d$ serves as an inaccurate description of the entity $e$. However, given that descriptions convey entities indirectly via representations, our formal interpretation of inaccuracy must be predicated upon the representations employed, rather than the original entities. We must also acknowledge the possibility of representations being inherently flawed, an issue previously addressed through the notion of miscoding. With these considerations in mind, we propose the following definition for the concept of an inaccurate description.

\begin{definition}
Let $r \in \mathcal{B}^\ast$ represents a representation, and $d \in \mathcal{D}$ a description, where $d = \langle TM, a \rangle$. If the outcome of $TM(a)$ is a string $r'$, such that $r \neq r'$, we designate $d$ as an \emph{inaccurate} description for $r$.
\end{definition}

Our proposed description $d$ may not fall within the spectrum of valid descriptions $\mathcal{D}_r$ for $r$ (an instance of positive inaccuracy), and the representation $r$ may not be included in the valid $\mathcal{R}^\star_e$ representations for the entity $e$ (indicative of positive miscoding).

In instances where our description proves inaccurate, we aspire to quantify the extent of this inaccuracy. In the context of computational machines, an intuitive approach to defining this measure would involve calculating the difficulty in converting the incorrect representation $r'$—produced by running $d$ through the universal Turing machine—into the original representation $r$. In essence, this involves the computation of the normalized information distance between $r'$ and $r$.

\begin{definition} [Inaccuracy]
\label{def:inaccuracy:inaccuracy:inaccuracy}
Let us consider $r \in \mathcal{B}^\ast$ as a representation, and $d \in \mathcal{D}$ as a description, where $d = \langle TM, a \rangle$. We then define the \emph{inaccuracy} of the description $d$ with respect to the representation $r$, denoted as $\iota(d, r)$, according to the following formula:
\[
\iota(d, r) = \frac{ \max\{ K \left(r \mid \delta(d) \right), K \left( \delta(d) \mid r \right) \} } { \max\{ K(r), K \left(\delta(d) \right) \} }
\]
\end{definition}

The employment of a relative measure of inaccuracy, rather than an absolute one, facilitates the comparison of inaccuracies across different descriptions for the same representation, as well as across various descriptions for different representations.

Much like miscoding (refer to Definition \ref{def:miscoding}), inaccuracy is determined using a bidirectional method: we compute the length of the shortest computer program that can generate the correct representation $r$ given the erroneous one $r'$, and vice versa—namely, the computation of the shortest computer program that can generate $r'$ given the string $r$. Essentially, the representation produced by a valid description needs to encompass all the necessary information for reconstructing an entity, while it must exclude erroneous or irrelevant information. 

\begin{example}
Inaccuracy primarily concerns the difficulty of correcting the output of a description, that is, the output of a computable model, rather than the difficulty of rectifying the description itself. For instance, if we have a dataset generated by a system perfectly described by a quadratic function, and we choose to use a linear function as the description, inaccuracy will evaluate the original quadratic dataset against the predicted linear dataset. Inaccuracy does not measure how challenging it is to convert the incorrect linear model into the correct quadratic one. In this regard, if the original dataset comprises 10 points, a perfectly fitted polynomial of degree ten would also register an inaccuracy of zero. Deciding on the better model between the zero-inaccuracy quadratic and the zero-inaccuracy ten-degree polynomial falls under the purview of the surfeit metric (see Chapter \ref{chap:Redundancy}).
\end{example}

Given its foundation in Kolmogorov complexity, inaccuracy is a quantity that, in general, cannot be practically computed and must be approximated. The method for approximating inaccuracy is contingent on the unique characteristics of the entities under investigation and their representations.

The inaccuracy of a description conveniently falls within the range of $0$ and $1$, as illustrated by the following proposition.

\begin{proposition}
\label{prop:inaccuracy:inaccuracy:range}
For all representations $r \in \mathcal{B}^\ast$ and all descriptions $d \in \mathcal{D}$, it is true that $0 \leq \iota(d, r) \leq 1$.
\end{proposition}
\begin{proof}
This is because for all $x, y \in \mathcal{B}^\ast$, it follows that $0 \leq \frac{ \max\{ K(x \mid y), K(y \mid x) \} } { \max\{ K(x), K(y) \} } \leq 1$ in accordance with Proposition \ref{prop:ncd_between_zero_and_one}.
\end{proof}

The preceding proposition applies to all possible descriptions $d$ and representations $r$, even in cases where a description $d$ is not intended to model the representation $r$. In such scenarios, the inaccuracy would be approximately one.

Inaccuracy is exactly zero if, and only if, the description $d$ constitutes one of the feasible valid descriptions of the representation $r$.

\begin{proposition}\label{prop:perfect_description}
Given a description $d \in \mathcal{D}$ for a representation $r \in \mathcal{B}^\ast$, it is the case that $\iota(d, r) = 0$ if, and only if, $d$ is a member of the valid descriptions of $r$, i.e., $d \in \mathcal{D}_r$.
\end{proposition}
\begin{proof}
If $d$ belongs to the set $\mathcal{D}_r$, it follows that $K \left( r \mid \delta(d) \right) = K \left( \delta(d) \mid r \right) = 0$, implying that $\iota(d, r) = 0$. Conversely, if $\iota(d, r) = 0$, it means that $\max\{ K \left( r \mid \delta(d) \right), K \left( \delta(d) \mid r \right) \} = 0$. This leads to the conclusion that $K \left( r \mid \delta(d) \right) = K \left( \delta(d) \mid r \right) = 0$ and, consequently, $d$ is part of the set of valid descriptions for $r$, i.e., $d \in \mathcal{D}_r$.
\end{proof}

%
% Section: Reducing Inaccuracy
%

\section{Decreasing Inaccuracy}

{\color{red} TODO

In the previous section we saw how, given a representation, to reduce of the inaccuracy by means of using a different description. In this section we are going to study an alternative approach to reduce our unknown about an entity. Instead of changing the description, perhaps it is better to change the represetation of the entity. Of course, change the representation of an entity might increase the miscoding of that entity, but this change could be smaller that the gain we have by means of reducing the inaccuacy.

\begin{definition}
Let $e \in \mathcal{E}$ be an entity, and $r_1, r_2 \in \mathcal{R}_e$ be two of its representations, and $d_1, d_2 \in \mathcal{D}$ be two descriptions. The ratio of change between the inaccuracy of the description $d$ and the miscoding for the representations $r_1, r_2$, denoted by $\Delta_{\mu \iota} ( r_1, r_2, d )$, is defined as:
\[
\Delta_{\mu \iota} ( r_1, r_2, d ) = \frac{\mu(r_1) - \mu(r_2)}{\iota(d, r_1) - \iota(d, r_2)}
\] 
assuming that $\iota(d, r_1) - \iota(d, r_2) \neq 0$.
\end{definition}

If both, miscoding and innacuracy, decreases, that is $\mu(r_1) - \mu(r_2) > 0$ and $\iota(d, r_1) - \iota(d, r_2) > 0$, we should prefer $r_2$ over $r_1$. If both increase, that is $\mu(r_1) - \mu(r_2) > 0$ and $\iota(d, r_1) - \iota(d, r_2) > 0$, in general it is not a good idea to replace $r_1$ by $r_2$.

}

%
% Section: Inaccuracy Rate of Change
%

\section{Inaccuracy Rate of Change}

At times, we might be compelled to posit that the exclusive method to attain improvement in the precision of our description is by incurring a loss in the miscoding of our representation. The extent of miscoding that we must relinquish in order to enhance inaccuracy is referred to as the miscoding-inaccuracy trade-off (refer to Section \ref{sec:trade_offs} for more information of trade-offs in multiobjective optimization).

\begin{definition}
Let $e \in \mathcal{E}$ be an entity, and $\mathbf{x}_1, \mathbf{x}_2 \in \mathcal{R}_e \times \mathcal{D}$ be two hypothesis, with $\mathbf{x}_1 = (r_1, d_1)$ and $\mathbf{x}_2 = (r_2, d_2)$. The rate of change between the inaccuracy and the miscoding of the hypothesis $\mathbf{x}_1, \mathbf{x}_2$, denoted by $\Delta_{\mu \iota} ( \mathbf{x}_1, \mathbf{x}_2 )$, is defined as:
\[
\Delta_{\iota \mu} ( \mathbf{x}_1, \mathbf{x}_2 ) = \frac{\iota(d_1, r_1) - \iota(d_2, r_2)}{\mu(r_2) - \mu(r_1)}
\] 
assuming that $\mu(r_2) - \mu(r_1) \neq 0$.
\end{definition}

We are interested in those hypothesis were a small loss in miscoding has a positive impact in inaccuracy. That is, we are looking for a $\Delta_{\mu \iota} ( \mathbf{x}_1, \mathbf{x}_2 ) > M$, where $M$ is large positive number.


{\color{red} TODO: properly pareto optimal}

%
% Section: Inaccuracy of Joint Representations
%

\section{Inaccuracy of Joint Representations}

Given two representations $r$ and $s$, we want to know the inaccuracy of the model $d$ when describing the joint representation $rs$. Since we require that $rs$ must be a valid representation, the formalization of the concept of inaccuracy applied to joint representation is straightforward, and it does not require a new definition:
\[
\iota(d, rs) = \frac{ \max\{ K \left(rs \mid \delta(d) \right), K \left( \delta(d) \mid rs \right) \} } { \max\{ K(rs), K \left(\Gamma(d) \right) \} }
\]
As a direct consequence of Proposition \ref{prop:range_miscoding}, if $r, s \in \mathcal{B}^\ast$ are two arbitrary representations and $d \in \mathcal{D}$ is a description, we have that $0 \leq \iota(d, rs) \leq 1$.

{\color{red} TODO: Recall the properties of NID, and particularize for the case of inaccuracy of joint representations.}

%
% Section: Inaccuracy of Conditional Descriptions
%

\section{Conditional Inaccuracy}

In this section, we delve deeper into the concept of inaccuracy by considering its application to conditional descriptions. Specifically, we explore the inaccuracy of a description when assessed in conjunction with pre-existing background knowledge, a notion we term \emph{conditional inaccuracy}. As we will see below, the inaccuracy of a description will never increase compare to its unconditional version; at its worst, it will simply remain constant. This property of conditional inaccuracy makes it a practical method for evaluating new concepts or models and gauging their effectiveness in explaining the entity of our interest.

In Definition \ref{def:conditional_description}, we introduced the concept of a conditional description $d$, for a representation $r$, given an arbitrary background string $s$. This is denoted by $d \mid s$ and was defined as the self-delimited concatenated string $\langle d, s \rangle$, where $d = \langle TM, a \rangle$ and $TM \left(\langle a, s \rangle \right) = r$. If $TM \left(\langle a, s \rangle \right) = r'$, with $r \neq r'$, then $d \mid s$ is referred to as an \emph{inaccurate} conditional description of $r$. We also observed that $d \mid s$ must be defined for all possible $s$, and that we refer to conditioning on the empty string $d \mid \lambda$ as the unconditional version of $d$.

Drawing from the idea of inaccuracy as outlined in Definition \ref{def:inaccuracy:inaccuracy:inaccuracy}, we can formulate the notion of conditional inaccuracy to encapsulate the error induced when employing an inaccurate conditional description.

\begin{definition}
Let $r \in \mathcal{B}^\ast$ be a representation, $s \in \mathcal{B}^\ast$ a string, and $d \mid s$ an inaccurate conditional description. We characterize the \emph{conditional inaccuracy} of the description $d$ for the representation $r$ given the string $s$, denoted as $\iota(d \mid s, r)$, according to the following equation:
\[
\iota(d \mid s, r) = \frac{ \max\{ K \left(r \mid \delta(d \mid s) ) \right), K \left( \delta(d \mid s) \mid r \right) \} } { \max\{ K(r), K \left( \delta(d \mid s) \right) \} }
\]
\end{definition}

Conditional inaccuracy is defined as the normalized compression distance between the representation $r$ and the string computed by the conditional description $d \mid s$.

As a normalized measure, the conditional inaccuracy of a description falls within the interval between $0$ and $1$.

\begin{proposition}
\label{prop:range_conditional_inaccuracy}
Let $r \in \mathcal{B}^\ast$ be a representation, $s \in \mathcal{B}^\ast$ be a string, and $d \mid s$ be a conditional description of $r$ given the string $s$. Then $0 \leq \iota(d \mid s) \leq 1$.
\end{proposition}
\begin{proof}
This assertion holds true given $0 \leq \frac{ \max{ K(x \mid y), K(y \mid x) } } { \max{ K(x), K(y) } } \leq 1$ for all $x, y \in \mathcal{B}^\ast$, as established by Proposition \ref{prop:ncd_between_zero_and_one}.
\end{proof}

The conditional inaccuracy assumes a null value if, and only if, the conditional description $d \mid s$ serves as one of the plausible valid models of the representation $r$.

\begin{proposition}\label{prop:perfect_description}
Let $r \in \mathcal{B}^\ast$ be a representation, $s \in \mathcal{B}^\ast$ be a string, and $d \mid s$ be a conditional description of $r$ given the string $s$, where $d = \langle TM, a \rangle$. Then $\iota(d \mid s) = 0$ if, and only if, $TM \left(\langle a, s \rangle \right) = r$.
\end{proposition}
\begin{proof}
If $TM \left(\langle a, s \rangle \right) = r$, it can be deduced that $K \left( r \mid \delta(d \mid s) \right) = K \left( \delta(d \mid s) \mid r \right) = 0$, and consequently $\iota(d \mid s, r) = 0$. Conversely, if $\iota(d \mid s, r) = 0$, we observe that $\max\{ K \left( r \mid \delta(d \mid s) \right), K \left( \delta(d \mid s) \mid r \right) \} = 0$. This implies that $K \left( r \mid \delta(d \mid s) \right) = K \left( \delta(d \mid s) \mid r \right) = 0$, and therefore $TM \left(\langle a, s \rangle \right) = r$.
\end{proof}

Incorporating established prior knowledge into research does not increase the inaccuracy of a description. If this background knowledge is relevant to the description of the representation, the oracle will utilize it appropriately. Conversely, if the prior knowledge is irrelevant, the oracle will simply disregard it. The following theorem formalizes this notion.

\begin{theorem}
\label{th:conditional_inaccuracy}
Let $r \in \mathcal{B}^\ast$ be a representation, and $d \in \mathcal{D}$ a conditional description of $r$. Then
\[
\iota(d \mid s, r) \leq \iota(d , r)
\]
for all strings $s \in \mathcal{B}^\ast$.
\end{theorem}
\begin{proof}
{\color{red} TODO: review

Given that $\iota(d , r)$ is equivalent to $\iota(d \mid \lambda, r)$ we have to show 
\[
\frac{ \max\{ K \left(r \mid \delta(d \mid s) \right), K \left( \delta(d \mid s) \mid r \right) \} } { \max\{ K(r), K \left( \delta(d \mid s) \right) \} } \leq \frac{ \max\{ K \left(r \mid \delta(d \mid \lambda ) \right), K \left( \delta(d \mid \lambda ) \mid r \right) \} } { \max\{ K(r), K \left( \delta(d \mid \lambda ) \right) \} }
\]
This inequality follows from the fact that $K \left(r \mid \langle \delta(d), s \rangle \right) \leq  K \left(r \mid \delta(d) \right)$, as demonstrated in Proposition \ref{prop:kolmogorov_joint_conditional}.
}
\end{proof}

Theorem \ref{th:conditional_inaccuracy} represents a seminal result in the theory of nescience. It lays the groundwork for the development of a robust methodology to deepen our understanding (i.e., reduce inaccuracy) of a research entity. In practical contexts, our main focus will be on prior knowledge that directly pertains to our study. However, the essence of Theorem \ref{th:conditional_inaccuracy} is its indication that we can venture into concepts from seemingly unrelated domains without affecting our primary investigation. This theorem becomes especially valuable when such explorations are automated (see Chapter \ref{chap:computational-creativity}).

\begin{example}
The P vs NP problem stands as a pivotal unresolved question in computer science. It seeks to determine whether every problem, whose solution can be verified quickly (in polynomial time), can also be solved in a similar expedited manner. The intricate relationship between these two classes, P (problems solvable quickly) and NP (problems verifiable quickly), remains undeciphered. Providing a comprehensive, self-contained solution to this problem in formal language could be a daunting task. However, drawing upon pre-existing knowledge can significantly condense the solution. For instance, incorporating insights from Algorithm Theory, which elucidates the classification and efficiency of algorithms, or leveraging principles from Formal Language Theory, which maps out the categorization and approach to different computational challenges such as regular or context-free languages, and underscores the significance of Turing machines, can be immensely beneficial. Moreover, harnessing and building upon established background knowledge might not only simplify our descriptions but could also pave the way for a deeper understanding and potential resolution of the P vs. NP conundrum.

\end{example}

Finally, given two representations $r$ and $t$, the formalization of the concept of conditional inaccuracy, when applied to the joint representation $rt$, is quite straightforward, and it does not demand a new definition:
\[
\iota(d \mid s) = \frac{ \max\{ K \left(rt \mid \delta(d \mid s) \right), K \left( \delta(d \mid s) \mid rt \right) \} } { \max\{ K(rt), K \left(\delta(d \mid s) \right) \} }
\]

%
% Section: Inaccuracy of Areas
%

\section{Inaccuracy of Areas}

The concept of conditional inaccuracy can be extended to research areas in order to quantitative measure the amount of effort required to fix an inaccurate description of the area assuming some already existing background knowledge.

{\color{red} TODO: review notation}

\begin{definition}
Let $\mathcal{A} \subset \mathcal{E}$ be an area with known subset $\hat{\mathcal{A}} = \{r_1, r_2, \ldots, r_n\}$, $s \in \mathcal{B}^\ast$ a string, and $d_{\hat{\mathcal{A}} \mid s}$ a condtional description. We define the \emph{inaccuracy of the area} $d_{\hat{\mathcal{A}}}$ as:
\[
\iota(d_{\hat{\mathcal{A}} \mid s}) = \frac{ \max\{ K \left( \langle r_1, r_2, \ldots, r_n \rangle \mid \delta(\langle d, t \rangle) \right), K \left( \delta(\langle d, t \rangle) \mid \langle r_1, r_2, \ldots, r_n \rangle \right) \} } { \max\{ K(\langle r_1, r_2, \ldots, r_n \rangle), K \left(\delta(\langle d, t \rangle) \right) \} }
\]
\end{definition}

{\color{red}

TODO: Recall the properties of areas, and particularize for the case of inaccuracy.
TODO: Study the miscoding of subareas of areas in relation to the miscoding of areas
TODO: Say something about the concept of intradisciplinary and interdisciplinary in the context
of miscoding and provide a reference to the chapter of computational creativity.

}

%
% Section: References
%

\section*{References}

A good introduction to the study of uncertaintines (error analysis in models) in science, and in particular in physics, chemistry, and engineering, is the best-selling text \cite{taylor2022introduction}, which also features the same image of a crashed train than in the introduction to this chapter.

{\color{red} TODO: Add more references.}

