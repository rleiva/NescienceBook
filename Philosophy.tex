%
% CHAPTER - Philosophy
%

\chapterimage{School_of_Athens.pdf}

\chapter{Philosophy of Science}
\label{chap:Philosophy}

\begin{quote}
\begin{flushright}
\emph{To go where you don't know, \\
you have to go the way you don't know.} \\
San Juan de la Cruz 
\end{flushright}
\end{quote}
\bigskip

The \emph{philosophy of science}\index{Philosophy of science} is the branch of philosophy that examines the foundations, methods, and implications of scientific inquiry. It explores how scientific knowledge is generated, the validity of scientific theories, the nature of scientific reasoning, and the role of values in science. By addressing fundamental questions about objectivity, reality, and the limits of scientific explanation, the philosophy of science helps us understand how science works and its impact on our understanding of the world.

The philosophy of science provides a theoretical framework for analyzing the core elements that constitute our theory of nescience. It enables us to critically examine the foundations and assumptions of our theory, guiding us toward the identification of the essential questions that we must address. Moreover, philosophical inquiry compels us to rigorously push the boundaries of our analysis, ensuring that our theory is explored to its ultimate consequences, both logically and conceptually. This approach strengthens the robustness of the theory, even if these results do not directly translate into practical applications.

A central theme in scientific methodology is the distinction between \emph{discovery} and \emph{justification}. Discovery refers to how new ideas or hypotheses emerge, often through creativity, intuition, or serendipity, while justification involves the use of evidence and logical reasoning to evaluate and validate these ideas. Philosophers of science have historically emphasized justification, focusing on methods to rigorously test and analyze scientific claims. However, both discovery and justification are critical to understanding scientific progress, and this chapter will address both aspects.

In this chapter, we provide a concise overview of key elements from the philosophy of science, as well as relevant concepts from other branches of philosophy, such as metaphysics, epistemology, and ontology, that are important to the theory of nescience. Certain other topics within the philosophy of science, such as the problem of objectivity (examining whether science can be truly objective or is influenced by social and personal values) or the role of values in science, including the relationship between ethical, social, and political values and scientific practices, are not included in this review, as they are not directly relevant to a mathematical theory of nescience.

The chapter begins with a brief introduction to the field and its importance in understanding scientific inquiry. We delve into the problem of which entities can be known, examining the scope of scientific knowledge and the nature of observable and unobservable phenomena. The chapter also addresses the concept of scientific representation, discussing how models, theories, and laws reflect aspects of reality. We examine how science discovers new knowledge, the principles behind the scientific method, and the various ways in which scientists formulate and test hypotheses. Finally, we explore the limits of science, considering the boundaries of what science can explain and where its explanatory power may fall short. 


%
% Section: What is Science
%

\section{What is Science}

\emph{Science}\index{Science} is a systematic method of investigating the world around us, aimed at generating reliable knowledge through observation and reasoning. Unlike other forms of inquiry, science is rooted in the idea that knowledge must be based on evidence that can be tested and verified. By combining theoretical thinking with empirical data, science offers a powerful way to explain, predict, and understand natural phenomena. Sometimes science seeks explanations for practical purposes, but other times it is sought simply to satisfy our intellectual curiosity.

The \emph{scientific method}\index{Scientific method} is understood as the systematic process by which science acquires new knowledge. In schools, the scientific method is often taught as a series of steps: first observing and describing a phenomenon, then coming up with a hypothesis to explain it, testing that hypothesis through experiments, analyzing the results, and finally making a conclusion. However, the idea of a single, universal scientific method that can be applied to all sciences isn’t widely accepted anymore. Instead, scientists and philosophers recognize that different scientific fields require different methods because each field faces its own challenges and complexities.

The following is a list of the key features that make science distinct and valuable as a way of knowing.

\begin{itemize}

\item \emph{Empiricism}\index{Empiricism}: At its core, science is an empirical endeavor, meaning it relies on observation, experimentation, and measurable evidence to understand the natural world. Scientific knowledge is grounded in data that can be gathered through direct or indirect observation, ensuring that claims can be tested and verified by others.

\item \emph{Testability}\index{Testability}: A key characteristic of science is its focus on developing testable hypotheses, that is, statements or predictions that can be empirically investigated. This means that scientific claims must be falsifiable, open to potential disproof if the evidence does not support them. This distinguishes science from fields that rely on unfalsifiable or speculative claims.

\item \emph{Theoretical Frameworks}\index{Theoretical framework}: Science is not merely about collecting facts; it seeks to develop broader explanations through models, laws, and theories. Models offer simplified representations of complex systems, while theories are well-supported frameworks that explain the underlying mechanisms of phenomena. These frameworks help interpret data and guide further investigation, offering coherence to the body of scientific knowledge.

\item \emph{Self-Correction}\index{Self-correction}: A defining feature of science is its self-correcting nature. Scientific theories are not static; they evolve as new evidence comes to light. When new data contradicts a theory, science adapts, modifies, refines, or sometimes discards the theory in favor of one that better fits the evidence. This continuous process of revision ensures that scientific knowledge becomes more accurate over time.

\item \emph{Generalizability}\index{Generalizability}: Science strives to uncover universal principles that apply across various contexts, not just to isolated cases. While science begins with specific observations, its goal is to identify general laws and patterns that explain a broad range of phenomena. This pursuit of generalizable knowledge allows science to predict future occurrences and provide deeper insights into the workings of the natural world.

\end{itemize}

The main task of the philosophy of science is to understand how techniques such as experimentation, observation, and theory building enable scientists to discover the secrets of nature. The philosophy of science draws on other areas of philosophy, such as ontology, epistemology, metaphysics, and logic. \emph{Ontology}\index{Ontology}, the branch of philosophy concerned with the nature of existence, addresses the question of which entities exist in the real world. It examines the types of entities that science can study, whether they are observable, abstract, or indeterminate, and engages with the philosophical debates surrounding their existence. Ontology provides the foundation for exploring the boundaries of scientific knowledge and the limits of inquiry. \emph{Epistemology}\index{Epistemology} is the branch of philosophy concerned with knowledge itself—how we acquire it, what justifies it, and what its limits are. While ontology deals with what exists, epistemology addresses how we come to know what exists. In the context of science, epistemology examines the methods, evidence, and reasoning that underpin scientific investigation, exploring how scientific knowledge is built, how reliable it is, and what counts as a justified belief in scientific practice. Both ontology and epistemology are part of the broader field of \emph{metaphysics}\index{Metaphysics}, which deals with the fundamental nature of reality and existence. Metaphysics explores the most basic concepts and categories of being, such as time, space, causality, and possibility, as well as the relationship between mind and matter. \emph{Logic}\index{Logic}, the study of valid reasoning, underpins the entire scientific enterprise by providing the tools to analyze arguments, identify fallacies, and structure sound reasoning. In science, logic is used to ensure the coherence of theoretical frameworks, the validity of inferences drawn from data, and the consistency of explanations and predictions. Formal logic, including propositional and predicate logic, provides a systematic way to evaluate arguments and detect errors, while informal logic addresses reasoning in everyday scientific discourse. Together, ontology, epistemology, metaphysics, and logic provide a comprehensive philosophical foundation for understanding what science studies, how it builds knowledge, and the fundamental nature of the reality science seeks to explain.

\begin{figure}[t]
\centering

\begin{tikzpicture}[
    % font=\bfseries,
    node distance=2.5cm and 2cm,
    every node/.style={align=center},
    process/.style={rectangle, rounded corners, draw=black, minimum width=2.5cm, minimum height=1cm},
    arrow/.style={thick,->,>=stealth},
    dashedarrow/.style={thick, dashed,->,>=stealth}
]

% Nodes
\node (entities) [process] {\footnotesize \textbf{Entities}};
\node (representations) [process, right=of entities] {\footnotesize \textbf{Representations}};
\node (explanations) [process, right=of representations] {\footnotesize \textbf{Explanations}};

% Labels
\node (observation) [above=0.1cm of $(entities)!0.5!(representations)$] {\footnotesize \textbf{Observation}};

% Arrows
\draw [arrow] (entities) to (representations);
\draw [arrow] (representations) -- node[above] {\footnotesize \textbf{Discovery}} (explanations);
\draw [arrow] (explanations.north) to[out=110, in=70] (entities.north);

% Dashed Arrows
\draw [dashedarrow] (explanations.north) to[out=150, in=30] node[above] {\footnotesize Influences} (observation.north);
\draw [dashedarrow] (entities.south) to[out=330, in=210] node[below] {\footnotesize Thought Experiments} (explanations.south);

% Justification Label
\node at ($(entities.north)!0.5!(explanations.north) + (0,3cm)$) {\footnotesize \textbf{Justification}};

\end{tikzpicture}

\caption{Chapter Organization}
\label{fig:chapter-organization}
\end{figure}


% \begin{figure}[t]
% \centering

% \begin{tikzpicture}[
%     % font=\bfseries,
%     node distance=2.5cm and 2cm,
%     every node/.style={align=center},
%     process/.style={rectangle, rounded corners, draw=black, minimum width=3.5cm, minimum height=1cm},
%     arrow/.style={thick,->,>=stealth},
%     dashedarrow/.style={thick, dashed,->,>=stealth}
% ]

% % Nodes
% \node (entities) [process] {\textbf{Entities} \\ \footnotesize (concrete, abstract)};
% \node (representations) [process, right=2.5cm of entities] {\textbf{Representations} \\ \footnotesize (facts, data)};
% \node (explanations) [process, right=of representations] {\textbf{Explanations} \\ \footnotesize (theories, laws)};

% % Labels
% \node (observation) [above=0.1cm of $(entities)!0.5!(representations)$] {\textbf{Observation}};

% % Arrows
% \draw [arrow] (entities) to (representations);
% \draw [arrow] (representations) -- node[above] {\textbf{Discovery}} (explanations);
% \draw [arrow] (explanations.north) to[out=110, in=70] (entities.north);

% % Dashed Arrows
% \draw [dashedarrow] (explanations.north) to[out=150, in=30] node[above] {\footnotesize Influences} (observation.north);
% \draw [dashedarrow] (entities.south) to[out=330, in=210] node[below] {\footnotesize Thought Experiments} (explanations.south);

% % Justification Label
% \node at ($(entities.north)!0.5!(explanations.north) + (0,3.5cm)$) {\textbf{Justification}};

% \end{tikzpicture}

% \caption{Chapter Organization}
% \label{fig:chapter-organization}
% \end{figure}

This chapter on philosophy of science is structured around key components that illustrate how scientific knowledge is developed and justified (see Figure \ref{fig:chapter-organization}). It begins with a discussion on \emph{Entities}, which can be either concrete or abstract, representing the objects of scientific study. From these entities, knowledge is acquired through \emph{Observation}, which involves gathering empirical data and facts. These observations are then transformed into \emph{Representations}, such as recorded data, or facts, that scientists use to analyze and interpret phenomena. Through the process of \emph{Discovery}, these representations lead to the formulation of \emph{Explanations}, which take the form of scientific \emph{theories and laws} that describe underlying principles governing the natural world. The chapter also explores how scientific explanations influence future observations, shaping what is investigated and how data is interpreted. Additionally, thought Experiments provide an alternative way of reasoning about scientific problems beyond direct empirical observation. Finally, the chapter addresses \emph{Justification}, emphasizing the criteria by which scientific claims are validated, ensuring that discoveries and explanations are robust, reliable, and well-supported by evidence. This structure provides a comprehensive view of the scientific process, from the identification of entities to the formation and justification of scientific theories.

%
% Section: What is an Entity
%

\section{What is an Entity}
\label{sec:what-is-an-entity}

In this section, we focus on the fundamental problem of determining which kinds of entities can be known or investigated by science.

A \emph{knowable entity}\index{Knowable entity} is an object, phenomenon, or concept that can be investigated, understood, or described through scientific or intellectual inquiry. Knowable entities are those that, either directly or indirectly, can be observed, measured, inferred, or modeled, using available tools, methods, or theories. They are within the scope of human knowledge, and their properties can be analyzed or explained. Examples of knowable entities include the stars and plantes, animals, or computer algorithms. A \emph{non-knowable entity}\index{Non-knowable entity} refers to something that cannot be directly observed, measured, or understood using current scientific or intellectual methods. This could be due to limitations in technology, the abstract or metaphysical nature of the entity, or inherent epistemological boundaries. Non-knowable entities might remain beyond the reach of human understanding either temporarily (until methods evolve) or permanently (due to their nature). Examples of non-knowable entities include the nature of consciousness, the origin of the universe, or the existence of a deity. The distinction between knowable and non-knowable entities is not always fixed, but varies depending on the clarity and precision of the area of interest and the evolving nature of scientific understanding in each field.

Scientific research encompasses both \emph{concrete entities}\index{Concrete entities} and \emph{abstract entities}\index{Abstract entities}. Concrete entities refer to physical objects or phenomena that can be directly observed, measured, or interacted with, such as stars, cells, or chemical compounds. These entities form the basis of empirical research, where data is collected through direct observation or experimentation. In contrast, abstract entities are conceptual and do not have a physical presence, such as numbers, algorithms, or theoretical models. Abstract entities play a crucial role in scientific research, particularly in fields like mathematics and theoretical physics, where they provide the framework for understanding and modeling concrete phenomena. While abstract entities cannot be observed directly, they can be known through indirect methods. The inclusion of these abstract entities in scientific inquiry raises important philosophical questions about their ontological status: Are these abstract entities real in the same way that physical objects are, or are they simply conceptual tools? This question remains an open and debated issue in the philosophy of science.

Finally, in scientific inquiry, there is also a distinction between \emph{observable entities}\index{Observable entities}, which can be directly perceived or measured, and \emph{non-observable entities}\index{Non-observable entities}, which cannot be directly observed but can still be detected or inferred from empirical evidence. Observable entities include things like trees, planets, and bacteria, objects that can be seen or measured using scientific instruments. Non-observable, but still detectable, entities include things like subatomic particles and gravitational forces. These entities are often crucial for explaining observable phenomena and are identified through the use of scientific instruments and theoretical frameworks. For example, we cannot observe a quark in the same way we observe a tree, but through scientific theory, experimentation, and the detection of indirect evidence, we infer its existence.

\begin{figure}[t]
\centering
\begin{tikzpicture}

  % Define the ovals
  \node[draw, ellipse, minimum width=3.5cm, minimum height=1cm, align=center] (knowable) {Knowable};
  \node[draw, ellipse, minimum width=3.5cm, minimum height=1cm, right=of knowable, xshift=0cm] (nonknowable) {Non-Knowable};
  \node[draw, ellipse, minimum width=3cm, minimum height=1cm, below=of knowable, xshift=-1.6cm] (concrete) {Concrete};
  \node[draw, ellipse, minimum width=3cm, minimum height=1cm, below=of knowable, xshift=1.6cm] (abstract) {Abstract};
  \node[draw, ellipse, minimum width=2.5cm, minimum height=1cm, below=of concrete, xshift=-1.8cm] (observable) {Observable};
  \node[draw, ellipse, minimum width=2.5cm, minimum height=1cm, below=of concrete, xshift=1.8cm] (nonobservable) {Non-Observable};

  % Arrows indicating subset relationships
  \draw[<-] (concrete) -- (knowable) node[midway, left] {};
  \draw[<-] (abstract) -- (knowable) node[midway, right] {};
  \draw[<-] (observable) -- (concrete) node[midway, left] {};
  \draw[<-] (nonobservable) -- (concrete) node[midway, right] {};

\end{tikzpicture}
\caption{Classification of Research Entities}
\end{figure}

% \begin{figure}[t]
% \centering
% \begin{tikzpicture}

%   % Define the ovals
%   \node[draw, ellipse, minimum width=4cm, minimum height=1.1cm, align=center] (knowable) {Knowable};
%   \node[draw, ellipse, minimum width=4cm, minimum height=1.1cm, right=of knowable, xshift=2+1cm] (nonknowable) {Non-Knowable};
%   \node[draw, ellipse, minimum width=3.5cm, minimum height=1.1cm, below=of knowable, xshift=-2.5cm] (concrete) {Concrete};
%   \node[draw, ellipse, minimum width=3.5cm, minimum height=1.1cm, below=of knowable, xshift=2.5cm] (abstract) {Abstract};
%   \node[draw, ellipse, minimum width=3cm, minimum height=1.1cm, below=of concrete, xshift=-2.5cm] (observable) {Observable};
%   \node[draw, ellipse, minimum width=3cm, minimum height=1.1cm, below=of concrete, xshift=2.5cm] (nonobservable) {Non-Observable};

%   % Arrows indicating subset relationships
%   \draw[<-] (concrete) -- (knowable) node[midway, left] {};
%   \draw[<-] (abstract) -- (knowable) node[midway, right] {};
%   \draw[<-] (observable) -- (concrete) node[midway, left] {};
%   \draw[<-] (nonobservable) -- (concrete) node[midway, right] {};

% \end{tikzpicture}
% \caption{Classification of Research Entities}
% \end{figure}

A central debate within the scope of science is the tension between \emph{reductionism}\index{Reductionism} and \emph{holism}\index{Holism}. Reductionism is the view that complex systems can be fully understood by breaking them down into their simplest, most fundamental parts. For example, a reductionist might argue that biological processes can be explained entirely by chemistry, and chemistry by physics. This approach assumes that understanding the smallest components of a system will provide a complete explanation of the whole. In contrast, holism argues that some phenomena cannot be fully understood by reducing them to their components. Instead, the whole system exhibits properties that cannot be predicted or explained by analyzing its parts in isolation. For example, in ecology, the interactions within an ecosystem can produce emergent properties that are not reducible to the behavior of individual species.

Finally, the scope of science is shaped by the debate between \emph{scientific realism}\index{Realism} and \emph{anti-realism}\index{Anti-realism}, which addresses the question of whether the entities posited by scientific theories are real or merely useful constructs. The contrast between realism and anti-realism is most marked for sciences which make claims about non-observable entities. Scientific realism holds that the entities described by scientific theories exist independently of our knowledge of them. According to this view, successful scientific theories reveal truths about the world. In contrast, anti-realism argues that scientific theories are useful tools for predicting and organizing observations, but we should not necessarily believe that non-observable entities like electrons or gravitational waves are real. For anti-realists, the purpose of science is not to describe an independent reality, but rather to provide models that help us navigate and predict phenomena.

Scientists often seek to classify the objects they study into general kinds or categories. A key goal of classification is to convey meaningful information, enabling us to better understand and navigate the complexities of the natural world. However, this process raises several intriguing philosophical questions. Do the categories used in science represent real, essential divisions in nature, or are they merely human-made constructs designed to impose order on a complex and often ambiguous reality (realism vs. anti-realism)? Since any set of objects can, in principle, be classified in various ways, how should we determine the most appropriate approach? Is there a 'correct' way to classify, or are all classification systems fundamentally arbitrary? Some philosophers argue that \emph{natural kinds}\index{Natural kinds}, groups that correspond to divisions genuinely existing in the world, do exist, as opposed to merely reflecting human interests. Understanding whether and how such natural kinds exist can provide valuable insights into the structure of reality and inform scientific inquiry.

%
% Observation
%
\section{Observation}

* Sientific knowledge has a special status in part because it is founded on a secure basis, solid facts firmly established by observation.

* Facts are claims about the world.

* Facts are directly given to careful, unprejudiced observers via the senses.
* Facts are prior to and independent of theory
* Facts constitute a firm and reliable foundation for scientific knowledge.

* There are reasons for doubting that facts acquired by observation and experiment are as straightforward and secure as has traditionally been assumed.

{\color{red} [...] what observers see, the subjective experience that they undergo, when viewing an object or scene is not determined solely by the images on their retinas, but depends also on the experience, knowledge and expectations of the observers [...] one has to learn to be a competent observer in science [...] The experienced and skilled observer does not have perceptual experiences identical to those of the untrained novice when the two confront the same situation. This clashes with a literal understanding of the claim that perception are given in a straightforward way via the senses. [...] observers viewing the same scene from the same place see the same thing but interpret wath they see differently. }

* Before an observer can formulate and assent to an observation statement, he must be in possesion of the approprate conceptual framework and a knowlege of how to appropriately apply it. Facts, formulated as statements, presuppose quite a lot of knowledge.

{\color{red} Our search for relevant facts needs to be guided by our current state of knowledge [...] the formulation of observation statements presupposes significatn knowledge, and that the search for relevant observable facts in science is guided by that knowledge. [...] the fact that knowledge is neccesary for the formulation of significant observationstatements still leaves open the question of which of the statements so formulated are borne out by observation and which are not. The idea that knowledge should be based on facts that are confirmed by observation is not undermined by the recognition that the formulation of the satements describing those facts are knowledge-dependent.}

{\color{red} The point is hat if the knowledge that provides the categories we use to describe out observations is defective, the observation statements that presopose those categories are similarly defective. [...] observation statemts depends on the knowledge that forms the backgroud against which the judment is made [...] scientific revolution involved not just a progressive transformation of scientific theore, but also a transformation in what were considered to be the observable facts. }

* Facts are fallible and subjet to correction.

* Perception are influenced by the background and expectations of the observer, so that what appears to be an observable fact for one need not be for another.

* Judgments about the truth of observation statements depend on what is alerady known or assumed, thus rendering the observable facts as fallible as the presuppositions underlying them.

* Everyday observation is far from passive. Thre is a range of things that  are done, many of them automatically and perhaps unconsciously, to establish the validity of a perception.

* Statements should be such that their validity can be tested in ways that involve routine, objective procedures that do not necessitate fine subjective judgement on the part of the observer.

* Observations suitable for constituting a basis for scientific knowledge are both objective and fallible. They are objective insofar as they can be publicly tested and straightforward procedures, and they are fallible insofar as they may be undermined by new kinds of test made possible by advances in science in technolgy.

* What is needed in science is not just facts but relevant facts. Which facts are relevant and which are not relevant to a science will be relative to the current state of development of that science. 

{\color{red} Many kind of processes are at work in the world around us, and they are all superimposed on, and interact with, each other in complicated ways. [...] It is not possible to arrive at un undesrtanding of these various processes by careful observation of events as they typically are naturally occur. [...] To acquire factors relevant for the identification and specification of the various processes at work in nature it is, in general, necessary to practically intervene to try to isolate the process under investigation and eliminate the effects of others. In short, it is ncessary to do experiments. [...] If these are facts that constitute the basis for science, then those facts come in the form of experimental results rather than any old observable facts. }

{\color{red} Experimental results are by no means straightforwardly given [...] the complexity of practical struggle involved in the production of an experimental result. [...] If experimental results constitute the facts on which sicence is based, then they are not straightforwardly given via the senses. They have to be worked for, and their establishment involves cosiderable know-how and practical trial and error as well as exploitation of the available technology. [...] Nor are judgments about the adequacy of experimental results straightforward. [...] Experimental results can be faulty if the knoledge informing them is deficient or faulty. [...] Experimental results are fallible, and can be updated or replaced for reasonably straightforward reasons. Experimental results can become outmoded because of advanced in technology, they can be rejected because of some advance in understanding (in the light of which an experimental set-up comes to be seen as inadequate) and they can be ignored as irrelevant in the light of some shift in theoretical understanding. }

* Experimental results are required not only to be adequate, but also to be appropriate or significant. What is an adequate and significant experiment depends heavily on how the practical and theoretical situation is understood.

* Experimental results are theory-dependent: All experiments will presume the truth of some theories to help judge that the set-up is adequate and the instruments are reading what they are meant to read.

* Experimental results are fallible and revisable.

{\color{red} Two schools of thought that involve attempts to formalise [...] that scientific knowledge is derived from the fact, are empiricists and the positivism. Empiricists [...] held that all the knowledge should be derived from ideas implanted in the mind by way of sense perception. The positivist had a broader view of what fact amount to. [...] The logical positivist [...] attempted to formalise it, paying close attention to the logical form of the relationship between scientific knowledge and the facts. }

%
% Scientific Representation
%

\section{Scientific Representation}
\label{sec:scientific_representation}

Science helps us understand the natural world by using different kinds of representations of research entities. These representations include measurements from scientific instruments, descriptions of observations, digital images like X-rays or MRI scans, and more. Scientific practice also often considers mathematical equations, models, and theoretical constructs as valid forms of representation. The challenge of \emph{scientific representation}\index{Scientific representation} is to identify the conditions that make a representation scientific and determine what makes an effective representation. The main issues discussed in this area of philosophy include:

\emph{Scientific Representation Problem}: The scientific representation problem is about figuring out the necessary and sufficient conditions that make a representation valid in science. It explores whether these conditions are the same across all scientific fields or if they vary depending on the discipline or research context. For example, what qualifies as a valid representation in physics, which often uses mathematical models, might be different from what is used in biology, where visual and descriptive representations are common. This problem also questions whether scientific representations need to be adapted to specific research goals to be considered valid.

\emph{Representational Demarcation Problem}\index{Representational demarcation}: The representational demarcation problem looks at whether scientific representations are fundamentally different from other kinds of representations, like those found in art or everyday life. It examines what makes scientific representations unique, focusing on their purpose, accuracy, and the methods used to create them. Unlike artistic representations, which may emphasize subjective interpretation or aesthetic value, scientific representations are generally held to standards of precision, reliability, and empirical adequacy. Understanding these differences helps clarify the specific role that scientific representations play in knowledge production.

\emph{Problem of Style}\index{Problem of style}: The problem of style addresses the fact that the same entity can be represented in different ways, depending on the goals and methods of the research. Different styles of representation—such as diagrams, mathematical equations, physical models, or computer simulations—each have unique characteristics, including the intended audience, level of abstraction, and type of information conveyed. This issue also asks whether these styles are fixed or if new styles can be invented to meet emerging scientific needs. The flexibility of representation styles is crucial because it allows for new insights and different ways of understanding scientific phenomena.

\emph{Standard of Accuracy}\index{Standard of accuracy}: The standard of accuracy problem is about determining what makes a scientific representation accurate. It involves figuring out how to distinguish between accurate and inaccurate representations by considering factors like how well the representation matches empirical data, captures important features of the phenomenon, and its ability to make predictions. This issue also explores whether accuracy should be seen as an objective standard or if it depends on the specific aims and context of the research. For example, a simplified model might still be considered accurate if it effectively serves its purpose, such as making predictions or providing explanations.

\emph{Problem of Ontology}\index{Problem of ontology}: The problem of ontology in scientific representation deals with the nature of the entities that can serve as representations. It asks whether representations need to be concrete, like physical models or graphs, or if they can also be abstract, like mathematical equations or theoretical constructs. This issue also questions whether representations must be realistic or if more abstract, idealized forms can still be effective in scientific inquiry. Understanding these ontological aspects helps define the types of entities that are allowed in scientific discourse and how they relate to the real-world phenomena they represent.

There are also five conditions of adequacy that a scientific representation should satisfy to be considered effective and reliable:

\emph{Requirement of Directionality}\index{Requirement of directionality}: The requirement of directionality examines the relationship between representations and the real world. Representations are meant to describe entities in the real world, but this condition raises the question of how, if at all, real-world entities might describe their representations. It challenges us to think about the direction of influence between the representation and the entity it aims to depict.

\emph{Surrogative Reasoning}\index{Surrogative reasoning}: Surrogative reasoning addresses how scientific representations allow researchers to generate hypotheses about the entities they represent. This condition explores how using a representation as a surrogate can lead to new insights or predictions about the target, effectively using the representation to stand in for the real-world entity during reasoning and analysis.

\emph{Applicability of Mathematics}\index{Applicability of mathematics}: The applicability of mathematics condition is concerned with how mathematical models can be used to represent the real world. It questions how abstract mathematical constructs can effectively describe complex physical systems and whether the success of mathematical representation depends on any special features of the target phenomena. This condition highlights the central role of mathematics in developing and understanding scientific theories.

\emph{Possibility of Misrepresentation}\index{Possibility of misrepresentation}: The possibility of misrepresentation addresses whether representations that are not fully accurate can still be considered valid scientific representations. It considers situations where simplifications or approximations are necessary and whether these less-than-perfect representations can still contribute valuable understanding of a phenomenon. This condition is important for understanding how idealizations and abstractions function in scientific practice.

\emph{Targetless Models}\index{Targetless models}: The targetless models condition explores whether we can allow representations that do not have a direct real-world counterpart. It questions if a model that does not represent any existing entity can still be useful in scientific inquiry, perhaps as a way to explore theoretical possibilities or to understand potential scenarios. This condition emphasizes the creative and exploratory aspects of scientific modeling.

There have been multiple proposals to formally define the concept of scientific representation. Unfortunately, none of these proposals can provide a convincing answer to the questions and conditions of adequacy described above. In the rest of this section, we describe some of these proposals, identifying their advantages and drawbacks. To compare these proposals, we will present them as: "A scientific model $M$ represents a target system $T$ if, and only if ...".

\emph{Stipulative Fiat}\index{Stipulative fiat}: The stipulative fiat proposal states that "a scientific model $M$ represents a target system $T$ if, and only if, a scientist stipulates that $M$ represents $T$." The main problem with this interpretation is that, since anything can be a representation if a scientist says so, it is difficult to guarantee the surrogative reasoning condition. If any model can be deemed a representation by simple stipulation, it becomes challenging to determine which representations are genuinely useful for making scientific inferences. Proponents of this theory acknowledge that while all representations may be stipulated, some are undeniably more useful than others.

\emph{Similarity Conception}\index{Similarity conception}: The similarity conception proposes that "a scientific model $M$ represents $T$ if, and only if, $M$ and $T$ are similar." This conception addresses the surrogative reasoning condition since similarity between the model and the target allows us to derive similar properties. However, it introduces new challenges, particularly regarding the problem of style. The concept of similarity is often vague: in what sense are $M$ and $T$ similar? This vagueness can lead to issues with directionality and accuracy, as different aspects of similarity may not always align with what is relevant for scientific representation.

\emph{Structuralist Conception}\index{Structuralist conception}: The structuralist conception is based on the idea of isomorphism. According to this view, a scientific model $M$ represents a target system $T$ if the structure of $M$ is isomorphic to the structure of $T$. In other words, there is a one-to-one correspondence between the elements and relationships in both $M$ and $T$. This approach justifies surrogative reasoning because having the same structure implies that properties and relations in the model correspond to those in the target. Furthermore, since mathematics is fundamentally concerned with the study of structures, this conception also supports the applicability of mathematics in representing natural systems.

\emph{Inferential Conception}\index{Inferential conception}: The inferential conception proposes that a model $M$ is an epistemic representation of a target $T$ if, and only if, the user adopts an interpretation of $M$ in terms of $T$. This view emphasizes the role of the user in giving meaning to the model, suggesting that representation is not an inherent property of the model itself but arises through its use in making inferences about the target system. This conception underscores the importance of context and interpretation in determining whether a model effectively represents its target.

\emph{Fiction View of Models}\index{Fiction view of models}: According to the fiction view of models, $M$ represents $T$ if and only if $M$ functions as a prop in a game of make-believe that prescribes imagining certain things about $T$. This view draws an analogy between scientific modeling and storytelling, where models are treated as fictional constructs that facilitate imaginative engagement with the target system. Although this approach highlights the creative aspects of modeling, it raises questions about how such fictional constructs can be rigorously linked to real-world entities.

\emph{Representation-As}\index{Representation-as}: The representation-as approach suggests that a scientific model represents a target system as something, emphasizing that representation involves highlighting certain features of the target while downplaying others. This conception focuses on the interpretive aspect of modeling, where the modeler selects specific attributes of the target to represent, depending on the research goals. This approach allows for a flexible understanding of representation that can accommodate different styles and purposes, but it also implies that the usefulness of a representation is contingent on how well the modeler captures the relevant aspects of the target.

Each proposal has its strengths and weaknesses, highlighting the complexity of what it means for a model to effectively represent a target in scientific inquiry. Understanding these various perspectives is crucial for advancing our comprehension of the role of representation in science.

%
% Scientific Discovery
%

\section{Scientific Discovery}

Scientific discovery refers to the process through which new knowledge, ideas, or principles are uncovered within science. Unlike the systematic procedures associated with justification, discovery often involves creativity, intuition, and inspiration. While some discoveries arise from planned experiments or systematic observation, others occur unexpectedly, challenging existing paradigms or opening new fields of inquiry. The general agreement among philosophers is that the creative process of conceiving a new idea is a non-rational process that cannot be formalized as a set of steps. Understanding discovery is crucial for appreciating how science evolves and adapts, as it reveals the dynamic and often unpredictable nature of scientific progress.

The following two proposals assume that a domain-neutral logic of discovery can be formalized, offering attempts to develop such a framework.

\begin{itemize}

\item \emph{Discovery as abduction}\index{Abductive reasoning}: Abductive reasoning is a mode of discovery that begins with surprising or anomalous phenomena and seeks to generate plausible hypotheses to explain them. This process is conceptualized as follows: (i) some unexpected data, such as $p_1, p_2, \ldots, p_n$, is encountered; (ii) these data would be less surprising if a hypothesis of type $H$ were true; and (iii) therefore, there is justification to develop a hypothesis of type $H$. Two types of abduction are distinguished: \emph{selective abduction}, which involves choosing from known hypotheses, and \emph{creative abduction}, which generates entirely new hypotheses. Abduction present some limitations. First, multiple hypotheses may explain the same phenomena, making additional criteria necessary to evaluate their merit. Second, the schema of abductive reasoning does not account for the act of conceiving a hypothesis itself.

\item \emph{Heuristic programming}\index{Heuristic programming} is a computational approach designed to simulate and assist the creative aspects of human problem-solving. These programs operate as searches within a defined problem space, which includes all possible configurations for a given domain. Each configuration represents a specific state within the problem space, with two key states being the initial state, the starting point of the search, and the goal state, which represents the desired outcome. Operators define the moves that transition between states, while path constraints limit permissible moves within the problem space. Problem-solving in this context involves finding a sequence of operations that connects the initial state to the goal state. The core aim of this approach is to develop heuristics (practical rules or strategies) to efficiently navigate and solve complex problems. Heuristic programming has its limitations, scientific problem spaces are often ill-defined, and computer programs rely on experimental data, meaning that simulations frequently cover only specific aspects of scientific discovery.

\end{itemize}

Many philosophers argue that discovery is an important topic within the philosophy of science, even as they move away from the idea of a formal logic of discovery. A highly influential perspective is Thomas Kuhn's examination of how new facts and theories emerge in the so-called \emph{paradigm shifts}\index{Paradigm shift}. According to Kuhn, discovery is not a single event but rather a complex and prolonged process that often results in paradigm shifts. Paradigms consist of shared generalizations, theoretical commitments, values, and exemplars that unify a scientific community and shape its research practices. During periods of normal science, research focuses on expanding and refining the existing paradigm rather than pursuing novelty. Discovery typically begins with the recognition of anomalies—phenomena that defy the expectations established by the current paradigm. This process includes observing and conceptualizing the anomaly, followed by revising the paradigm to accommodate it. During paradigm crises, theory-driven discoveries may occur as scientists propose speculative theories, develop new expectations, and conduct experiments or observations to test these ideas. Ultimately, a new paradigm emerges, transforming the once-anomalous phenomena into standard expectations.

Scientific discovery can be also viewed as inherently tied to creativity, with philosophers drawing from cognitive science, neuroscience, computational research, and environmental and social psychology to better understand how new ideas emerge. This perspective aims to demystify the mental processes behind creative thought, emphasizing that scientific creativity can be analyzed and understood philosophically. Central to this analysis are two pivotal cognitive mechanisms: analogies and mental models, which serve as fundamental tools in the generation of innovative ideas and the advancement of knowledge.

\begin{itemize}

\item \emph{Analogy}\index{Analogy}: Analogies play a crucial role in scientific discovery by enabling the transfer of ideas from one domain to another. Philosophers distinguish between three types of analogies: positive, negative, and neutral. Positive analogies involve properties that are shared by both the model (the well-understood domain) and the target domain (the new domain). Negative analogies include properties that belong solely to the model and do not apply to the target domain. Neutral analogies are the most intriguing because they consist of properties whose relevance to the target domain remains uncertain. These neutral analogies are significant as they often lead to new insights and hypotheses about the less familiar domain. Additionally, there is a distinction between horizontal and vertical analogies. Horizontal analogies connect two domains at the same level of abstraction, whereas vertical analogies involve relationships between different levels of abstraction within the same domain.

\item \emph{Model-based reasoning}\index{Model-based reasoning}: The concept of model-based reasoning suggests that much of human thought, including probabilistic and causal reasoning as well as problem-solving, relies on mental models rather than formal logic or strict methodological rules. In this approach, the mind constructs structural representations of real-world or imagined situations and manipulates these models to explore possibilities and generate insights. Conceptual structures are viewed as models, and conceptual innovation involves creating new models using various operations. Analogical reasoning, or analogical modeling, is one of the primary forms of model-based reasoning, alongside visual modeling and simulative modeling, such as through experiments.

\end{itemize}

%
% Scientific Explaination
%

\section{Scientific Explaination}

In philosophy of science it is often made the assumption that there exists a single, distinct type of explanation that qualifies as "scientific." The concept of "scientific explanation" suggests at least two key elements: first, a contrast between explanations characteristic of science and those that are not, and second, a contrast between "explanations" and other forms of discourse, such as mere "descriptions." It is important to note that a set of claims can be true, accurate, and supported by evidence while still failing to qualify as explanatory.

Good scientific explanations are typically evaluated based on several key characteristics. While different philosophical frameworks might emphasize different criteria, the following characteristics are broadly agreed upon:

\emph{Empirical Adequacy}\index{Empirical adequacy}: A good explanation must align with observed and experimental evidence. It should accurately describe the phenomena being explained, providing a detailed account of how the observed data supports the explanation. Additionally, it should integrate well with existing empirical findings, ensuring reliability and fostering broader scientific understanding.

\emph{Logical Coherence}\index{Logical coherence}: The explanation should be logically consistent and free of contradictions. Its components should interconnect in a structured and harmonious way, enabling clear and valid reasoning. This coherence ensures that the explanation aligns with established logical principles and provides a solid foundation for understanding the phenomena under investigation.

\emph{Causal Relevance}\index{Causal relevance}: Good explanations often identify the causal mechanisms responsible for the phenomenon. They should clarify how and why the phenomenon occurs, detailing the specific interactions and processes involved. By establishing a clear causal link, these explanations provide a framework for understanding not just what happens, but the underlying reasons and mechanisms driving the event. This depth of causality enables predictions, interventions, and broader scientific application.

\emph{Generality}: Explanations that apply to a broader range of phenomena are considered more valuable. They should transcend individual instances to reveal patterns or principles that connect seemingly disparate phenomena. By addressing a wider scope, such explanations enhance our ability to generalize knowledge, foster predictive accuracy, and provide a unifying perspective across different domains of inquiry.

\emph{Simplicity (Parsimony)}\index{Parsimony}: A good explanation should not be unnecessarily complex. Among competing explanations, the one that makes the fewest assumptions while still accounting for the phenomena is often preferred (Occam’s Razor). This principle emphasizes clarity and efficiency in reasoning, ensuring that explanations avoid superfluous details or unwarranted complexity. Simpler explanations are easier to test, communicate, and apply, fostering a more practical and streamlined understanding of the phenomena.

\emph{Explanatory Depth}\index{Explanatory depth}: Good explanations go beyond surface descriptions to provide a deeper understanding of the underlying mechanisms, principles, or causes. They delve into the fundamental elements that drive the phenomenon, offering insights into its origins and interconnections with related concepts. By unraveling these deeper layers, such explanations help uncover not just the "how," but the "why," enriching our comprehension and enabling a more profound application of knowledge.

\emph{Testability}: The explanation must allow for predictions that can be tested and potentially falsified. This criterion ensures that the explanation is scientifically meaningful and subject to empirical scrutiny. By being testable, the explanation invites rigorous examination and challenges, which help to confirm its validity or expose its weaknesses. Testability also connects scientific explanations to the broader experimental process, enabling continuous refinement and adaptation in light of new evidence, thereby fostering scientific progress and reliability.

\emph{Unification}: A good explanation often unifies disparate phenomena under a single framework or theory, showing how they are related. It highlights the connections and underlying principles that bring coherence to seemingly unrelated phenomena. By doing so, unification not only simplifies our understanding but also enhances the explanatory power of a theory, allowing for a more integrated and comprehensive perspective on the natural world.

\emph{Use of Laws}: Good explanations often incorporate established scientific laws or theories to provide a robust foundation for their claims. By grounding explanations in well-established principles, they ensure credibility and consistency with the broader scientific framework. This approach not only strengthens the explanatory power of the claims but also facilitates their integration into existing knowledge systems, thereby fostering coherence, predictability, and utility in advancing scientific understanding.

\emph{Practical Applicability}: In some cases, the usefulness of an explanation in solving problems, guiding further research, or applying knowledge in practical ways adds to its value. An explanation with practical applicability not only enhances theoretical understanding but also bridges the gap between abstract knowledge and real-world implementation. It can inform decision-making, inspire technological innovations, and address pressing societal challenges. By demonstrating utility in diverse contexts, such explanations underscore the relevance of scientific inquiry to everyday life and future advancements.

\emph{Asymmetry}: The requirement of asymmetry in scientific explanation is a widely discussed topic in the philosophy of science. According to most philosophical accounts, explanation is indeed considered to be an asymmetric relation, meaning that if X explains Y, it should not also be true that Y explains  X under the same laws and additional facts. However, there are debates and complications surrounding this idea. Let’s examine the arguments for and against asymmetry in scientific explanations.

\emph{Explanation as prediction}: When we provide a covering law explanation for a phenomenon, the laws and specific facts we reference could have allowed us to predict the phenomenon's occurrence. This highlights that a scientific explanation is inherently a potential prediction. Conversely, every reliable prediction is inherently a potential explanation, illustrating that explanation and prediction are structurally symmetric in their foundational principles.

The following paragraphs briefly introduce the most relevant proposals to characterize what is a scientific explanation.

The \emph{Deductive-Nomological model}\index{Deductive-Nomological model}, or DN model, emphasizes the importance of deductive reasoning and general laws. According to this model, a phenomenon is explained by demonstrating how it logically follows from a general law combined with specific initial conditions. This explanation comprises two main components: the \emph{explanans}\index{explanans}, which includes the general laws and initial conditions, and the \emph{explanandum}\index{explanandum}, which is the phenomenon to be explained. For the explanation to be valid, the explanans must be true and logically entail (see logical deduction at Section \ref{sec:scientific_justification}) the explanandum, meaning the phenomenon can be deduced from the laws and conditions provided. A DN model answers the question "Why did the explanandum occur?" by showing that the phenomenon resulted from specific circumstances $C_1, C_2, \ldots, C_i$, in conjunction with laws $L_1, L_2, \ldots, L_j$. For example, the motion of a particular pendulum can be explained by applying Newton's laws of motion (general laws) along with specific details such as the pendulum's length and initial displacement (specific initial conditions). Alternatively, the general behavior of pendulums can also be explained using the same laws and reasoning, since the DN model can be applied to both particular occurrences and general patterns.

The \emph{Statistical-Relevance model}\index{Statistical-Relevance model}, or SR model focuses on explaining phenomena through statistical relationships rather than strict deductive reasoning. Unlike the Deductive-Nomological model, which requires logical entailment from general laws, the SR model emphasizes the identification of statistically relevant factors that significantly influence the likelihood of a phenomenon. In this model, given some class or population \( A \), an attribute \( C \) is \emph{statistically relevant}\index{Statistical relevance} to another attribute \( B \) if and only if \( P(B | A, C) \neq P(B | A) \). This means that \( C \) affects the probability of \( B \) within the context of \( A \). An explanation involves identifying such statistically relevant factors and evaluating their impact within a reference class (a group of events or entities sharing common characteristics). For example, in explaining the likelihood of developing a particular disease, an SR explanation might highlight factors such as age, genetic predisposition, or lifestyle choices, showing how these variables alter the probability of the disease occurring. By uncovering these statistical relationships, the SR model provides a method for explaining probabilistic phenomena that cannot be addressed deterministically.

The \emph{Causal-Mechanical model}\index{Causal-Mechanical model}, or CM model, of scientific explanation emphasizes understanding phenomena by uncovering the underlying causal mechanisms that produce them (see causality at Section \ref{sec:scientific_justification}). This model asserts that explanations are not just about identifying laws or statistical relationships but about revealing the actual processes and interactions that link causes to effects. A causal-mechanical explanation requires tracing a continuous causal chain, often through detailed physical or biological processes, to show how an event is brought about. For example, explaining the boiling of water involves identifying the causal mechanism: heat energy transfers to the water molecules, increasing their kinetic energy until intermolecular bonds are overcome, leading to a phase change from liquid to gas. The CM model prioritizes clarity in how individual components interact and influence each other, providing a deeper understanding of the phenomenon by grounding it in observable and empirically testable mechanisms. This approach is particularly effective in fields like biology, physics, and engineering, where complex systems and their interactions play a central role in explanation.

The \emph{unificationist account}\index{Unificationist account} of scientific explanation, emphasizes the power of explanation through the unification of diverse phenomena under a single, coherent framework of principles and patterns. According to this model, the primary aim of scientific explanation is to reduce the number of independent assumptions and derive a wide range of phenomena from a minimal, consistent set of explanatory patterns. An explanation is considered successful if it contributes to this unifying framework by connecting seemingly disparate observations through common principles. For instance, Newtonian mechanics unifies the motions of celestial bodies and terrestrial objects under the same laws of motion and gravitation. The unificationist approach highlights the importance of simplicity, generality, and coherence in scientific theories, proposing that the value of an explanation lies in its ability to integrate knowledge into an organized, explanatory schema. By offering a comprehensive understanding of diverse phenomena, this account showcases the interconnectedness and systematic nature of scientific inquiry.

The \emph{pragmatic theories}\index{Pragmatic theories} of scientific explanation emphasize the context-dependent and audience-specific nature of explanations, focusing on their purpose and practical utility rather than strict formal structures. These theories argue that explanations are answers to "why" questions posed within a specific context, and their adequacy depends on how well they address the interests and background knowledge of the audience. A scientific explanation, therefore, is not inherently tied to a universal standard but varies depending on the explanatory goals, such as prediction, understanding, or control. For instance, explaining why a bridge collapsed might involve detailed structural analysis for engineers, whereas a simplified account focusing on the immediate cause, like high winds, might suffice for the general public. Pragmatic approaches recognize that explanatory demands can differ across disciplines, situations, and audiences, making the effectiveness of an explanation contingent on its relevance, clarity, and alignment with the inquirer's needs. This perspective underscores the interplay between scientific knowledge and its communication within varied practical contexts.

%
% Scientific Justification
%

\section{Scientific Justification}
\label{sec:scientific_justification}

{\color{red} scientific knowledge can neither be conclusively proved nor conclusively disproved}

{\color{red}

Logicians make an important distinction between deductive and inductive inference [...] The two statements above the line are called the premises of the inference, while the statements below the line is called the conclusion. This is a deductive inference because it has the following property: if the premises are true, then the conclusion must be true too [...] This is sometimes expressed by saying that the premises of the inference entail the conclusion [...] In a typical inductive inference, we move from premises about objects that we have examined to conclusions about objects of the same sort that we haven't examined.

When we reason deductively, we can be certain that if we start with true premises we will end up with a true conclusion. By contrast, inductive reasoning is quite capable of taking us from true premises to a false conclusion [...] Scientists reason inductively whenever they move from limited data to a more general conclusion, which they do all the time.

Popper claimed that scientist only need to use deductive inferences.

Although a scientific theory (or hypothesis) can never be proved true by a finite amount of data, it can be proved false, or refuted.

Hume argued [Hume's problem of induction] that the use of induction cannot be rationally justified at all [...] whenever we make inductive inferences, we presuppose the 'uniformity of nature' [...] our reasoning depend on the assumption that objects fwe haven't examined will be similar, in relevant aspects, to object of the same sort we have examined [...] we cannot prove the uniformity assumption.

Inductive inferences have all the same structure, the premise has had the form 'all examined Fs have been G' and the conclusion the from 'other Fs are also G' [...] Reasoning of this sort is known as 'inference to the best explanation' (IBE) [...] The basic idea behind IBE -- reasoning from one's data to a theory or hypothesis that explains the data -- good explanation should be simple [...] Preferring a theory which explains the data in terms of the fewest number of causes seems sensible. But are there any objective grounds for thinking that such a theory is more likely to be true than a less simple rival?

}

Thomas Kuhn introduced the concept of scientific paradigms, which revolutionized the understanding of scientific progress. A paradigm encompasses the set of practices, theoretical frameworks, methodologies, and standards that define a scientific discipline during a specific period. According to Kuhn, normal science operates within the confines of a prevailing paradigm, solving puzzles and extending the framework. However, scientific revolutions occur when anomalies accumulate—phenomena that the existing paradigm cannot adequately explain—leading to a paradigm shift. This shift replaces the old framework with a new one that better accommodates the observed data, fundamentally altering the trajectory of scientific inquiry. Kuhn's insights emphasize the sociocultural and historical dimensions of science, challenging the notion of continuous, cumulative progress.

{\color{red}

[...] scientific revolutions, periods of great upheaval when existing scientific ideas are replaced with radically new ones [...] these revolutions led to a fundamental change in the scientific worldview, the overthrow of an existing act of ideas by a completely different set [...] revolutions happen relatively infrequently [...] 'normal science' [...] the ordinary day-to-day activities that scientists engage in when their disciplines is not undergoing revolutionary change [...] A paradigm consists or two main components: first, a set of fundamental theoretical assumptions which all members of a scientific community accept; secondly, a set of 'examplars' or particular scientific problems which have been solved by means of those theoretical assumptions [...] When scientists share a paradigm [...] they agree on how future research in the field should proceed, on which problems are the pertinetn ones to tackle, on what the appropriate methods for solving those problems are, and on what an acceptable solution of the problems would look like [...] a paradigm is an entire scientific outlook, a constellation of shared assumptions, beliefs, and values which unite a scientific community and allow normal science to take place. [...] The job of the normal scientist is to try to eliminate these minor puzles while making a few changes as possible to the paradigms [...] normal scientists are not trying to test the paradigm. On the contrary, they accept the paradigm unquestioningly, and conduct their research within the limits it sets [...] as anomalies accumulate, a burgeoning sense of crisis envelops the scientific community. [...] A variety of alternatives to the old paradigm are proposed, and eventually a new paradigm becomes established [...] The essense of a scientific revolution is thus the shoft from an old paradigm to a new one. [...] Kuhn argued that adopting a new paradigm involves a certain act of faith on the part of the scientists. [...] if paradigm shifts work the way Kuhn says, it is hard to see how science can be regarded as a rational activity at all. [...] the facts about the world are paradigm-relative, and thus change when paradigms change [...] Kuhn espose a radical form of anti-realism about science.

[...] competing paradigms are typicallly 'incommensurable' with one another [...] Incommensurability is the idea that two paradigms may be so different as to render impossible any straightforward comparison of them with each other, there is no common language into which both can be translated [...] concepts cannot be explained independently of the theories in which they cannot be explained independently of the theories in which they are embedded. This idea, which is sometimes called 'holism' [...] replacement of 'wrong' iddeas by 'right' ones [...] later paradigms are not better than earlier, just different [...] old and new paradigms to be incompatible [...] lack of a common language [...] incommensurability of standars.

[...] theory-ladenness of data [...] the ideal of theory-neutrality is an ilusion, data are invariable contaminated by theoretical assumptions [...] a dispute between competing paradigms could not be resolved by simply appealing to 'the data' or 'the facts', for what a scientist counts as data, or facts, will depend on which paradigms they accept [...] To be objectively true, a theory must corespond to the facts, but the idea of such a correspondence makes little sense if the fact themselves are infected by our theories [...] perception is heavly conditioned by background beliefs [...] scientists' experimental and observational reports are often couched in highly theoretical language.

[...] there is 'no algorithm' for theory choice in science. [...] no one has ever succeeded in producing such an algorithm. [...] For one thing, there may be trade-offs: theory A maybe simpler than theory B, but B may fit the data more closely. So an element of subjective judment, or scientific common sense, will often be needed to decide between competing theories. [...] is not that paradigm shifts are irrational, but rather that a more relaxed, pragmatic concept of rationality is required to make sense of them.

[...] as did the idea of a sharp dicotomy between the context of discovery and justification. [...] His doctrines of paradigm shifts, normal and revolutionary science, incommesurability, and theory landenness.

}

Paul Feyerabend, in his provocative work "Against Method," argued that there is no universal scientific method that guarantees the success of science. He criticized the rigid methodological rules proposed by philosophers like Popper and Kuhn, suggesting that science has advanced precisely because of its methodological anarchy. Feyerabend contended that "anything goes" in science, meaning that historical scientific breakthroughs often occurred by defying established rules and norms. For example, Galileo's use of persuasive rhetoric and creative reasoning, rather than strict adherence to empirical observation, was crucial in advancing heliocentrism. Feyerabend's ideas challenge the assumption that scientific progress is orderly and rational, emphasizing instead the role of historical, cultural, and personal factors in shaping scientific practice. While his views remain controversial, they highlight the complexity and diversity of scientific inquiry and question the feasibility of prescribing universal methodological principles.

The hypothetico-deductive method is a widely recognized approach in the philosophy of science, describing how scientific theories and knowledge are developed and tested. It begins with the formulation of a hypothesis, which serves as a tentative explanation for a phenomenon or a set of observations. From this hypothesis, scientists deduce specific, testable predictions or consequences, often in the form of "if-then" statements. These predictions are then subjected to empirical testing through experiments or observations. If the results align with the predictions, the hypothesis is supported but not conclusively proven; if the results contradict the predictions, the hypothesis may need to be revised or rejected. This iterative process underscores the provisional nature of scientific knowledge.

Falsificationism emphasizes that scientific theories can never be conclusively proven but can be rigorously tested through attempts to falsify them. An example of this is Einstein's theory of general relativity, which predicted that light would bend near massive objects like the sun. This prediction was empirically tested during the solar eclipse of 1919, when astronomers observed starlight bending as it passed near the sun, providing a crucial opportunity to potentially falsify the theory—but instead offering strong support for it. According to this perspective, a theory is scientific only if it is falsifiable—that is, if it makes predictions that could, in principle, be shown to be false by empirical evidence. In this view, the strength of a scientific theory lies in its ability to withstand attempts at falsification, and progress in science occurs when falsified theories are replaced by better, more robust ones. This perspective shifts the focus from verification to critical testing, highlighting the dynamic and self-correcting nature of scientific inquiry.

One challenge within the hypothetico-deductive method is addressing the origin of hypotheses themselves. While the method provides a systematic way to test and refine hypotheses, it does not dictate where these initial ideas come from. In the past, the generation of hypotheses was often the direct result of careful observations of natural phenomena. However, as science has progressed, hypotheses have increasingly become products of creativity, intuition, or inspiration drawn from prior knowledge, analogies, or even serendipitous observations. This aspect highlights the interplay between the logical structure of scientific testing and the imaginative processes that fuel scientific discovery. Philosophers of science have long debated whether hypothesis generation is a purely rational process or one influenced by subjective and contextual factors, underscoring the complexity of scientific creativity.

\emph{Statistical inference}\index{Statistical inference} has become a significant approach within the scientific method, providing a framework for deriving conclusions from data in the face of uncertainty. By employing probabilistic models and statistical techniques, scientists can estimate the likelihood that observed phenomena are consistent with a given hypothesis. Techniques such as hypothesis testing, point estimation, and confidence intervals allow researchers to quantify uncertainty and make data-driven decisions. This approach is particularly powerful in fields where direct experimentation is difficult or impossible, such as cosmology or epidemiology. However, reliance on statistical methods also raises important questions about the interpretation of probabilities (see Section \ref{sec:probability_foundations}) and the potential for misuse, such as overfitting models or neglecting prior assumptions. Despite these challenges, statistical inference remains an indispensable tool for connecting empirical data to theoretical models in modern science.

\emph{The Bayesian approach}\index{Bayesian approach} is an application of the statistical reasoning to the scientific method. Based on Bayes' theorem (see Theorem \ref{th:Bayes_theorem}), the Bayesian approach provides a formal framework for updating the probability of a hypothesis as new evidence emerges. By iteratively adjusting probabilities, the Bayesian approach dynamically reflects how beliefs evolve as evidence accumulates. Each time an experiment is succesfully performed the likelihood of the hypothesis to be true increases. This iterative process allows for a dynamic adjustment of beliefs, reflecting how evidence accumulates over time. Bayesian methods are particularly useful in contexts of uncertainty or incomplete data, such as medical diagnosis, or climate modeling.

{\color{red}

Let $P(h \mid e)$ denote the probability of a hypotheis $h$ in the light of evidence $e$. $P(e \mid h)$ denote the probability to be ascribed to the evidence $e$ on the assumption that the hypothesis $h$ is correct, $P(h)$ the probability ascribed to $h$ in the absence of knowledge of $e$, and $P(e)$ the probability ascribed to $e$ in the absence of any assumption about the truth of $h$. The Bayes' theorem (see Theorem \ref{th:Bayes_theorem}) can be written:
\[
P(h \mid e) = P(h) \frac{P(e \mid h}{P(e)}
\]
$P(h)$ is referred to as the prior probability since it is the probability ascribed to the hypothesis prior to consideration of the evidence $e$, and $P(h \mid e)$ is referred to as the posterior probability, the probability after the evidence e is taken into account. So the formula tell us how to change the probability of a hypothesis to some new, revised probability in the light of some specified evidence.

The factor $P(e/h)$ is a measure of how likely $e$ is given $h$. It will take a maximum value of 1 if $e$ follows from $h$ and a minimum value of zero if the negation of $e$ follows from $h$.
}

With suffiencient amount of evidence, bayes converges? (weigth of isotopes), making less relevant the problem of subjective priors (conjugate priors?)

\begin{example}
{\color{red} Something established barely changes with new experiments, bold confirmed congetures do}
\end{example}

When an experiment fails to confirm a theory, Bayesian inference allows for a probabilistic adjustment of the theory's credibility by updating its posterior probability in light of the evidence, unlike falsificationism, which considers a theory definitively refuted when evidence contradicts its predictions.

Bayesian inference, while powerful, has notable limitations:

Objective prior probabilities of hypothesis are difficult to obtain (how do we list all possible hypothesis?). Subjective priors represent degrees of bileif. its reliance on subjective priors can introduce bias, requiring careful justification;

 it is sometimes applied in contexts lacking a well-defined probability space, undermining its validity; and it cannot accommodate scientific inferences that leap to entirely new theories, as conditionalization is incapable of handling hypotheses or concepts absent from the prior probability space. Despite these limitations, Bayesian inference continues to shape modern scientific practices, highlighting the interplay between evidence, prior knowledge, and probabilistic reasoning.

\emph{Causality}\index{Causality} refers to the relationship between events where one event (the cause) brings about or influences another event (the effect), and it asserts that explaining a natural phenomenon involves identifying its causes. In the philosophy of science, there is ongoing debate about whether causal explanations differ fundamentally from those based on general laws, as deducing an event from a general law often implicitly reveals its cause. A key feature of causality is its inherent asymmetry, if $x$ is the cause of $y$, then $y$ cannot be the cause of $x$; this asymmetry is a crucial distinction that sets causal explanations apart from mere statistical correlations. Many challenges arise when relying on empirical observations to justify causal relationships. One perspective emphasizes the development of rigorous methodologies, generally by statisticians and computer scientists, to infer causality from observational data, addressing issues such as \emph{confounding factors}\index{Confounding factors} (variables that obscure the true causal relationship) and the principle that correlation does not imply causation. \emph{Randomized controlled trials}\index{Randomized controlled trials} stand as a gold standard in causal inference, where confounding variables are systematically controlled by design to isolate the effect of the factor under investigation. In contrast, empiricists argue that causal relations cannot be directly observed and suggest that causality is merely a conceptual framework humans impose on the world to make sense of observed regularities.

%
% The limits of science
% 

\section{The Limits of Science}

{\color{red} [...] philosophical enquiry has its own propietary methods, which can reveal truths of a sort that science cannot. [...] They include logical reasoning, the use of thought experiments, and what it is called 'conceptual analysis', which tries to delimit a particular concept by relying on our intuitions about whether a particular case fall under it. [...] It is often felt that natural sciences such as physics, chemistry, and biology are in a more advanced state than social sciences such as economics, sociology, and anthropology; the former can formulate precise laws with great predictive power, while the latter usually cannot. [...] It is never possible to prove that a scientific theory is true, in the strict sense of proof, for the inference from data to theory is invariably non-deductive.}

{\color{red} Non-detectable entities}

{\color{red} [...] sicence can in principle explain everything? Or are there some phenomena that must forever elude scientific explaination? [...] However much the science of the future can explain, the explanations it gives will have to make use of certain fundamental laws and principles. Since nothing can explain itself, it follows tat at least some of these laws and principles will themselves remain unexplained [...] some things will never be explained, but does not tell use what they are.}

Science has long been a powerful tool for understanding and shaping the world. However, its scope is not unlimited. There are domains where science struggles to provide answers, such as consciousness or moral values. Metaphysical questions, such as the nature of existence or why there is something rather than nothing, often fall outside the realm of empirical investigation. Similarly, science can describe the consequences of actions but cannot determine moral values or prescribe what ought to be done. This section contains a brief description of the main topics related to the limits of science.

\subsubsection*{Reductionism vs. Holism}

One key debate in understanding the limits of science is the tension between \emph{reductionism}\index{Reductionism} and \emph{holism}\index{Holism}. Reductionism asserts that complex phenomena can be fully understood by breaking them down into their most basic components and laws. For example, biology might be reduced to chemistry, and chemistry to physics. However, holism argues that some phenomena, especially in systems like ecosystems, societies, or even consciousness, cannot be fully understood without considering the interactions and emergent properties of the whole system. This debate underscores the challenge of addressing complexity within scientific frameworks.

{\color{red} The different scientific disciplines are designed for explaining different types of phenomena [...] there is a distinction of labour betwen the different sciences: each specializes in explaining its own particular set of phenomenon [...] it is widely held than the different branches of science are not all on a par: some are more fundamental than others [...] physics can subsume all the higher-level sciences? [...] The objects studied by the higher-level sicences are multiply realized at the phisical level.}

Scientific inquiry excels in answering questions about the natural world, but it encounters boundaries when addressing issues that are metaphysical, moral, or inherently subjective. For example, while science can study the mechanics of evolution, it does not address whether life has an intrinsic purpose. Similarly, while it can analyze the factors influencing human behavior, it cannot resolve normative questions about justice or fairness. These limitations highlight the need for interdisciplinary approaches and alternative methods of inquiry.

\emph{Realism vs. Anti-realism}: As it was already mentioned in Section \ref{sec:what-is-an-entity}, another critical debate in philosophy of science concerns the nature of scientific knowledge: does science uncover true aspects of reality (\emph{scientific realism}\index{Scientific realism}), or does it merely provide useful models and predictions without necessarily representing reality (\emph{scientific anti-realism}\index{Scientific anti-realism})? Anti-realism suggests that {\color{red}scientific theories as instruments for helping us predict observable phenomena, rather than as attempts to describe the underlying nature of reality}. The scientific realism vs scientific anti-realism debate underscores {\color{red} a debate in philosophy between two opposing schools of though called \emph{realism}\index{realism} and \emph{idealism}. Realism holds that the physical world exists independently of human though and perception. Idealism claims that the physical world is in some way dependent on the concious activity of humans.}

{\color{red}

The underdetermination argument: Anti-realist emphasize that the empirical data to which scientific theores are responsible consist of fact about observable entities and processes. [...] fact about observable phenomena provide the ultimate data fro theories that posit unobservable entities and processes. [...] Anti-realists that aregue that the emprirical data 'underdetermine' the theories scientist put forward on their basis [...] the data can in principle be explained by many different, mutually incompatible, theories. [...] Undetermination lead naturally to the anti-realist conclusion that agnosticism is the rational attitude to take towards theories about the unobservable region of reality. [...] But, say the realists, it does not follow that all of these possible explanations are equally good. [...] why simple theories should be though more likely to be true.

}

\subsubsection*{Objetivity}

Science is often regarded as an objective endeavor, but this view is contested. Scientific practices are influenced by the cultural, social, and personal contexts of researchers. For example, funding priorities, societal values, and individual biases can shape research questions, methodologies, and interpretations. The ideal of objectivity remains central to scientific inquiry, but recognizing these influences is crucial for understanding the limitations and potential biases inherent in scientific work.

{\color{red} Address the self-correcting nature of science}

\subsubsection{The Demarcation Problem}

The \emph{demarcation problem}\index{Demarcation problem} addresses the challenge of distinguishing science from non-science or pseudoscience. This philosophical issue has significant implications for the credibility and authority of scientific knowledge. Karl Popper's criterion of falsifiability, a theory is scientific if it can be tested and potentially falsified, has been influential but not universally accepted. Some disciplines, like evolutionary psychology or string theory, straddle the line, sparking debate about their scientific status. The demarcation problem highlights the complexity of defining the scope and boundaries of science.

Science thrives on uncertainty, yet there are questions that may remain permanently beyond its reach. For example, the origins of the universe, the nature of dark matter, or the ultimate fate of existence may elude definitive answers. Furthermore, the tools and methodologies of science may be inherently limited in addressing phenomena that require new paradigms or approaches. This recognition does not diminish science but rather emphasizes its role as one part of a broader human quest for knowledge.

While science provides the means to achieve certain ends, it does not dictate the ethical use of its discoveries. Ethical questions, such as the use of genetic engineering or artificial intelligence, require value-based judgments that go beyond empirical evidence. Integrating ethical considerations with scientific progress is essential to navigate the societal impact of science responsibly.


%
% Section: References
%

\section*{References}

{\color{red} Add references to the following entries from the Stanford Encyclopedia of Philosophy:

\begin{itemize}
\item Scientific Representation
\item Scientific Explanation
\item Scientific Method
\item Scientific Discovery
\end{itemize}

}


\ref{pirsig1999zen} contains an interesting review of the concept of science, the scientific method, and the role that technology plays in our society. The author proposes that the goal of science should be quality, although the concept of quality is left undefined, and how to reconcile the rational and romantic points of view in science. The book also contains some advice about which is the right state of mind to pursue a scientific problem, and how to deal with the inevitable failures.


