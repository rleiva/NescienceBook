%
% CHAPTER: Preliminaries
%

\chapterimage{Koenigsberg_Map_by_Bering_1613.pdf} % Chapter heading image

\chapter{Discrete Mathematics}
\label{chap:Discrete_Mathematics}

\begin{quote}
\begin{flushright}
\emph{Mathematics may be defined as the subject in which\\
we never know what we are talking about,\\
nor whether what we are saying is true.}\\
Bertrand Russell
\end{flushright}
\end{quote}
\bigskip

The majority of mathematical concepts employed throughout this book fall within the realm of \emph{discrete mathematics}. This field of study focuses on mathematical objects that possess distinct or individual values, as opposed to continuous ones. This book utilizes a variety of discrete objects, including integers, strings, graphs, and computer programs. A defining characteristic of discrete sets is their countability, meaning they can be enumerated with natural numbers. In contrast, we will scarcely apply continuous mathematics, such as calculus, to the theoretical formulations within the theory of nescience.

Our primary interest in discrete mathematics stems from its relevance to computers. The theory of nescience draws upon various facets of computer science, such as algorithms, coding, and string complexity. Computers function in discrete stages and process data stored in discrete memory units. We are captivated by computers due to our ambition to apply our theoretical explorations to a wide range of real-world objects. We believe computers provide the most appropriate means of modeling our world. While pure mathematics often delves into abstract objects without concern for their representations, the theory of nescience places great importance on the representation (or encoding) of objects.

This chapter serves as a brief overview of the fundamental concepts of discrete mathematics, and as such, does not provide formal definitions or prove theorems. Discrete mathematics is a highly diverse and vast field of study. We will only focus on those components essential for understanding the theory of nescience. Certain involved theories (such as computability, information, complexity, and so forth) demand a more extensive coverage and are therefore explored in individual chapters. The References section includes a list of recommended books that delve into the topics addressed in this chapter in greater detail.

This chapter serves as a brief overview of the fundamental concepts of discrete mathematics, introducing topics such as sets, strings and languages, counting methods, matrices, and graphs. Though we do not provide formal definitions or prove theorems in this overview, these subjects offer a foundation for the theories and concepts discussed in subsequent sections. Discrete mathematics is a highly diverse and vast field of study. Our focus will be on those components essential for understanding the theory of nescience. Certain involved theories (such as computability, information, complexity, and so forth) demand a more extensive coverage and are therefore explored in individual chapters.

The References section includes a list of recommended books that delve into the topics addressed in this chapter in greater detail. By using this list, readers interested in deepening their understanding of these topics can explore each in more detail, complementing the fundamental overview presented in this chapter.


%
% Section: Sets
%

\section{Sets, Relations and Functions}
\label{sec:sets}

The sets of \emph{natural}\index{Set of natural numbers}, \emph{integers}\index{Set of integers}, \emph{rational}\index{Set of rationals}, and \emph{real}\index{Set of real numbers} numbers are represented by $\mathbb{N}$, $\mathbb{Z}$, $\mathbb{Q}$, and $\mathbb{R}$ respectively, which includes the number $0$. The \emph{positive integers}\index{Set of positive integers} are denoted by $\mathbb{Z}^+$, and the \emph{positive reals}\index{Set of positive reals} by $\mathbb{R}^+$, where both of these sets incorporate the number $0$. Let $A$ be a \emph{set}\index{Set}. We signify that $x$ is an \emph{element}\index{Element of a set} of $A$ by the notation $x\in A$, and that $x$ is not an element of $A$ by $x \notin A$. Elements of a set can be enumerated using braces, such as $A = \{0, 1, 2, 3\}$, or they can be defined by conditions via the \emph{set-builder}\index{Set formation notation} notation, for instance $A = \{x \in \mathbb{N} : x < 4\}$, with the stipulation that the \emph{universe}\index{Universe of a set} of the set be clearly established.

Suppose $A$ and $B$ are two sets. We use the notation $A = B$ to denote that the sets are \emph{equal}\index{Equal sets}. The expression $A \subseteq B$ signifies that $A$ is a \emph{subset or equal}\index{Subset} to $B$, and $A \subset B$ is used to indicate that $A$ is a \emph{proper subset}\index{Proper subset} of $B$ (implying $A$ is not equivalent to $B$). The condition $A = B$ holds true if, and only if, both $A \subseteq B$ and $B \subseteq A$ are satisfied concurrently. The symbol $\varnothing$ represents the \emph{empty set}\index{Empty set}, a set that contains no elements.

\begin{example}
For every set $A$ we have that $\varnothing \subseteq A$ and $ A \subseteq A$.
\end{example}

The term \emph{cardinality}\index{Cardinality of a set} refers to the number of elements within a finite set $A$, denoted as $d(A)$. Accordingly, the cardinality of the empty set $\varnothing$ is 0, as it contains no elements. For any two sets $A$ and $B$, the notation $A \cup B$ signifies the \emph{union}\index{Union of sets} of $A$ and $B$, whereas $A \cap B$ designates the \emph{intersection}\index{Intersection of sets} of $A$ and $B$. When dealing with $n$ sets, say $A_1, A_2, \ldots, A_n$, their union and intersection are denoted as $\cup_{i=1}^n A_i$ and $\cap_{i=1}^n A_i$ respectively. For an arbitrary collection of sets indexed by $I$, we employ $\cup_{i \in I} A_i$ and $\cap_{i \in I} A_i$. In the context of an infinite collection of sets, the notations $\cup_{i}^{\infty} A_i$ and $\cap_{i}^{\infty} A_i$ are adopted.

On occasion, we will resort to the use of \emph{Venn diagrams}\index{Venn diagram} as a visual means to represent sets, as exemplified in Figure \ref{fig:Venn-diagram}.

\begin{figure}[t]
\centering
\begin{tikzpicture}

    % Rectangle with label
    \draw (0,0) rectangle (5,3.5) node[below left] {$\mathbb{N}$};
    
    \fill[gray!30] (1.75,1.75) circle (1);
    \fill[gray!30] (3.25,1.75) circle (1);

    \node[draw, circle, minimum width=2cm, label=center:{$A$}] at (1.75, 1.75) {};
    \node[draw, circle, minimum width=2cm, label=center:{$B$}] at (3.25, 1.75) {};

\end{tikzpicture}
\caption{\label{fig:Venn-diagram}Representation of $A \cup B$ as a Venn Diagram}
\end{figure}


Given the sets $A$ and $B$, $A \backslash B$ is the \emph{set difference}\index{Set difference}, and ${A}^c$ is the \emph{complement}\index{Complement of a set} set of $A$. The \emph{De Morgan's laws}\index{De Morgan's laws} state that for every two sets $A$ and $B$ we have that $\left( A \cup B \right)^c = A^c \cap B^c$ and $\left( A \cap B \right)^c = A^c \cup B^c$.

Two sets $A$ and $B$ are \emph{disjoint}\index{Disjoint sets} if $A \cap B = \varnothing$. The sets $A_1, A_2, \ldots, A_n$ are disjoint if for every $i$ and $j$ such that $i \neq j$ we have that $A_i \cap A_j = \varnothing$. A \emph{partition}\index{Partition of a set} of a set $A$ is a collection of nonempty disjoint subsets of $A_1, A_2, \dots, A_n$ of $A$ such that  $A = \cup_{i=1}^n A_i$. The \emph{power set}\index{Power set} $\mathcal{P}(A)$ is the set whose members are all possible subsets of A. If $d(A)=n$ then $d\left( \mathcal{P}(A) \right) = 2^n$.

Given any two sets $A$ and $B$, we denote the \emph{set difference}\index{Set difference} as $A \backslash B$, and the \emph{complement}\index{Complement of a set} of the set $A$ as ${A}^c$. \emph{De Morgan's laws}\index{De Morgan's laws} articulate that for any pair of sets $A$ and $B$, we have $\left( A \cup B \right)^c = A^c \cap B^c$ and $\left( A \cap B \right)^c = A^c \cup B^c$.

The term \emph{disjoint}\index{Disjoint sets} is applied to two sets $A$ and $B$ when their intersection $A \cap B = \varnothing$. We say that the sets $A_1, A_2, \ldots, A_n$ are disjoint if for every distinct pair $i$ and $j$ ($i \neq j$), we find $A_i \cap A_j = \varnothing$. A \emph{partition}\index{Partition of a set} of a set $A$ is an assembly of nonempty disjoint subsets $A_1, A_2, \dots, A_n$ of $A$ satisfying  $A = \cup_{i=1}^n A_i$. The \emph{power set}\index{Power set} of $A$, denoted as $\mathcal{P}(A)$, is the collection of all conceivable subsets of $A$. If the cardinality of $A$ is $n$, i.e., $d(A)=n$, then the cardinality of the power set of $A$ is $2^n$, thus expressed as $d\left( \mathcal{P}(A) \right) = 2^n$.

\begin{example}
Given the set $A = \{1, 2, 3\}$, its power set is:
\[
\mathcal{P}(A) = \{\varnothing, \{1\}, \{2\}, \{3\}, \{1,2\}, \{1,3\}, \{2,3\}, A\}
\]
\end{example}

Consider a non-empty set $A$ and a collection $\mathcal{F}$ of subsets of $A$. The pair $\left( A, \mathcal{F} \right)$ is designated as an \emph{field}\index{Field of sets} over $A$ if it fulfills the following conditions: it includes the empty set, denoted as $\varnothing \in \mathcal{F}$, it is closed under the operation of complementation, meaning for each $F \in \mathcal{F}$, the complement $F^c  \in \mathcal{F}$, and it is closed under finite unions, which indicates $F_1 \cup \ldots \cup F_n  \in \mathcal{F}$ for all subsets $F_1, \ldots, F_n \in \mathcal{F}$. Additionally, it can be demonstrated that a field also fulfills two further criteria: $A \in \mathcal{F}$, and it is closed under finite intersections, expressed as $F_1 \cap \ldots \cap F_n  \in \mathcal{F}$ for all subsets $F_1, \ldots, F_n \in \mathcal{F}$.

% Relations

Consider two elements, $x$ and $y$. An \emph{ordered pair}\index{Ordered pair}, symbolized as $(x, y)$, is a pairing of $x$ and $y$ in that order. By expanding this concept, an \emph{n-tuple}\index{n-tuple} — which can be visualized as an $n$-element ordered pair — is written as $(x_1, \ldots, x_n)$. We define the \emph{Cartesian product}\index{Cartesian product} of two sets $A$ and $B$, which is symbolized as $A \times B$. This product is a set consisting of all possible ordered pairs $(x, y)$, where $x$ belongs to set $A$ and $y$ belongs to set $B$. The Cartesian product can be extended to $n$ sets, $A_1, A_2, \dots, A_n$, and is expressed as $A_1 \times A_2 \times \dots \times A_n$. Moreover, the \emph{n-fold Cartesian product} of a set $A$ with itself is represented as $A^n$.

Let $R$ be a subset of the Cartesian product of set $A$ with itself, i.e., $R \subseteq A \times A$. Such a subset is referred to as a \emph{binary relation}\index{Binary relation}, which can be represented as $aRb$, meaning that the ordered pair $(a, b)$ is a member of $R$. A binary relation is deemed \emph{reflexive}\index{Reflexive relation} if for any element $a$ in $A$, it holds that $aRa$. It is termed \emph{symmetric}\index{Symmetric relation} if for all $a, b$ in $A$, the presence of $aRb$ automatically implies $bRa$. The property of \emph{antisymmetric}\index{Antisymmetric relation} is attributed to a binary relation when the coexistence of $aRb$ and $bRa$ leads to the conclusion that $a = b$. It is considered \emph{transitive}\index{Transitive relation} if for any $a, b, c$ in $A$, the occurrence of $aRb$ and $bRc$ infers $aRc$. A binary relation is identified as \emph{total}\index{Total relation} if for all $a, b$ in $A$, either $aRb$ or $bRa$ holds. Binary relations can be extended to include two different sets $A$ and $B$ as a subset $R \subseteq A \times B$, and can also be adapted to \emph{n-ary} relations represented as $R \subseteq A_1 \times A_2 \times \dots \times A_n$.

Let $R$ be a binary relation that is a subset of the Cartesian product $A \times A$, i.e., $R \subseteq A \times A$. If this relation is reflexive, symmetric, and transitive, it is designated as an \emph{equivalence relation}\index{Equivalence relation}, typically symbolized by $\sim$. Within the context of an equivalence relation, two elements $a, b$ from set $A$ are deemed \emph{equivalent}\index{Equivalent elements} if the relation $a \sim b$ holds. The notion of an \emph{equivalence class}\index{Equivalence class}, denoted as $[a]$, refers to the set of all elements in $A$ that are equivalent to a particular element $a$. In other words, the equivalence class of $a$ is defined as $[a] := \{ b \in A : a \sim b\}$. An equivalence relation serves to partition the base set into what is known as the \emph{quotient set}\index{Quotient set}. Represented as $A / {\mathord {\sim }}$, the quotient set consists of all equivalence classes stemming from elements of $A$, that is, $A / {\mathord {\sim }} := \{ [a] : a \in A \}$.

A binary relation that is reflexive, transitive, and antisymmetric is known as a \emph{partial order}\index{Partial order}, often represented by the symbol $\preceq$. A set equipped with a partial order is referred to as a \emph{partially ordered set}\index{Partially ordered set}, also abbreviated as \emph{poset}\index{poset}. In the context of a poset, an element $a$ from set $A$ is considered \emph{minimal}\index{Minimal element} if there is no other element $b$ in $A$ for which $b \preceq a$. Similarly, an element $a$ is labeled as \emph{maximal}\index{Maximal element} if no other element $b$ in $A$ exists such that $a \preceq b$. A relation that embodies reflexivity, transitivity, antisymmetry, and totality is designated as a \emph{total order}\index{Total order}, typically symbolized by $\leq$. A set that is coupled with a total order is identified as a \emph{totally ordered set}\index{Totally ordered set}. For any totally ordered set $A$, the \emph{maximum}\index{Maximum element} element is represented by $\max(A)$, meaning that $\max(A) \geq x$ holds for all $x$ in $A$. Similarly, the \emph{minimum}\index{Minimum element}, represented by $\min(A)$, is defined as an element such that $\min(A) \leq x$ for all $x$ in $A$.

\begin{example}
Let $R$ be a relation that is a subset of the Cartesian product of the set of natural numbers $\mathbb{N}$ with itself, i.e., $R \subset \mathbb{N} \times \mathbb{N}$. In this relation, an ordered pair $(a, b)$ belongs to $R$ if $a$ is a divisor of $b$. The set $\mathbb{N}$, when paired with relation $R$, forms a partially ordered set. In this context, the number $11$ serves as a minimal element of $R$. This is because $11$ is a prime number, which, by definition, can only be divided evenly by 1 and itself.
\end{example}

% Functions

A \emph{function}\index{Function} is defined as a binary relation $f \subseteq A \times B$, where for each element $x \in A$, there exists at most one $y \in B$ satisfying the condition $\left(x, y\right) \in f$. In this context, elements $\left(x, y\right) \in f$ are denoted by $f(x)=y$, with the function represented by $f : A \rightarrow B$. The set $A$ is referred to as the \emph{domain}\index{Domain} of $f$, and $B$ is the \emph{codomain}\index{Codomain}. The set $\{ y \in B : \exists x \in A , f(x) = y\}$ constitutes the \emph{range}\index{Range} of $f$. If the relation is not defined for all $x \in A$, the function is termed \emph{partial}\index{Partial function}, denoted by $f(x) \uparrow$ for undefined $x$ in the function $f$. 

\begin{example}
In Section \ref{sec:computable_functions}, we will discuss an alternate interpretation of a function as a procedure, or a series of steps, that assigns an element of $B$ to each element of $A$. For instance, the subsequent C code delineates a partial function from $\mathbb{R}$ to $\mathbb{R}$, characterized as partial due to $inv(0)\uparrow$:
\begin{verbatim}
    double inv(double x) {
        return 1 / x;
    }
\end{verbatim}
\end{example}

A function is said to be \emph{injective}\index{Injective function} if, for all elements $x$ and $y$, $f(x) = f(y)$ implies $x=y$. A function is \emph{surjective}\index{Surjective function} when for every $y$, there exists at least one $x$ such that $f(x) = y$. A function is described as \emph{bijective}\index{Bijective function} if it exhibits both injective and surjective properties. The \emph{identity}\index{Identity function} function $I_A : A \rightarrow A$, determined by $f(a) = a$ for all $a \in A$, is bijective. These concepts of function, partial function, injective, surjective, and bijective can be extended to $n$-ary functions, represented as $f: A_1 \times A_2 \times \dots A_n \rightarrow B$.

The \emph{inverse}\index{Inverse function} function of a function $f$, represented by $f^{-1}$, is identified by $f(f^{-1}(x)) = f^{-1}(f(x)) = x$. Given two functions $f$ and $g$, where the domain of $f$ coincides with the range of $g$, we define the \emph{composition}\index{Composition} of $f$ with $g$, represented by $f \circ g$, as $f \circ g = f(g(x))$.

An infinite set $A$ is designated as \emph{countable}\index{Countable set} if there is a bijective function that maps the elements of $A$ onto the set of natural numbers $\mathbb{N}$. In contrast, a set is deemed \emph{uncountable}\index{Uncountable set} if it is not finite and also not countable. We refer to a set as having \emph{countably many}\index{Countably many set} elements if it is either finite or countable.

\begin{example}
Sets like $\mathbb{N}$, $\mathbb{Z}$ and $\mathbb{Q}$ are countable, while $\mathbb{R}$ is not.
\end{example}

The \emph{characteristic function}\index{Characteristic function} of a set $A$ is denoted as $1_A : A \rightarrow \{1, 0\}$, where $1_A(x) = 1$ if $x \in A$ and $0$ otherwise.

Considering a real number $x \in \mathbb{R}$, its \emph{absolute value}\index{Absolute value}, represented as $\mid x \mid$, is defined to be $x$ if $x \geq 0$ and $-x$ if $x < 0$. The \emph{ceil}\index{Ceil} function of $x$, denoted as $\lceil x \rceil$, is the smallest integer that is greater than or equal to $x$. The \emph{floor}\index{Floor} function of $x$, represented by $\lfloor x \rfloor$, is the largest integer that is less than or equal to $x$. Given two positive integers $a$ and $b$, the \emph{modulo}\index{Modulo} operation of $a$ and $b$, symbolized by $a \bmod b$, gives the remainder of the integer division of $a$ by $b$.

For two functions $f$ and $g$, defined as $f,g:\mathbb{N}\rightarrow\mathbb{R}^{+}$, we assert that $f(n)$ is of \emph{order of}\index{Order of a function} $g(n)$, symbolized by $f(n)=O(g(n))$, if there exist positive integers $c$ and $m$ such that $f(n)\leq cg(n)$ for every integer $n \geq m$. If $f(n)=O(g(n))$, we denote $g$ as an \emph{upper bound}\index{Upper bound of a function} for $f$.

%
% Section: Strings and Languages
%

\section{Strings and Languages}
\label{sec:strings}

Consider a non-empty finite set $\mathcal{S}=\left\{ s_{1},s_{2},\ldots,s_{q}\right\}$, which we will refer to as the \emph{alphabet}\index{Alphabet}. The elements of this set are termed \emph{symbols}\index{Symbols}. A \emph{sequence}\index{Sequence of symbols} over $\mathcal{S}$ is defined as an ordered arrangement of symbols $x_1 x_2 \dots x_n$ taken from $\mathcal{S}$. In the special case where the alphabet is the set $\mathcal{B} = \{0, 1\}$, such sequences are known as \emph{binary sequences}\index{Binary sequence}. We use the term \emph{string}\index{String} to denote a finite sequence. This book predominantly focuses on binary strings. 

The \emph{length}\index{Length of a string} of a string $s$, represented as $l(s)$, refers to the total number of symbols present in $s$. We use the notation $\lambda$ to represent the \emph{empty string}\index{Empty string}, which is defined as the unique string over $\mathcal{S}$ that has a length of 0. Given a symbol $x \in \mathcal{S}$, the string comprising $x$ repeated $n$ times is denoted by $x^n$. If $s = x_1 x_2 \dots x_n$ constitutes a string, its \emph{reverse}\index{Reverse string}, designated as $s^R$, is $x_n x_{n-1} \dots x_1$.

The set of all strings $s_{1}s_{2}\ldots s_{n}$ of length $n$ over the alphabet $\mathcal{S}$ is denoted by $\mathcal{S}^{n}$\footnote{It is important to avoid confusing the set of strings of length $n$ over an alphabet $\mathcal{S}^n$ with the $n$-fold Cartesian product of a set $S^n$. The use of calligraphic fonts helps distinguish between alphabets and other sets.}. We denote by $\mathcal{S}^{+}$ the union of all $\mathcal{S}^{n}$ for $n\geq1$, and by $\mathcal{S}^{\ast}$ the set $\mathcal{S}^{+} \cup \{\lambda\}$. Note that all strings in $\mathcal{S}^{\ast}$ have finite lengths. The term \emph{Kleene closure}\index{Kleene closure} refers to $\mathcal{S}^{\ast}$.

\begin{example}
The following relations hold: the cardinality of the set of binary strings of length $n$ is $d \left( \left\{ s \in \mathcal{B}^{\ast} : l(s) = n \right\} \right) = 2^n$, and the cardinality of the set of binary strings of length up to $n$ is $d \left( \left\{ s \in \mathcal{B}^{\ast} : l(s) \leq n \right\} \right) = 2^{n+1}-1$.
\end{example}

Given two strings $s$ and $t$ from $\mathcal{S}^{\ast}$, the \emph{concatenation}\index{String concatenation} of $s$ and $t$, symbolized as $st$, is the sequence that results from placing the sequence of symbols in $t$ immediately after the sequence of symbols in $s$. Consequently, the length of the concatenated string, $l(st)$, is the sum of the lengths of $s$ and $t$. This suggests that $\mathcal{S}^\ast$ is closed under the concatenation operation. Furthermore, the set $\mathcal{S}^\ast$, together with the operation of concatenation, forms a \emph{free monoid}\index{Free monoid}. This implies that concatenation is associative ($s(tr)=(st)r$), and that there is an identity element, specifically, the empty string $\lambda$, for which $\lambda a = a \lambda = a$ holds.

A string $s$ is termed a \emph{substring}\index{Substring} of $t$ if there exist strings $u$ and $v$ (which may be empty) such that $t = usv$. If there exists a string $u$ such that $t = su$, $s$ is considered a \emph{prefix}\index{Prefix string} of $t$, which is notated as $s <_p t$. A subset $S \subset \mathcal{S}^{\ast}$ is described as \emph{prefix-free}\index{Prefix free set} if, for any $s, t \in S$, $s = t$ whenever $s <_p t$. Let $S, T \subset \mathcal{S}^{\ast}$ be two sets of strings, the (left) \emph{quotient}\index{String quotient} $S^{-1}T$ is defined as the residual words obtained from $T$ by removing some prefix in $S$; formally, $S^{-1}T=\{\,t \mid st \in T \land s \in S\,\}$.

We denote the \emph{self-delimited}\index{Self delimited string} form of a string $s \in \mathcal{S}^{\ast}$ by $\bar{s}$, and define it as $\bar{s} = 1^{l(s)}0s$. Consequently, the length of $\bar{s}$, $l(\bar{s})$, is twice the length of $s$ plus one, i.e., $l(\bar{s}) = 2l(s)+1$.

\begin{example}
The set $\bar{\mathcal{S}^{\ast}}$, which comprises all the self-delimited strings from $\mathcal{S}^{\ast}$, is prefix-free.
\end{example}

In cases where $\mathcal{S}$ is a totally ordered set, we are able to define a total order on $\mathcal{S}^{\ast}$. This ordering, termed \emph{shortlex ordering}\index{Shortlex ordering}, arranges sequences primarily by length, positioning the shortest sequences first. Sequences of identical length are further sorted according to lexicographical order.

\begin{example}
Given $S = \{a, b, c\}$ with $a < b < c$, the shortlex order on $\mathcal{S}^{\ast}$ generates the relations $\lambda < a < b < c < aa < ab < \ldots < cc < aaa < aab < \ldots < ccc < \ldots$
\end{example}

For any arbitrary object $O$, we utilize the notation $\left\langle O\right\rangle$ to represent its string representation, presupposing the existence of a standard encoding method. For objects $O_{1},O_{2},\ldots,O_{k}$, the notation $\left\langle O_1 O_2 \ldots O_k \right\rangle$ denotes the concatenation of the string representations of these objects: $\left\langle O_1 \right\rangle \left\langle O_2 \right\rangle \ldots \left\langle O_k \right\rangle$. We employ the notation $\left\langle O_1, O_2,\ldots,O_k \right\rangle$ to indicate the concatenation of the representations of these objects in a manner that allows for decoding and unique identification of all objects. As an example, $\left\langle O_1, O_2,\ldots,O_k \right\rangle$ might be represented as $\bar{\left\langle O_1 \right\rangle} \bar{\left\langle O_2 \right\rangle} \ldots \bar{\left\langle O_k \right\rangle}$.

\begin{example}
Natural numbers can be represented by binary strings via the following encoding method: $\langle 0 \rangle = \lambda$, $\langle 1 \rangle \rightarrow 0$, $\langle 2 \rangle \rightarrow 1$, $\langle 3 \rangle \rightarrow 00$, $\langle 4 \rangle \rightarrow 01$, $\langle 5 \rangle \rightarrow 10$, $\langle 6 \rangle \rightarrow 11$, $7 \rightarrow 000$, and so on. Therefore, the pair of numbers $\left\langle 3, 7 \right\rangle$ would be represented as $110001110000$. Given this particular encoding, it follows that $l \left( \langle n \rangle \right) = \lfloor \log_2 (n + 1) \rfloor$.
\end{example}

A \emph{language}\index{Language} $L$ over an alphabet $\mathcal{S}$ is a set of strings $L \subset \mathcal{S}^{\ast}$. The elements of $L$ are called \emph{words}\index{Words of a language}. The \emph{empty language}\index{Empty language} is the language that contains no words $L = \varnothing$. 

A \emph{language}\index{Language}, denoted by $L$, over an alphabet $\mathcal{S}$, is defined as a subset of strings such that $L \subseteq \mathcal{S}^{\ast}$. The individual elements of $L$ are termed as \emph{words}\index{Words of a language}. The unique language that does not contain any words is referred to as the \emph{empty language}\index{Empty language}, and is expressed as $L = \varnothing$.

Consider two languages $L_1$ and $L_2$ over a common alphabet $\mathcal{S}$. There are several standard operations that can be applied to these languages, including: language union $L_1 \cup L_2 = \{ w \in \mathcal{S}^{\ast} \mid w \in L_1 \text{ or } w \in L_2 \}$, language intersection $L_1 \cap L_2 = \{ w \in \mathcal{S}^{\ast} \mid w \in L_1 \text{ and } w \in L_2 \}$, language complement $\overline{L_1} = \{ w \in \mathcal{S}^{\ast} \mid w \notin L_1 \}$, and Kleene closure $L_1^\ast = \{ \lambda \} \cup \{ wz \mid w \in L_1 \text{ and } z \in L_1^\ast \}$.

Languages can be systematically generated using a finite set of string rewriting rules known as grammars. A \emph{grammar}\index{Grammar}, denoted as $G$, is a 4-tuple $(N, \Sigma, P, S)$, where: $N \subseteq \mathcal{S}$ is a finite set of \emph{nonterminal symbols}\index{Non-terminal symbol}; $\Sigma \subseteq \mathcal{S}$ is a finite set of \emph{terminal symbols}\index{Terminal symbol}; $P$ is a finite set of \emph{production rules}\index{Production rule} in the form $( \Sigma \cup N )^\ast N ( \Sigma \cup N)^\ast \rightarrow (\Sigma \cup N)^\ast$; and $S \in N$ is a special \emph{start symbol}\index{Start symbol}. Each production rule transforms one string of symbols into another, starting with the designated start symbol.

\begin{example}
\label{ex:context_free_grammar}
Let us consider the alphabet $\mathcal{S} = \{ S, a, b \}$, and define the grammar $(N, \Sigma, P, S)$ where $N = \{ S \}$, $\Sigma = \{ a, b \}$, $P = \{ S \rightarrow aSb, S \rightarrow ba \}$, and the start symbol is $S \in N$. This grammar generates the language $L = \{ a^nbab^n \mid n\geq0 \} = \{ ba, abab, aababb, aaababbb, \ldots \}$.
\end{example}

The \emph{Chomsky hierarchy}\index{Chomsky hierarchy} serves as a categorization system for grammars, based on their expressive capacity or the range of languages they can generate. The hierarchy, listed from the most to the least restrictive grammars, is defined as follows (where $a$ represents a terminal symbol, $A, B$ are non-terminal symbols, and $\alpha, \beta$, and $\gamma$ denote strings composed of either terminal or non-terminal symbols):

\begin{description}
\item[Type-3] Also known as \emph{regular grammars}\index{Regular grammar}. For these grammars, the left-hand side of every production rule consists solely of a single nonterminal symbol. The right-hand side may either be an empty string, a single terminal symbol, or a single terminal symbol followed by a nonterminal symbol. Formally, the rules are ($A \rightarrow \lambda$, $A \rightarrow a$, $A \rightarrow aB$).

\item[Type-2] These are referred to as \emph{context-free grammars}\index{Context-free-grammar}. Here, the left-hand side of each production rule is comprised of only a single nonterminal symbol, symbolically expressed as ($A \rightarrow \alpha$).

\item[Type-1] These are \emph{context-sensitive grammars}\index{Context sensitive grammar}. In this case, the left and right sides of the production rules may be embedded within a context of terminal and nonterminal symbols. This can be written as ($\alpha A \beta \rightarrow \alpha \gamma \beta$).

\item[Type-0] The \emph{recursively enumerable grammars}\index{Recursively enumerable grammar} fall in this category, and they do not impose any constraints on the production rules ($\gamma \rightarrow \alpha$).
\end{description}

\begin{example}
The grammar discussed in Example \ref{ex:context_free_grammar} is classified as a Type-2, or context-free grammar.
\end{example}

The \emph{Backus–Naur form}\index{Backus–Naur form} is a notation system specifically designed for context-free grammars. This notation is frequently employed in the field of computer science to formally outline the syntax of programming languages and communication protocols. A Backus–Naur form consists of a set of production rules structured in the following way:

\begin{verbatim}
    <symbol> ::= __expression__
\end{verbatim}

Here, \texttt{<symbol>} stands for a non-terminal symbol, \texttt{\_\_expression\_\_} refers to a string of terminal or non-terminal symbols, and \texttt{::=} indicates that the symbol on the left-hand side should be substituted with the expression on the right. Several \texttt{\_\_expression\_\_}s can be integrated into a single production rule by separating them with a vertical bar \texttt{|}, suggesting that any one of them can be selected for substitution. Symbols that are not found on a left-hand side of a production rule are considered terminal symbols. Conversely, those that appear on a left-hand side are non-terminal symbols and are invariably enclosed within the pair \texttt{<>}. The non-terminal symbol of the first production rule is identified as the start symbol.

\begin{example}
The grammar discussed in Example \ref{ex:context_free_grammar} can be reformulated in Backus-Naur form using the subsequent production rule:
\begin{verbatim}
    <string> ::= a <string> b | ba
\end{verbatim}
\end{example}

%
% Section: Counting Methods
%

\section{Counting Methods}
\label{sec:counting}

\emph{Combinatorics}\index{Combinatorics}, a specialized branch of mathematics, primarily focuses on the investigation of discrete objects and their mutual relationships. The core aspects of combinatorics include the counting, arranging, and selection of these objects, supplemented by the methodologies employed for achieving these objectives. It presents an array of robust tools essential for handling extensive collections of objects exhibiting certain characteristics. In this section, we shall focus on revisiting the significant outcomes of combinatorics from the perspective of sets and ordered lists.

The \emph{multiplication rule}\index{Multiplication rule} is a fundamental theorem that specifies the number of potential outcomes in the Cartesian product of sets. According to this rule, if there are $k$ sets $A_1, A_2, \ldots, A_k$, and each set contains $n_i$ elements $\left( i=1, \ldots, k \right)$, then the Cartesian product $A_1 \times A_2 \times \ldots \times A_k$ encapsulates a total of $n_1 n_2 \ldots n_k$ elements. Particularly, if a set $A$ consists of $n$ elements, then $A^k$ includes $n^k$ elements.

The \emph{inclusion-exclusion principle}\index{Inclusion-exclusion principle} provides the count of the union of several sets, given the individual size of each set, and the size of every feasible intersection of these sets. Given $k$ sets $A_1, A_2, \ldots, A_k$, the expression is as follows:
\begin{equation*}
\begin{split}
d \left( \bigcup_{i=1}^k A_i \right) & = \sum_{i=1}^k d \left( A_i \right) - \sum_{i<j} d \left( A_i \cap A_j \right) + \sum_{i<j<l} d \left( A_i \cap A_j \cap A_l \right) - \\
& - \sum_{i<j<l<m} d \left( A_i \cap A_j \cap A_l \cap A_m \right) + \ldots +  (-1)^{k+1} d \left( A_1 \cap A_2 \cap \ldots \cap A_k \right) 
\end{split}
\end{equation*}
\emph{Permutations}\index{Permutations} denote the number of ways in which a set's elements can be arranged. Suppose $A$ is a set with $n$ elements, the number of permutations of $n$ elements taken $k$ at a time, represented as $P_{n,k}$, is $P_{n,k} = n \left( n-1 \right) \ldots \left( n-k+1 \right)$. When $k=n$, the permutations are calculated as $P_{n,n} = n \left( n-1 \right) \cdots 1=n!$, where $n!$ is known as $n$ factorial.

The \emph{pigeonhole principle}\index{Pigeonhole orinciple} is a simple yet powerful concept that states if you have more pigeons than pigeonholes, then there must be at least one pigeonhole with more than one pigeon. In a more mathematical sense, if you have $n$ items to place into $m$ containers and $n>m$, then at least one container must contain more than one item.

For performing vast computations, an approximation of $n!$, commonly known as \emph{Stirling's formula}, proves highly effective:
\[
\log\left(n!\right) \approx \frac{1}{2}\log\left(2\pi\right)+\left(n+\frac{1}{2}\right)\log\left(n\right)-n
\]

\begin{example}
Consider the set \{a, b, c\}. There are six unique permutations of its elements: $[a, b, c], [a, c, b], [b, a, c], [b, c, a], [c, a, b], [c, b, a]$. Each permutation signifies a distinct order of the elements in the original set.
\end{example}

Numerous counting problems revolve around determining the quantity of subsets of a certain size present within a given set. Given a set with $n$ elements, the total possible subsets amount to $2^n$, inclusive of the empty set and the set itself. The quantity of subsets of size $k$, also known as the number of \emph{combinations}\index{Combinations} of $k$ elements from a set of $n$, denoted by $C_{n,k}$, is computed using the formula $C_{n,k}=\frac{P_{n,k}}{k!}=\frac{n!}{k!\left(n-k\right)!}$. The symbol ${n \choose k}$ also represents the number $C_{n,k}$, which is known as the \emph{binomial coefficient}\index{Binomial coefficient}. We know that for all $n$, ${n \choose 0}={n \choose n}=1$, and for all $n$ and $k=0,1,\ldots,n$, ${n \choose k}={n \choose n-k}$. Moreover, ${n \choose k} = 0$ for $k>n$.

\begin{example}
Take for instance the set $\{a, b, c, d \}$. There exist 4 combinations of size 3: $[a, b, c]$, $[a, b, d]$, $[a, c, d]$, and $[b, c, d]$. Combinations do not consider order, hence $[a, c, d]$ and $[d, c, a]$ are deemed the same combination.
\end{example}

The \emph{multinomial coefficient}\index{Multinomial coefficient}, an extension of the binomial coefficient to more than two categories or types, signifies the number of ways a set of objects can be partitioned into a fixed number of subsets, each of which contains a specific number of objects. Assuming we have a set with $n$ elements, which can be partitioned into $k$ subsets of sizes $n_1, n_2, \ldots, n_k$, respectively. The multinomial coefficient, symbolized as ${n \choose n_{1},n_{2},\ldots,n_{k}}$, represents the number of feasible partitions, and is computed as ${n \choose n_{1},n_{2},\ldots,n_{k}} = \frac{n!}{n_{1}!n_{2}!\ldots n_{k}!}$.

%
% Section: Matrices
%

\section{Matrices}

A \emph{matrix}\index{Matrix}, denoted by $A$, of order $m \times n$ is composed of a sequence of $mn$ scalars. These scalars are arranged in a rectangular array consisting of $m$ \emph{rows} and $n$ \emph{columns}, as depicted below:
\[
A = 
 \begin{pmatrix}
  a_{1,1} & a_{1,2} & \cdots & a_{1,n} \\
  a_{2,1} & a_{2,2} & \cdots & a_{2,n} \\
  \vdots  & \vdots  & \ddots & \vdots  \\
  a_{m,1} & a_{m,2} & \cdots & a_{m,n} 
 \end{pmatrix}
\]

The \emph{entry} $a_{ij}$ denotes the element of $A$ found at the $i$-th row and $j$-th column. The \emph{set of all matrices} of order $m \times n$ is symbolized as $\mathcal{M}_{m \times n}$. A \emph{row matrix}\index{Row matrix} belongs to the set $\mathcal{M}_{1 \times n}$, whereas a \emph{column matrix}\index{Column matrix} is a member of $\mathcal{M}_{m \times 1}$. A \emph{square matrix}\index{Square matrix} is any matrix within the set $\mathcal{M}_{n \times n}$. The entries $a_{ii}$ compose the \emph{main diagonal}\index{Matrix main diagonal} of a square matrix. A \emph{diagonal matrix}\index{Diagonal matrix} is distinguished by having all of its entries outside the main diagonal as zero. The \emph{identity matrix}\index{Identity matrix}, denoted by $I$, is a diagonal square matrix with all entries on the main diagonal equal to 1.

The \emph{transpose}\index{Matrix transpose} of a matrix $A \in \mathcal{M}_{m \times n}$ is defined as the matrix $A^T \in \mathcal{M}_{n \times m}$, with entries at position $(i,j)$ mirroring the entries at position $(j, i)$ in $A$. If $A = A^T$, then the matrix $A$ is classified as a \emph{symmetric matrix}\index{Symmetric matrix}. A \emph{submatrix}\index{Submatrix} of a matrix is obtained by eliminating any selection of rows and/or columns.

\begin{example}
Take for instance the square matrix $A = \left( \begin{smallmatrix} 1 & 2 & 3 \\ 4 & 5 & 6 \\ 7 & 8 & 9 \end{smallmatrix} \right)$. Here, the entry located at position $(2, 3)$ has the value $6$, the main diagonal is made up of the numbers $1$, $5$, and $9$. The transpose of the matrix is $A^T = \left( \begin{smallmatrix} 1 & 4 & 7 \\ 2 & 5 & 8 \\ 3 & 6 & 9 \end{smallmatrix} \right)$, and the matrix $B = \left( \begin{smallmatrix} 1 & 3 \\ 4 & 6 \end{smallmatrix} \right)$ is identified as a submatrix of $A$.
\end{example}

The addition of two matrices $A$ and $B$ of identical size results in a new matrix $A + B$. Each entry $(i, j)$ of this matrix is given by $(A + B)_{ij} = a_{ij} + b_{ij}$. The operation of matrix addition exhibits associativity, i.e., $(A + B) + C = A + (B + C)$, and commutativity, i.e., $A + B = B + A$. It has a neutral element, such that $A + 0_{m \times n} = A$, and an inverse element, $A + (-A) = 0_{m \times n}$.

The product of a scalar $\lambda$ and a matrix $A$ yields another matrix, denoted $\lambda A$, where each entry $(i, j)$ is $(\lambda A)_{ij} = \lambda a_{ij}$. This scalar multiplication operation is distributive relative to the addition of matrices, as $(\alpha (A + B) = \alpha A + \alpha B)$, and to the addition of scalars, as $(\alpha + \beta) A = \alpha A + \beta B$. It is also associative with scalar multiplication, such that $(\alpha \beta) A = \alpha (\beta A)$, and has a unit element, as $1 A = A$.

The product of two matrices $A_{m \times n}$ and $B_{n \times p}$ results in a matrix $AB_{m \times p}$, where each entry $(i, j)$ is given by $(AB)_{ij} = \sum_{k=1}^n a_{ik} b_{kj}$. The operation of matrix multiplication is associative, as $(A B) D = A (B D)$, and it possesses a left neutral element $A I_n = A$ and a right neutral element $I_m A = A$. It is associative with respect to scalar multiplication, such that $\alpha (A B) = (\alpha A) B = A (\alpha B)$, and is distributive with respect to matrix addition, both from the right $A (B + C) = AB + AC$ and from the left $(B + C) D = B D + C D$. 

Additionally, the transpose operation satisfies the following properties: $(A + B)^T = A^T + B^T$, $(\lambda A)^T = \lambda A^T$, and $(A B)^T = B^T A^T$.

\begin{example}
Given the matrices $A = \left( \begin{smallmatrix} 1 & 2 \\ 3 & 5 \end{smallmatrix} \right)$ and $B = \left( \begin{smallmatrix} 5 & 6 \\ 7 & 8 \end{smallmatrix} \right)$ we have that $A + B = \left( \begin{smallmatrix} 6 & 8 \\ 10 & 13 \end{smallmatrix} \right)$, $2 A = \left( \begin{smallmatrix} 2 & 4 \\ 6 & 10 \end{smallmatrix} \right)$ and $A B = \left( \begin{smallmatrix} 19 & 22 \\ 50 & 58 \end{smallmatrix} \right)$.
\end{example}

A square matrix $A$ is \emph{invertible} or \emph{non-singular} if there exists a matrix $B$ such that $AB = BA = I$. If $A$ is non-singular, $B$ is unique and is called the \emph{inverse matrix} of $A$, denoted by $A^{-1}$. A matrix $A$ is \emph{orthogonal} if its transpose is equal to its inverse $A^T = A^{-1}$; the columns and rows of a orthogonal matrix are called \emph{orthonormal vectors}.

The \emph{determinant}\index{Matrix determinant} is a special scalar value that can be computed from the elements of a square matrix. The determinant is denoted as det($A$) for a matrix $A$. The determinant of a square matrix can be computed using the Leibniz formula, which is given as:
\[
\text{det}(A) = \sum_{\sigma \in S_n} \text{sgn}(\sigma) \cdot a_{1,\sigma(1)} \cdot a_{2,\sigma(2)} \cdots a_{n,\sigma(n)}
\]
where $S_n$ denotes the set of all permutations of the numbers 1 to $n$, and sgn($\sigma$) is the signature of the permutation $\sigma$, being $+1$ for even permutations and $-1$ for odd permutations. The determinant is nonzero if and only if the matrix is invertible

\begin{example}
The computation of the determinant of a 3x3 matrix $A = \left( \begin{smallmatrix} a & b & c \\ d & e & f \\ g & h & i \end{smallmatrix} \right)$ is given by:

\begin{align*}
\text{det}(A) &= aei + bfg + cdh - ceg - bdi - afh
\end{align*}
\end{example}

For a given matrix $A$, the \emph{rank}\index{Matrix rank}, denoted as rank($A$), is the maximum number of linearly independent rows or columns within the matrix.

A number $\lambda$, and a non-zero vector $\mathbf{v}$ satisfying $A \mathbf{v} = \lambda \mathbf{v}$ are called an \emph{eigenvalue} and an \emph{eigenvector} of $A$, respectively.

Matrix decomposition is the process of rendering a matrix into a more easily accessible form, meanwhile certain properties, like the determinant or the rank, are preserved. The \emph{singular value decomposition}\index{Singular value decomposition} of a matrix $A$ of order $m \times n$ is a factorization of the form $A = U \Sigma V^T$ where $U$ is an $m \times m$ orthogonal matrix, $\Sigma$ is an $m \times n$ non-negative diagonal matrix of rectangular shape, and $V^T$ is the transpose of an $n \times n$ orthogonal matrix.

%
% Section: Graphs
%

\section{Graphs}
\label{sec:Graphs}

A \emph{graph}\index{Graph}\footnote{The definition of a graph stated here corresponds to the definition of a \emph{simple graph} as found in typical discrete mathematics literature.} $G$ is represented as an ordered pair $(V,E)$, comprising a set $V$, referred to as \emph{vertices}\index{Vertices of a graph}, and a set $E$, denoted as \emph{edges}\index{Edges of a graph}. The members of $E$ take the form of unordered pairs $\left\{ u,v\right\}$, constituting distinct vertices $u,v\in V$ (loops are not permitted). Vertices $u$ and $v$ are described as \emph{adjacent}\index{Adjacent vertices} when an edge $\left\{ u,v\right\} \in E$ exists, consequently, they are termed the \emph{endpoints}\index{Endpoints of an edge} of that edge. If the set $V$ is infinite, the graph is classified as an \emph{infinite graph}\index{Infinite graph}. This book, however, focuses exclusively on finite graphs. Given that $G = (V,E)$ is a graph, its \emph{adjacency matrix}\index{Adjacency matrix} is a square $d(V) \times d(V)$ matrix $A$ whereby element $A_{uv}$ equals 1 if $\left\{ u,v\right\} \in E$ and 0 otherwise.

Graphs are typically illustrated as a collection of dots representing vertices, linked by lines denoting edges.

\begin{example}
\label{ex:binary_tree}
If $V=\{a, b, c, d\}$ and $E=\{ \{a,b\}, \{a,c\}, \{a,d\}, \{b,c\} \}$, the graph $G=(V,E)$ is represented in Figure \ref{fig:Graph-Example}.
\end{example}

\begin{figure}[t]
\centering
\begin{tikzpicture}

  % Small circles
  \node[draw, fill=black, circle, inner sep=0.075cm, label=above left:{$a$}] (circlea) at (0, 0) {};
  \node[draw, fill=black, circle, inner sep=0.075cm, label=above right:{$b$}] (circleb) at (2, 0) {};
  \node[draw, fill=black, circle, inner sep=0.075cm, label=below left:{$c$}] (circlec) at (0, -2) {};
  \node[draw, fill=black, circle, inner sep=0.075cm, label=below right:{$d$}] (circled) at (2, -2) {};

  % Arrows
  \draw[-] (circlea) to (circleb);
  \draw[-] (circlea) to (circlec);
  \draw[-] (circleb) to (circled);
  \draw[-] (circleb) to (circlec);

\end{tikzpicture}
\caption{\label{fig:Graph-Example}An Example of Graph}
\end{figure}

When a vertex $v$ serves as an endpoint of an edge $e$, it is said that $e$ is \emph{incident}\index{Incident edge} upon $v$. The \emph{degree}\index{Degree of a vertex} of a vertex $v$, notated as $\deg(v)$, corresponds to the count of edges incident on $v$. A vertex with degree zero is labeled as \emph{isolated}\index{Isolated vertex}, while a vertex with degree one is termed \emph{pendant}\index{Pendant vertex}. The \emph{neighborhood}\index{Neighborhood of a vertex} of a vertex $v$, signified by $N(v)$, includes all vertices that are adjacent to $v$. If $A \subset V$, the neighborhood of $A$ is given by $N(A) = \cup_{v \in A} N(v)$. A \emph{path}\index{Path} in a graph consists of a series of unique vertices $\{v_{0}, v_{1}, \ldots ,v_{k}\}$ such that $v_{i}$ and $v_{i+1}$ are adjacent for each $1 \leq i < k$. A path is known as a \emph{simple path}\index{Simple path} if no vertex is repeated. A graph is considered \emph{connected}\index{Connected graph} when a path exists between any two vertices. If $v_{0} = v_{k}$, the path is defined as a \emph{cycle}\index{Cycle}. A cycle is called a \emph{simple cycle}\index{Simple cycle} if it consists of at least three vertices and only the first and last vertices are repeated. 

\begin{example}
In a given graph $G=(V,E)$, the \emph{handshaking theorem}\index{Handshaking theorem} posits that $\sum_{v \in V} \deg(v) = 2m$, where $m = d(E)$, given that each edge has two endpoints.
\end{example}

If the vertex pairs $u, v$ are arranged in ordered pairs, the graph is termed a \emph{directed graph}\index{Directed graph}. In this case, $u$ is referred to as the \emph{initial vertex}\index{Initial vertex}, while $v$ is known as the \emph{terminal vertex}\index{Terminal vertex}. Given that $G$ is a directed graph, the \emph{in-degree}\index{In-degree of a vertex} of a vertex $v$, signified by $indeg(v)$, corresponds to the count of edges in which $v$ serves as a terminal vertex. The \emph{out-degree}\index{Out-degree of a vertex}, denoted by $outdeg(v)$, refers to the number of edges where $v$ is the initial vertex. A directed graph is \emph{strongly connected}\index{Strongly connected graph} if a directed path connects each pair of vertices. Directed graphs are typically illustrated with arrows, rather than lines, to represent edges.

A graph $G$ is classified as \emph{bipartite}\index{Bipartite graph} if the vertex set $V$ can be partitioned into two subsets $V_1$ and $V_2$ such that every edge of $G$ links a vertex from $V_1$ to one from $V_2$. Bipartite graphs are usually denoted as $G=(V_1, V_2, E)$. The degree of vertices in a bipartite graph adheres to the \emph{degree sum formula}\index{Degree sum formula}, $\sum_{u \in V_1} \deg(u) = \sum_{v \in V_2} \deg(v) = d(E)$.

A graph $G(V',E')$ is a \emph{subgraph}\index{Subgraph} of $G(V,E)$ if $V'$ is a subset of $V$ and $E'$ is a subset of $E$ with endpoints that belong to $V'$. A graph $G$ is termed a \emph{labeled graph}\index{Labeled graph} if its edges and/or vertices are assigned specific data. Specifically, if each edge $e$ of $G$ is allocated a nonnegative number $w(e)$, then $w(e)$ is referred to as the \emph{weight}\index{Weight of an edge} of $e$.

A specific type of graph that plays a fundamental role in this book is the \emph{tree}\index{Tree}. Defined as a non-empty graph, a tree ensures any pair of vertices are interconnected by a singular, unique path. A tree always includes a specially designated vertex termed the \emph{root}\index{Root of a tree}, and every edge of the tree is oriented away from the root.

\begin{example}
An alternative definition of trees, based on set theory, posits that a tree is a partially ordered set $(T, <)$ such that for each $t \in T$, the set $S = \{ s \in T : s < t \}$ possesses a least element – an element smaller than all other elements in $S$.
\end{example}

Given a tree $T$, for any vertex $v$ other than the root, the \emph{parent}\index{Parent of a vertex} of $v$ is the single, unique vertex $u$ such that an edge directly links $u$ to $v$. Conversely, if $u$ is the parent of $v$, $v$ is then identified as a \emph{child}\index{Child of a vertex} of $u$. Any other vertex within the tree sharing the same parent as $v$ is considered a \emph{sibling}\index{Sibling to a vertex} of $v$. The \emph{ancestors}\index{Ancestors of a vertex} of a vertex encompass all vertices along the path from the root to the given vertex, excluding the vertex itself but including the root. The \emph{descendants}\index{Descendant of a vertex} of a vertex $v$ include those vertices that count $v$ as an ancestor. A vertex with no children is labeled as a \emph{leaf}\index{Leaf vertex}, whereas vertices possessing children are referred to as \emph{branches}\index{Branches of a tree}. The \emph{depth}\index{Depth of a vertex} of a vertex $v$ is determined by the length of the unique path leading from the root to $v$. The \emph{height}\index{Height of a tree} of a tree is the maximum among the depths of all its vertices.

\begin{example}
For the tree illustrated in Figure \ref{fig:BinaryTree-Example}, the root vertex is $a$; $c$ serves as a parent of $d$, making $d$ a child of $c$; $d$ and $g$ are siblings; the ancestors of $d$ include $a$ and $c$; the descendants of $c$ comprise $d$, $e$, and $f$; leaf nodes in the tree are $b$, $e$, $f$, and $g$; $a$ and $c$ are branches; the depth of $d$ is 3; the height of the tree is 4.
\end{example}

\begin{figure}[t]
\centering
\begin{tikzpicture}

  % Small circles
  \node[draw, circle, inner sep=0.2cm, label=center:{$a$}] (circlea) at (0, 0) {};
  \node[draw, circle, inner sep=0.2cm, label=center:{$b$}] (circleb) at (-2, -2) {};
  \node[draw, circle, inner sep=0.2cm, label=center:{$c$}] (circlec) at (2, -2) {};
  \node[draw, circle, inner sep=0.2cm, label=center:{$d$}] (circled) at (0, -4) {};
  \node[draw, circle, inner sep=0.2cm, label=center:{$g$}] (circleg) at (4, -4) {};
  \node[draw, circle, inner sep=0.2cm, label=center:{$e$}] (circlee) at (-2, -6) {};
  \node[draw, circle, inner sep=0.2cm, label=center:{$f$}] (circlef) at (2, -6) {};


  % Arrows
  \draw[-] (circlea) to (circleb);
  \draw[-] (circlea) to (circlec);
  \draw[-] (circlec) to (circled);
  \draw[-] (circlec) to (circleg);
  \draw[-] (circled) to (circlee);
  \draw[-] (circled) to (circlef);

\end{tikzpicture}
\caption{\label{fig:BinaryTree-Example}An Example of a Tree}
\end{figure}

Given a vertex $v$ in a tree, the \emph{subtree}\index{Subtree} with $v$ as its root is the subgraph within the tree that includes $v$, its descendants, and all edges connected to these descendants. A tree is termed a \emph{k-ary tree}\index{k-ary tree} if each branch houses no more than $k$ children. If every branch comprises exactly $k$ children, the tree is then labeled a \emph{full k-ary tree}\index{full k-ary tree}. A \emph{k-ary} tree where $k=2$ is specifically referred to as a \emph{binary tree}\index{Binary tree}. A $k$-ary tree of height $h$ is deemed \emph{balanced}\index{Balanced tree} if all its leaves are located at a depth of $h$ or $h-1$.

\begin{example}
A tree composed of $n$ vertices includes $n-1$ edges. A full $k$-ary tree featuring $i$ branches hosts $m=ki+1$ vertices.
\end{example}

The procedure of visiting each node in a tree exactly once is defined as \emph{tree traversal}\index{Tree traversal}. The classifications of tree traversals are determined by the order of node visits, namely, \emph{depth-first} and \emph{breadth-first} order. In a depth-first traversal\index{Depth-first tree traversal}, the algorithm initiates at the root node and ventures as far as possible along each branch before transitioning to the next sibling. There are three standard strategies for processing nodes within the tree: \emph{in-order}\index{In-order tree traversal}, \emph{pre-order}\index{Pre-order tree traversal}, and \emph{post-order}\index{Post-order tree traversal}.

The following snippet of code, resembling C language syntax, demonstrates the usage of a recursive pre-order depth-first traversal algorithm to print a binary tree:

\begin{verbatim}
    void print_tree(binary_tree *tree) {
        if (!is_empty(tree)) {
            printf("%c\n",tree->node); /* print node */
            print_tree(tree->left_branch); /* process left branch */
            print_tree(tree->right_branch); /* process right branch */
        }
    }
\end{verbatim}

Conversely, in a breadth-first traversal\index{Breadth-first tree traversal}, the algorithm commences at the tree root and explores all nodes at the current depth before progressing to nodes at the subsequent depth level. Implementing depth-first tree traversal algorithms necessitates the employment of sophisticated data structures. For an example of such algorithms, please consult the references section.

\begin{example}
In the case of the tree delineated in Example \ref{ex:binary_tree}, a pre-order depth-first traversal would yield the string "abcdefg". Conversely, a pre-order breadth-first traversal would generate the string "abcdgef".
\end{example}

%
% Section: References
%

\section*{References}

The book "Discrete Mathematics" by Johnsonbaugh \cite{johnsonbaugh2009discrete} is tailored for undergraduate students taking a one- or two-semester course in discrete mathematics, thoroughly covering key topics in the field. "Introduction to the Theory of Computation" by Sipser \cite{sipser2012introduction} offers a comprehensive, clear, and student-centric introduction to the latest computational theory topics and methodologies. It is highly acclaimed for its in-depth exploration of automata, formal languages, and complexity theory. "Introduction to Algorithms" by Cormen et al. \cite{cormen1990introduction}, commonly known by the acronym "CLRS" derived from the authors' initials, is a seminal work in the algorithms field, encompassing a broad spectrum of topics, including graph algorithms. This book is both extensive and rigorous. Finally, "Matrix Computations" by Golub and Van Loan \cite{golub2013matrix} delves into various topics related to matrices, with an emphasis on matrix computations - an area of particular interest to those engaged in computational studies.






