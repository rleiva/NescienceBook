%
% CHAPTER.- Computability
%

\chapterimage{TuringMachine.pdf}

\chapter{Computability}
\label{chap:Computability}

\begin{quote}
\begin{flushright}
\emph{Caminante, no hay camino,\\
se hace camino al andar.\footnote{Wanderer, there is no road, the road is made by walking.}}\\
Antonio Machado
\end{flushright}
\end{quote}
\bigskip

We begin our review of the background required to understand the theory of nescience by providing a mathematical formalization of the concept of a \emph{computable procedure}\index{Computable procedure}. Intuitively, a computable procedure is a method consisting of a finite number of instructions that, when applied to a problem, produce the correct answer after a finite number of steps. The key point is that the instructions must be clear and precise enough for any human to follow without aid. We can even go a step further and requre that the instructions must be so straightforward that a machine could execute them. In 1936, British mathematician Alan Turing introduced a formal model for a family of hypothetical machines and posited that for every computable procedure (in its intuitive sense), there exists a \emph{Turing machine}\index{Turing machine} capable of computing it. The model was not only simple enough for precise mathematical analysis but also versatile and powerful.

Over the years, many alternative proposals have aimed to formalize the concept of computable procedure. Some have been very complicated, but all have proven equivalent to the concept of the Turing machine; that is, they solve the same set of problems. Two notable examples of alternative definitions are the \emph{lambda calculus}\index{Lambda calculus} by Alonzo Church and the \emph{theory of recursive functions}\index{Recursive function} by Kurt Gödel and Stephen Kleene. The \emph{Church-Turing thesis}\index{Church-Turing thesis} asserts that any formalization of the concept of a computable procedure, meeting some minimum requirements (such as performing a finite amount of work in a single step), is equivalent to a Turing machine. This thesis suggests an objective notion of a computable procedure that is independent of any specific formalization.

The concept of the Turing machine, initially referring to mechanical devices designed to solve individual problems, has been extended and universalized. A \emph{universal Turing machine}\index{Universal Turing machine} exists that can resolve all computable problems by simulating the behavior of other specific machines, akin to how modern computers run algorithms written in various programming languages. This concept raises a significant question: Are there problems that are not computable? We will see that the answer is affirmative, certain well-defined problems exceed the computational capabilities of computers, and such problems are more common than initially anticipated. The notion of uncomputable functions will be pivotal in our theory of nescience.

Given the abstract nature of most entities studied in science, we employ the concept of the \emph{oracle Turing machine}\index{Oracle Turing machine} to aptly formalize our theory. An oracle Turing machine resembles a regular Turing machine but is augmented with the capability to query an external oracle, whose workings are not fully understood, to aid in its computations. This oracle can address problems that are unresolvable by standard Turing machines—essentially, it can solve uncomputable problems. The oracle is a theoretical construct that represents a source of solutions or information that is not bound by the limitations of computability. It acts as a ‘black box’ that instantly provides answers to specific questions or problems, enabling the oracle Turing machine to transcend its computational boundaries. The oracle is an abstract and non-mechanical entity, a theoretical tool used to explore the bounds of computation, rather than a physical or concrete machine that can be built or observed.

Turing machines illuminate the inherent limitations of our computational capabilities. This exploration into the abstract and theoretical realms of computation is not just a philosophical endeavor; it also possesses practical applications in the field of \emph{computational complexity}\index{Computational complexity}. Located at the intersection of computer science and mathematics, computational complexity evaluates the challenges associated with solving problems, measured against the required resources, notably time and space. Problems are classified based on their intrinsic complexity and the computational effort required for their resolution. One of the key questions in this field is the elusive and yet unsolved $P\overset{?}{=}NP$\index{$P\overset{?}{=}NP$} question, which seeks to determine if the class $P$ of problems, those that are easy to solve, coincides with the class $NP$ of problems, whose solutions are easy to verify. In this book, our focus is not solely on the epistemological question of identifying which problems can be effectively solved given ample time and space, but also on those that can be resolved efficiently in time.

%
% Section: Turing Machines
%

\section{Turing Machines}
\label{sec:Turing-Machines}

A Turing machine is an extremely simplified model of a general-purpose computer, yet it is capable of solving any problem that real computers can address. Intuitively, one can envision the machine as consisting of a head that operates on a two-way infinite tape striped with symbols. At each time step, the machine reads the symbol under the head and decides to either write a new symbol on the tape, move the head one square to the left or right, or execute both actions. Algorithms are implemented using an internal table of rules housed within the control head, and the actual input to the algorithm is encoded on the tape. Once the machine reaches its final state, the algorithm's output can be read from the tape. Figure \ref{fig:Turing-Machine} depicts an example of a machine in its initial state, with the head located at the beginning of the input string.

\begin{figure}[t]
\centering
\begin{tikzpicture}[>=stealth', shorten >=1pt, auto, node distance=2cm]
    % Draw tape
    % \draw[thick] (-3,0) -- (3,0);
    \foreach \x in {-2.5,-1.5,...,2.5} {
        \draw (\x,-0.5) rectangle ++(1,1);
    }
    
    % Draw tape head
    \node[draw, rectangle, minimum height=1cm, minimum width=1cm, thick] (head) at (0.5,1.5) {Head};
    
    % Draw symbols on the tape
    \node at (-2,0) {1};
    \node at (-1,0) {0};
    \node at (0,0) {1};
    \node at (1,0) {0};
    \node at (2,0) {1};
    
    % Draw arrow from head to tape
    \draw[->] (head) -- (1,0.5);
\end{tikzpicture}
\caption{\label{fig:Turing-Machine}Turing Machine}
\end{figure}

The following definition formally introduces the concept of a Turing machine.

\begin{definition}[Turing Machine]
\label{def:Turing-Machine}\index{Turing machine}
A \emph{Turing machine} is a 7-tuple $\left(Q,\Gamma,\sqcup,\Sigma,q_{i},q_{f},\tau\right)$ where:
\begin{align*}
 & Q \quad \text{is a finite, non-empty, set of \emph{states},} \index{Machine State} \\
 & \Gamma \quad \text{is a finite, non-empty, set of \emph{tape symbols},} \index{Tape Symbol} \\
 & \sqcup\in\Gamma \quad \text{is the \emph{blank symbol},} \index{Blank Symbol} \\
 & \Sigma\subseteq\Gamma\setminus\sqcup \quad \text{is the set of \emph{input symbols},}  \index{Input Symbol} \\
 & q_{o}\in Q \quad \text{is the \emph{initial state},} \index{Initial State} \\
 & q_{f}\in Q \setminus \{q_o\} \quad \text{is the \emph{final state},} \index{Final State} \\ 
 & \tau:\left(Q\setminus \{q_{f}\}\right)\times\Gamma \rightarrow  Q\times\Gamma\times\left\{ L,R,S\right\} \quad\text{is a partial \emph{transition function}. \index{Transition Function} }
\end{align*}
\end{definition}

The algorithm executed by the machine is defined by the transition function $\tau$. This function dictates the machine's actions based on its current state and the tape symbol currently under the head. According to $\tau$, the machine transitions to a new state, writes a new symbol on the tape (or retains the existing one), and moves the head left, right, or keeps it stationary ($L$, $R$, or $S$ respectively). The machine follows a finite, uniquely determined sequence of steps until it reaches the final state $q_f$ and \emph{halts}, making no subsequent moves. The algorithm's output is the string of symbols $s \in \Sigma^\ast$ remaining on the tape after halting. Some machines, however, may enter an infinite loop, never reaching a halting state. If a machine encounters an undefined transition, it stalls.

The machine's input consists of a string of symbols, with the assumption that the machine's head is initially positioned at the first symbol of the input string. To address problems involving an object $O$ that isn’t a string, we must first develop a method to encode that object as a string, denoted as $\left\langle O \right\rangle$.

\begin{example}
\label{ex:Turing-Machine}
The following Turing machine is designed to solve the problem of adding two natural numbers. It consists of the set of states $Q = \left\{q_{o}, q_{1}, q_{f}\right\}$, the set of tape symbols $\Gamma = \left\{0, 1, \sqcup \right\}$, and the set of input symbols $\mathcal{B} = \left\{0, 1 \right\}$. The transition function is defined in the table below, where rows are indexed by machine states, and columns by tape symbols:

\begin{table}[h]
\centering
\begin{tabular}{l l l l}
\toprule
 & 0 & 1 & $\sqcup$ \\
\midrule
$q_{o}$ & $\left(q_{f}, \sqcup, S\right)$ & $\left(q_{1}, \sqcup, R\right)$ & $\uparrow$ \\
$q_{1}$ & $\left(q_{f}, 1     , S\right)$ & $\left(q_{f}, 1     , R\right)$ & $\uparrow$ \\
\bottomrule
\end{tabular}
\caption{Transition Rules}
\end{table}

For natural numbers $n$ and $m$, the input string is composed of $n$ occurrences of the symbol ‘1’, followed by a ‘0’, and then followed by $m$ occurrences of ‘1’. The machine's output will be a string of $n+m$ consecutive ‘1’s. For instance, to add the numbers 2 and 3, the input string should be $\sqcup 1 1 0 1 1 1 \sqcup$, resulting in the output string $\sqcup 1 1 1 1 1 \sqcup$.
\end{example}

A Turing machine can also be represented by a \emph{state diagram}\index{State diagram}. A state diagram is similar to a labeled directed graph\footnote{In this particular case, we allow loops and multiple edges originating from vertices.} where the vertices represent the states of the machine. The edges signify transitions from one state to another, and the edge labels indicate the symbol under the head that leads to the new state, the symbol that gets written on the tape, and the direction in which the head moves. Following these conventions, the state diagram for the Turing machine in Example \ref{ex:Turing-Machine} is depicted in Figure \ref{fig:Example-Turing-Machine}.

\begin{figure}[t]
\centering
\begin{tikzpicture}[shorten >=1pt,node distance=3cm,on grid,auto] 
   \node[state,initial] (q_0)   {$q_0$}; 
   \node[state] (q_1) [right=of q_0] {$q_1$}; 
   \node[state] (q_f) [right=of q_1] {$q_f$}; 
   
   \path[->] 
    (q_0) edge  node {1$\to$$\sqcup$,R} (q_1)
    (q_0) edge[bend right] node[below] {0$\to$$\sqcup$,R} (q_f)
    (q_1) edge  node {0$\to$1,S} (q_f)
    (q_1) edge [loop above] node {1$\to$1,R} ();
\end{tikzpicture}
\caption{\label{fig:Example-Turing-Machine}Example of Turing Machine}
\end{figure}

It is a remarkable fact that minor alterations to the definition of a Turing machine do not change its computational power. In other words, the definition is highly robust. In Example \ref{ex:multitape_turing_machine}, it's demonstrated that adding more tapes to the machine doesn't expand the range of problems it can solve. Similar arguments can be made when adding finite storage to the control tape, allowing for parallel processing with multiple control heads, and so on.

\begin{example}
\label{ex:multitape_turing_machine}
A \emph{multitape Turing machine}\index{Multitape Turing machine} is a Turing machine equipped with multiple heads and their respective tapes. In the initial configuration, the input string resides in tape 1, while the other tapes are blank. The transition function for a multitape Turing machine is:
\[
\tau:\left(Q \setminus q_{f} \right) \times \Gamma^k \rightarrow  Q \times \Gamma^k \times \left\{L,R,S\right\}^k,
\]
where $k$ denotes the number of tapes. Multitape Turing machines are equivalent in power to standard Turing machines. We can validate this claim by devising a method for a standard Turing machine to mimic a multitape machine's behavior. This requires encoding the content of multiple tapes onto a single tape, introducing a new symbol as a tape separator, and encoding the positions of the heads across the tapes with a distinct head location symbol. If we designate the tape separation symbol as $|$ and the head location symbol as $h$, a simulation tape for a machine with 3 tapes might appear as $\sqcup01h00|000h1|h0101\sqcup$. The standard machine's operation would involve scanning the subtapes one by one, pinpointing the head's location, and executing the necessary transition. If the computation on one subtape necessitates writing a new symbol beyond its boundary, we'd need to shift subsequent symbols to accommodate the new one. While the simulation might operate at a slower pace than the original multitape machine, both machine types can solve an identical set of problems.
\end{example}

For the remainder of this book, without any loss of generality, we'll assume that the set of input symbols is $\Sigma = \mathcal{B}$ and the set of tape symbols is $\Gamma = \left\{0, 1, \sqcup \right\}$.

In addition to providing a formal definition of a Turing machine, it's essential to formally outline its computational process. This entails detailing how the machine reads the input string, produces the output string, and transitions between states during computation. We will start by defining the concept of the machine's internal configuration. This configuration captures the machine's current state and position, as well as the present state of the tape.

\begin{definition}\index{Configuration}
A \emph{configuration}\index{Configuration} of a Turing machine $T$ is the 3-tuple $\left(q,s,i\right)$, where $q\in Q$ represents a state of the machine, $s\in\Gamma^+$ denotes a string containing the tape's content (excluding the blank symbols), and $1 \le i \le n$ is the index of the symbol $s_i$ beneath the head. Here, $s_1$ is the first non-blank symbol on the tape, and $n=l(s)$. 
\end{definition}

Configurations enable us to describe the current state of a Turing machine without any loss of information. At any stage of computation, one could halt the machine, record its configuration, and later resume the computation from the exact point of interruption using this configuration.

The following definition explains how we transition from one configuration to the next during computation.

\begin{definition}\index{Configuration yields configuration}
A configuration $C=\left(q,s,i\right)$ \emph{yields}\index{Yield} another configuration $C'=\left(r,s',j\right)$ if there exists a transition $\tau:\left(q, s_{i}\right) = \left(r, s'_{i}, a\right)$, where $s=s_{1} \dots s_{i-1}s_{i}s_{i+1} \dots s_{n}$, $s'=s_{1} \dots s_{i-1}s'_{i}s_{i+1} \dots s_{n}$, and
\begin{equation}
  j = \begin{cases}
        i+1 & \text{if $a=R$} \\
        i-1 & \text{if $a=L$} \\
        i   & \text{if $a=S$}
  \end{cases}
\end{equation}
\end{definition}

Building on the concepts of configuration and one configuration yielding another, we can now formally articulate the notion of computation.

\begin{definition}[Computation]\index{Computation}
Let $T$ be a Turing machine, $C_{0}$ its initial configuration, and $C_n$ a configuration encompassing the final state $q_f$. A \emph{computation}\index{Computation} under machine $T$ refers to a finite sequence of $n+1$ configurations $\left(C_{0},C_{1},\ldots,C_n\right)$ wherein each configuration $C_{k}$ yields the subsequent configuration $C_{k+1}$, for all $0\leq k < n$.
\end{definition}

Computations are deterministic; meaning, for a given Turing machine $T$ and an input string $s$, the configuration sequence is preordained. If machine $T$ neither halts nor progresses with input $s$, we deduce the absence of computation.

\begin{example}
The computation of the Turing machine described in Example \ref{ex:Turing-Machine} using the input string $110111$ results in the following sequence of configurations:

\begin{enumerate}
\item $(q_0, 110111, 1)$
\item $(q_1, 10111,  1)$
\item $(q_1, 10111,  2)$  
\item $(q_f, 11111,  2)$  
\end{enumerate}

\end{example}

Intuitively, a procedure is deemed computable by a human if it can be delineated through specific steps, executed systematically, without relying on intuition or ingenuity. This intuitive grasp aligns with the formalized concept of a Turing machine, bridging informal comprehension and the machine's rigorous definition—a cornerstone in the theory of computation. However, this alignment presents an intriguing challenge. Affirming that our grasp of computability mirrors a Turing machine's capabilities cannot be proven traditionally, as 'computability' lacks a well-defined interpretation. Consequently, some researchers categorize this as a \emph{thesis}, avoiding the formal 'theorem' label. Turing himself opted to term it a \emph{definition}, steering clear of denoting it as a theorem.

\begin{theorem}[Turing's Thesis]
\label{th:turing_thesis}\index{Turing's thesis}
A procedure is computable if, and only if, it can be executed by a Turing machine.
\end{theorem}

To further underscore the significance and robustness of the Turing machine as a model of computation, it's worth noting, as mentioned earlier in this chapter, that all alternative formalizations of computability proposed to date align in terms of their computational capabilities with that of the Turing machine. This universality underscores the Turing machine's central position in the realm of theoretical computer science.

%
% Section: Universal Turing Machine
%

\section{Universal Turing Machines}
\label{sec:Universal-Turing-Machines}

In Section \ref{sec:Turing-Machines}, we explored storing the current state of a Turing machine, its configuration, to pause and later resume computation. In Example \ref{ex:Encoding_TM}, we will delve into a similar procedure, not for storing the machine's current state, but for saving a comprehensive description of the machine itself. This methodology facilitates the enumeration, or listing, of all possible Turing machines. Such enumeration is instrumental in demonstrating the existence of problems that cannot be solved by any Turing machine (refer to Section \ref{sec:non_computable_problems}) and unveiling the pivotal concept of the \emph{Universal Turing Machine}.

\begin{example}
\label{ex:Encoding_TM}
To describe a Turing machine concisely, we need to encode the transition function $\tau:\left(Q\setminus \{q_{f}\}\right)\times\Gamma\rightarrow Q\times\Gamma\times\left\{ L,R,S\right\}$. This function can be represented as a collection of quintuples $\left(q,s,r,t,a\right)$, where $q \in \left(Q\setminus \{q_{f}\}\right)$, $r \in Q$, $s, t\in\Gamma$, and $a\in\left\{ L,R,S\right\}$. In this manner, any Turing machine $T$ is fully described by a collection of quintuples:
\[
\left(q_{1},s_{1},r_{1},t_{1},a_{1}\right),\left(q_{2},s_{2},r_{2},t_{2},a_{2}\right),\ldots,\left(q_{m},s_
{m},r_{m},t_{m},a_{m}\right)
\]
where $m \leq d\left(Q\setminus \{q_{f}\}\right) \times d(\Gamma)$, with the stipulation that the first quintuple refers to the initial state and the second one to the final state; i.e., $q_{1} = q_{o}$ and $r_{2} = q_{f}$. A possible approach to describe these quintuples is to encode the elements of the set $Q\cup\Gamma\cup\left\{ L, R, S \right\}$ using a fixed-length binary code (refer to Definition \ref{def:Fixed-Length-Codes} for more details), encoding the quintuple $\left(q,s,r,t,a\right)$ as $\left\langle q, s, r, t, a \right\rangle$. The length of an encoded quintuple is $5l$, where $l=\left\lceil \log\left(d\left(Q\cup\Gamma\cup\left\{ L,R,S\right\}\right)\right)\right\rceil$. Following this convention, machine $T$ is encoded as the binary string:
\[
\left\langle T \right\rangle = \left\langle \bar{l}, \left\langle q_{1}, r_{1}, s_{1}, t_{1}, a_{1} \right\rangle, \ldots, \left\langle q_{r}, r_{r}, s_{r}, t_{r}, a_{r} \right\rangle \right\rangle 
\]
The length of the encoded machine, following this schema, would be $l(\left\langle T \right\rangle) \leq 5lm + \log l + 1$.
\end{example}

Since each Turing machine is composed by a finite set of quintuples, we can encode and list all the machines using a shortlex ordering. We associate each machine $T$ with the index $i$ corresponding to its position in this list, and we denote by $T_i$ the i-th Turing machine. Each positive integer $i$ encodes one, and only one, Turing machine. However, as Proposition \ref{prop:padding_lemman} shows, all Turing machines have an infinite number of indexes. We associate each Turing machine with its smallest index.

\begin{proposition}[Padding Lemma]
\label{prop:padding_lemman}\index{Padding lemma}
Each Turing machine has infinitely many indexes.
\end{proposition}
\begin{proof}
Consider a Turing machine $T_i$ encoded by the string $\langle T_i \rangle$. We can create a new encoding $\langle T_j \rangle$  by appending a finite number of 0's to $\langle T_i \rangle$,  such that $\langle T_j \rangle = \langle T_i \rangle 0^n$  for some positive integer $n$. Since $n$ can take on any positive integer value, there are infinitely many possible encodings $\langle T_j \rangle$ for the same Turing machine $T_i$.
\end{proof}

A universal Turing machine is a machine that can simulate the behavior of any other Turing machine on arbitrary input. The universal machine achieves this by reading both the description of the machine to be simulated (for instance, using the coding schema described in Example \ref{ex:Encoding_TM}) and the input string for the computation from its own tape.

\begin{definition}[Universal Turing Machine]
\label{def:Universal-Turing-Machine}
\index{Universal Turing machine}
A \emph{Universal Turing Machine} is a Turing machine $U$ such that $U(\langle \langle T_i\rangle, s \rangle) = T_i(s)$ for all Turing machines $T_i$ and all input strings $s \in \mathcal{B}$.
\end{definition}

Naturally, we must prove that such a machine exists before we can utilize it. One could argue that a human being could decode the machine $T_i$ and simulate its behavior with the input string $s$, and then refer to Theorem \ref{th:turing_thesis}. A more rigorous approach would be to explicitly construct a universal Turing machine. However, providing a detailed description of one of these machines is beyond the scope of this book. Instead, we direct the reader to the references included at the end of the chapter for further exploration.

%
% Section: Non computable problems
%

\section{Non-Computable Problems}
\label{sec:non_computable_problems}

Turing machines enable us to delineate the set of problems that can be resolved through effective procedures or, in other words, by computers. It may be surprising to learn that numerous problems cannot be addressed using algorithms; such challenges lie beyond the computational capabilities of machines. We are not alluding to speculative queries like whether a computer can be intelligent or self-aware but to concrete, well-defined mathematical problems. We are also not referring to complex problems that demand a substantial amount of time to solve, as those, irrespective of their time consumption, remain computable.

One classic exemplar of non-computability is the \emph{halting problem}\index{Halting problem}. As illustrated in Algorithm \ref{alg:halt}, it involves a program or algorithm tasked with determining whether any given program (including itself) and input will eventually halt or continue to run indefinitely. Alan Turing proved that no algorithm can exist to solve this problem for all possible program-input pairs. This revelation wasn't a reflection on the limitations of technology or processing power but highlighted a profound theoretical limit intrinsic to computation.

\begin{algorithm}
\caption{HALT function}
\label{alg:halt}
\begin{algorithmic}
\Procedure{HALT}{$A, I$}
    \If{$A(I)$ halts} 
        \State \textbf{return} $1$
    \Else
        \State \textbf{return} $0$
    \EndIf
\EndProcedure
\end{algorithmic}
\end{algorithm}

The proposition below proves that the halting problem is non-computable.

\begin{proposition}[Halting Problem]
\index{Halting problem}
\label{th:halting-problem}
Define HALT as in Algorithm \ref{alg:halt}. There does not exist a Turing machine that computes the HALT function for all possible pairs $(A, I)$, where $A$ is a Turing machine and $I$ is the input string to that machine.
\end{proposition}
\begin{proof}
The proof is by contradiction. Assume that the machine $HALT$  exists, and define a new Turing machine $TC$ such that $TC(A) = 1$ if $HALT(A,A) = 0$, and $TC(A)$ will never stop if $HALT(A,A) = 1$. Then the contradiction arises when we ask about the result of $TC(TC)$: if $TC(TC)$ stops we have that $HALT(TC,TC) = 0$ and that $TC(TC)$ should not stop, and if $TC(TC)$ does not stop then we have that $H(TC,TC) = 1$ and thus $TC(TC)$ should stop.
\end{proof}

The existence of such non-computable problems underscores the boundaries of mechanical computation. It illustrates that while Turing machines, and by extension, computers are profoundly powerful tools capable of solving an extensive array of problems, they are not omnipotent. A frontier of unsolvable problems exists, necessitating deeper exploration into the realms of mathematics, logic, and perhaps even philosophy to understand the inherent limits of computation.

The Halting Problem also has significant practical consequences in computer programming. For instance, it is impossible to write a program that can guarantee any other arbitrary program is bug-free or that all infinite loops with conditional exits will eventually halt for all possible inputs.

The next example introduces a well-defined, practical problem involving simple string manipulation that cannot be solved using computers.

\begin{example}
\label{ex:PCP}
Given two finite lists $\left( \alpha_1, \ldots, \alpha_n \right)$ and $\left( \beta_1, \ldots, \beta_n \right)$ of strings over some alphabet $\Sigma$, where $d(\Sigma) \ge 2$, the \emph{Post Correspondence Problem}\index{Post Correspondence Problem} (PCP) asks to determine if there exists a sequence of $K \geq 1$ indices $(i_k)$, with $1 \le i_k \le n$ for all $1 \le k \le K$, such that $\alpha_{i_1} \ldots \alpha_{i_K} = \beta_{i_1} \ldots \beta_{i_K}$. For instance, given the sequences $(a, ab, bba)$ and $(baa, aa, bb)$, a solution would be $\alpha_3 \alpha_2 \alpha_3 \alpha_1 = \beta_{3} \beta_{2} \beta_{3} \beta_{1}$. No algorithm exists to solve PCP. Like many proofs of incomputability, the proof proceeds by showing that HALT can be reduced to PCP, meaning if PCP is decidable, then the Halting Problem should be decidable as well. We will not detail the proof in this section; for interested readers, we refer to the references at the end of this chapter.
\end{example}

Non-computable problems are generally not derived directly from natural phenomena but from logical and mathematical constructs. To date, there are no known examples of non-computable problems manifesting plainly in natural phenomena. It's essential to distinguish between non-computability and unpredictability. Non-computable problems are those for which no algorithm can ever be created to solve them. In contrast, unpredictable systems (such as chaotic or complex systems) are theoretically computable but are unpredictable in practice due to factors like sensitivity to initial conditions or measurement precision.

%
% Section: Computable Functions and Sets
%

\section{Computable Functions and Sets}
\label{sec:computable_functions}

Each Turing machine \(T\) defines a function \(f_T:\mathcal{B}^{\ast} \rightarrow \mathcal{B}^{\ast}\) that assigns to each input string \(s \in \mathcal{B}^{\ast}\) an output string \(T(s) \in \mathcal{B}^{\ast}\). This relationship between Turing machines and functions forms the basis for introducing the concept of a \emph{computable function}, a fundamental element in the field of computational theory.

\begin{definition}
\label{def:computable-function}
\index{Computable function}
A function \(f: \mathcal{B}^{\ast} \rightarrow \mathcal{B}^{\ast}\) is \emph{computable}\index{Computable function} if there exists a Turing machine \(T\) that defines the function \(f\).
\end{definition}

The terminology in computational theory can vary. While computable functions are occasionally referred to as \emph{recursive functions}\index{Recursive function}, this book opts for the term computable functions for consistency.

\begin{example}
In the context of this theoretical framework, let’s consider a practical example. The function that assigns to each pair of natural numbers \(x\) and \(y\) their sum \(x + y\) is computable, as demonstrated in Example \ref{ex:Turing-Machine}. The natural numbers and pairs are encoded as strings, transforming the original function into one operating in the realm of strings.
\end{example}

In real-world scenarios, certain functions don’t provide a defined output for all possible inputs. Partial functions, characterized by Turing machines that don’t halt for specific inputs, model these cases. This realistic representation of computational processes is essential in both theoretical exploration and practical application.

\begin{definition}
A partial function \(f:\mathcal{B}^{\ast} \rightarrow \mathcal{B}^{\ast}\) is \emph{partial computable}\index{Partial computable function} if there exists a Turing machine \(T\) that defines \(f\) for defined values and does not halt for undefined values.
\end{definition}

Partial functions, as next example shows, are only operational for certain input values. 

\begin{example}
The function $f: \mathbb{N} \times \mathbb{N} \rightarrow \mathbb{N}$ that assigns to each pair of natural numbers $x$ and $y$ the number $x - y$ is a partial computable function, since it is not defined in the case that $x < y$.
\end{example}

We can expand the application of the principles of computability and partial computability to the domain of sets. We characterize sets through the lens of theirs characteristic functions that discern the membership of elements within the sets.

\begin{definition}
A set $A \in \mathcal{B}^\ast$ is \emph{computable}\index{Computable set} if its characteristic function $\mathcal{X}_A$ is a total computable function. A set $A \in \mathcal{B}^\ast$ is \emph{computably enumerable}\index{Computably enumerable set} if its characteristic function $\mathcal{X}_A$ is a partial computable function, that is, $\mathcal{X}_A(a) = 1$ if $a \in A$, but $\mathcal{X}_A(a)$ is undefined if $a \not\in A$.
\end{definition}

The application of these concepts is illustrated through the example of the set of all Turing machines that halt for all inputs.

\begin{example}
The set of all Turing machines that halt on all inputs, as demonstrated in \ref{th:halting-problem}, is not computable but is computably enumerable.
\end{example}

These definitions and examples provide insights into the delicate interplay between functions, sets, Turing machines, and the realm of the computability and non-computability.

%
% Section: Oracle Turing Machine
%

\section{Oracle Turing Machine}
\label{sec:oracle_turing_machine}

{\color{red} TODO: Introduce the concept}

{\color{red} TODO: Provide a diagram}

Withe the aid of the Oracle, a Turing machine could solve uncomputable problems, like the halting problem.

{\color{red} The oracle tape is a one-way unbounded, read-only tape that contains all the values of the characteristic function $\chi_\mathcal{O}$. We assume that it takes, for arbitrary $w \in \Sigma^\ast$, only one step to search the tape and return the value of $\chi_\mathcal{O}(w)$.}

\begin{definition}[Oracle Turing Machine]
\label{def:Oracle-Turing-Machine}
An \emph{oracle Turing machine} with oracle set $\mathcal{O}$ is a 8-tuple $\left(Q, \Gamma, \sqcup, \Sigma, q_i, q_f, \tau, \mathcal{O} \right)$ where:
\begin{align*}
 & Q \quad \text{is a finite, non-empty, set of \emph{states},} \index{Machine State} \\
 & \Gamma \quad \text{is a finite, non-empty, set of \emph{tape symbols},} \index{Tape Symbol} \\
 & \sqcup\in\Gamma \quad \text{is the \emph{blank symbol},} \index{Blank Symbol} \\
 & \Sigma\subseteq\Gamma\setminus\sqcup \quad \text{is the set of \emph{input symbols},}  \index{Input Symbol} \\
 & q_{o}\in Q \quad \text{is the \emph{initial state},} \index{Initial State} \\
 & q_{f}\in Q \setminus \{q_o\} \quad \text{is the \emph{final state},} \index{Final State} \\ 
 & \tau: \left(Q \setminus \{q_{f}\}\right) \times \Gamma \times \{0, 1\} \rightarrow  Q\times\Gamma\times\left\{ L,R,S\right\} \quad\text{is the \emph{transition function}, \index{Transition Function} } \\
 & \mathcal{O} \subseteq \Sigma^\ast \quad \text{is the \emph{oracle set}.}
\end{align*}
\end{definition}

Properties:

 * The machine is independent of the oracle set
 * Turing machines are a subset of oracle Turing machines

Talk about:

 * How to encode oracle Turing machines
 * What means a function or set to be oracle computable
 * 

%
% Section: Computational Complexity
%

\section{Computational Complexity}
\label{sec:computational_complexity}

{\color{red} Computational Complexity theory is an investigation of the time, memory, or other resources required for solving computational problems.} In this book we are insterested mostly in the time required to solve a problem. {\color{red} We compute the running time of an algorithm as a function of the length of the string representing the input.}

{\color{red} TODO: Adapt this definiton.}
\begin{definition}
Let $M$ a deterministic Turing machine that halts on all inputs. The running time or time complexity of $M$ is the function $f:\mathbb{N}\rightarrow\mathbb{N}$, where $f(n)$ is the maximum number of steps that $M$ uses in any input of length $n$. If $f(n)$ is the running time of $M$, we say that $M$ runs in time $f(n)$ and that $M$ is an $f(n)$ time Turing machine.
\end{definition}

{\color{red} It considers only the highest order term of the expression for the running time of the algorithm, disregarding both the coefficient of that term and any lower order terms.}

{\color{red} Introduce polynomial bounds $O(n^c)$}

{\color{red} TODO: Adapt this definiton.}
Let $t:\mathbb{N}\rightarrow\mathbb{R}^{+}$ be a function. Define the time complexity class, $TIME(t(n))$, to be the collection of all languages that are decidible by an $O(t(n))$ time Turing machine.

{\color{red} TODO: Add the following as an example:
Let $t(n)$ be a function, where $t(n)\geq n$. Then every $t(n)$ time multiple tape Turing machine has an equivalent $O(t^{2}(n))$ time single-tape Turing machine.
}

{\color{red} Polynomial differences in running time are considered to be small, whereas exponential differeces are considered to be large.}


{\color{red} Adapt this definition:
\begin{definition}
$P$ is the class of languages that are decidible in polynomial time on a deterministic single-tape Turing machine $P=\cup_{k}TIME(n^{k})$.
\end{definition} 

$P$ roughly corresponds to the class of problems that are realistically solvable on a computer.}

{\color{red} Add the following example of problem in P: PATH = \{ $\langle G,s,t\rangle|G$ is a directed graph that has directed path from $s$ to $t$ }

{\color{red} Adapt this definition:
\begin{definition}
A verifier for a language $A$ is an algorithm $V$, where $A=\{w|V$ accepts $\langle w, c\rangle$ for some string $c\}$.
\end{definition}
}

{\color{red} We measure the time of a verier only in terms of the length of $w$, so a polynomial time verifier runs in polynomial time in the length of $w$
. A language $A$ is polynomially verifiable if it has a polynomial time verifier. The symbol $c$ is called a certificate, or proof of membership in $A$.}

{\color{red}
\begin{definition}
$NP$ is the class of languages that have polynomial time verifiers.
\end{definition}
}


{\color{red} TODO: Include an example.}

{\color{red} $P$ is the class of languages for which membership can be decided quickly. $NP$ is the class of languages for which membership can be verified quickly. The question of whether $P=NP$ is one of the greatest unsolved problems in theoretical computer science and contemporary mathematics.}


{\color{red} TODO: Not sure about the rest of this chapter:

Definition 14. A function $f:\Sigma^{\ast}\rightarrow\Sigma^{\ast}$ is a polynomial time computable function if some polynomial time Turing machine $M$ exists that halts with just $f(w)$ on its tape, when started on any imput $w$.

When problem $A$ reduces to problem $B$, a solution to $B$ can be used to solve $A$.

Definition 15. Language $A$ is polynomial time mapping reducible, or simply polynomial time reducible, to language $B$, written $A\leq_{P}B$, if a polynomial time computable function $f:\Sigma^{\ast}\rightarrow\Sigma^{\ast}$ exists, where for every $w$ $w\in A\iff f(w)\in B$

The function $f$ is called the polynomial time reduction of $A$ to $B$.

If one language is polynomial time reducible to a language already known to have a polynomial time solution, we obtain a polynomial time solution to the original language.

Theorem 16. If $A\leq_{P}B$ and $B\in P$, then $A\in P$.

Definition 17. A language $B$ is NP-complete if it satisfies two conditions: $B$ is in $NP$, and every $A$ in $NP$ is polynomial time reducible to $B$.

Theorem 18. If $B$ is NP-complete and $B\in P$, then $P=NP$.

Theorem 19. If $B$ is NP-complete and $B\leq_{P}C$ for $C$ in $NP$, then $C$ is NP-Complete.

}

%
% Section: References
%

\section*{References}

{\color{red} TODO:  Briefly mention the historical emergence of the concept, including the works of pioneers like Alan Turing, Alonzo Church, and others.}

The original paper form Alan Turing where the concepts of Turing machine, universal Turing machine, and non-computable problems were introduced is \cite{turing1936computable}, however it is a difficult to read paper for the contemporary reader. An easier to read introduction to computability theory, from the point of view of languages, can be found in \cite{sipser2012introduction}, and a more advanced introductions in \cite{cooper2003computability} and \cite{soare2016turing}. In \cite{fernandez2009models} we can find a description of the most important computability models proposed so far. The Post Correspondence Problem was introduced by Emil Post in \cite{post1946variant}; for the details of the proof sketched in Example \ref{ex:PCP} please refer to \cite{sipser2012introduction}.

{\color{red} TODO: Here are a few seminal academic works on non-computability:

Turing, A. M. (1936). On Computable Numbers, with an Application to the Entscheidungsproblem. Proceedings of the London Mathematical Society, s2-42(1), 230-265. Content: This foundational paper by Alan Turing introduces the concept of Turing machines, laying the groundwork for the theory of computation and establishing the halting problem's non-computability.

Church, A. (1936). An Unsolvable Problem of Elementary Number Theory. American Journal of Mathematics, 58(2), 345-363. Content: Alonzo Church presents the $\lambda$-calculus and establishes Church’s Thesis, claiming that his formalism captures the intuitive notion of "computable," and proving the unsolvability of the Entscheidungsproblem.

Gödel, K. (1931). Über formal unentscheidbare Sätze der Principia Mathematica und verwandter Systeme, I. Monatshefte für Mathematik, 38(1), 173-198. Content: Kurt Gödel's landmark paper where he introduces his incompleteness theorems, showing that within any sufficiently powerful mathematical system, there are statements that cannot be proven or disproven.

Post, E. (1946). A Variant of a Recursively Unsolvable Problem. Bulletin of the American Mathematical Society, 52(4), 264-268. Content: Emil Post presents a simpler, more accessible proof of unsolvability (non-computability) related to the halting problem and delves into the Post Correspondence Problem, a classic example of a non-computable problem.

Davis, M. (1958). Computability and Unsolvability. McGraw-Hill. Content: In this book, Martin Davis offers a comprehensive overview of the theory of computability and unsolvability, addressing topics like recursive functions, Turing machines, and Gödel’s incompleteness theorems in an accessible manner.

These references should provide a solid academic foundation for exploring the multifaceted and intriguing world of non-computability. Each offers unique insights and perspectives that collectively illuminate the complexity and depth of this area of study.
}

{\color{red} TODO: Add a reference to how to build a universal Turing machine.}

{\color{red} TODO: Introduce other well-known non-computable problems besides the halting problem, like Turing’s “Entscheidungsproblem” or the Busy Beaver function.}

{\color{red} TODO: Relate non-computability to Gödel's incompleteness theorems to illustrate the inherent limitations in formal mathematical systems.}

{\color{red} TODO: Explore philosophical discussions on the implications of non-computability for artificial intelligence and human cognition.}

