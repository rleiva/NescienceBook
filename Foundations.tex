%
% Foundations of Mathematics
%

\chapterimage{Philosophers.pdf}

\chapter{Foundations of Mathematics}
\label{apx:foundations_mathematics}

{\color{red} TODO: Introduce this chapter.}

Propositional logic deal with sentences, which can be true or false, and they way we can combine those sentences to construct arguments. Predicate logic extends propositional logic introducing quantified variables and relations, allowing richer arguments. Logic is studied here with the aim of providing the tools to examine the soundness, consistency and completeness of the axiomatic foundations of the theory of nescience. The exposition of logic contained in this chapter is a little bit unconventional. Most of the textbooks describing logic assume set theory, and the books on set theory require logic. We avoid this circularity by defining formulas as strings of symbols and logic as the rules to properly manipulate those strings. With this approach we loose the intuition behind logic, and the interpretability of the results. However, this book is about computers and automation, where meaning does not play a particular role.

{\color{red} TODO: Explain why if we have predicate logic to formalize the theory of nescience we also include type theory and category theory in this chapter.}

%
% Section: Propositional Logic
%

\section{Propositional Logic}

\emph{Propositional logic} is about the relationship between the truth of \emph{propositions}. Most of the authors require propositions to be declarative sentences, that is, they can be affirmed or denied. However, from a formal point of view, the content of propositions is not relevant to logic, and so, we will assume that any finite string of symbols can be a proposition. 

The language (syntax) of propositional logic contains two \emph{primitive symbols}, $\lnot$ and $\land$, called "\emph{not}" and "\emph{and}" respectively.  Propositions that do not contain those primitive symbols are called \emph{atomic sentences}. Atomic sentences are denoted by capital letters $A, B, C, \ldots$.

Formulas in propositional logic are derived from atomic sentences and primitive symbols.

\begin{definition}
\label{definition:logic_formula}
A finite string of symbols is a \emph{formula}, denoted by the capital letters $F, G, H, \ldots$, if and only if it is an atomic sentence or it is build up from atomic sentences by repeated application of the following two rules:
\begin{description}
\item[R1 (negation)] If $F$ is a formula, then $\lnot F$ is a formula.
\item[R2 (conjunction)] If $F$ and $G$ are formulas, then $( F \land G )$ is a formula.
\end{description}
\end{definition}

For example, the string $\lnot ( A \land (B \land C) )$ is a formula, but the string $ \lnot \land ( A \land B C ($ is not.

In order to make complex formulas easier to read (by humans), the following convenient abbreviations are introduced:

\begin{definition}
Let $F$ and $G$ be two formulas. The symbols $\lor$, $\rightarrow$ and $\leftrightarrow$, called "\emph{or}", "\emph{implies}" and "\emph{if and only if}" respectively, are defined as:
\begin{enumerate}[label=(\roman*)]
\item $\left( F \lor G \right)$ abbreviates $ \lnot \left( \lnot F \land \lnot G \right)$
\item $\left( F \rightarrow G \right)$ abbreviates $\left( G \lor \lnot F \right)$
\item $\left( F \leftrightarrow G \right)$ abbreviates $ \left( F \land \rightarrow G \right) \land \left( G \rightarrow F \right)$
\end{enumerate}
\end{definition}

Also, with readability in mind, the following notation is used:

\begin{notation}
If $F$ or $\left( F \right)$ is a formula, then the formulas $F$ and $\left( F \right)$ are considered as the same formula.
\end{notation}

If no parentheses are present, the symbol $\lnot$ has priority over the symbols $\land$, $\lor$, $\rightarrow$ and $\leftrightarrow$. For example, the formulas $\lnot ( A \land B )$ and $\lnot A \land B$ are different.

A subformula of a formula $F$ is a substring of $F$ that is itself a formula.

\begin{definition}
The \emph{subformulas} of a formula are defined as:
\begin{enumerate}[label=(\roman*)]
\item If $F$ is a formula, then $F$ is a subformula of itself. 
\item If $F$ is a formula and $G$ is a subformula of $F$, then $G$ is also a subformula of $\lnot F$. 
\item If $F$ and $G$ are formulas and $H$ is a subformula of $F$ or a subformula of $G$, then $H$ is also a subformula of $(F \land G)$.
\end{enumerate}
\end{definition}

From a semantic point of view, each formula has either a true value of \emph{true} or a true value of \emph{false}, represented by the symbols $1$ and $0$ respectively. The semantic of a formula is derived using \emph{true tables}. A true table is a table that given an assignment of values to atomic formulas allows us to derive the true value of more complex formulas.

The true table of the not symbol $\lnot$ is given by:

\begin{center}
\begin{tabular}{ c | c }
 $A$ & $\lnot A$ \\
 \hline
 $0$ & $1$  \\  
 $1$ & $0$    
\end{tabular}
\end{center}

The true table of the and symbol $\land$ is given by:

\begin{center}
\begin{tabular}{ c | c | c }
 $A$ & $B$ & $A \land B$ \\
 \hline
 $0$ & $0$ & $0$ \\
 $0$ & $1$ & $0$ \\
 $1$ & $0$ & $0$ \\
 $1$ & $1$ & $1$   
\end{tabular}
\end{center}

The true tables of more complex formulas can be derived by the repeated application of these two tables.

\begin{example}
The true table of the if-then, or implies, symbol $\rightarrow$ can be derived as follow:
\begin{center}
\begin{tabular}{ c | c | c | c }
 $A$ & $B$ & $\lnot A$ & $\lnot A \lor B$ \\
 \hline
 $0$ & $0$ & $1$ & $1$ \\
 $0$ & $1$ & $1$ & $1$ \\
 $1$ & $0$ & $0$ & $0$ \\
 $1$ & $1$ & $0$ & $1$
\end{tabular}
\end{center}
As we can observe in this table, a counterintuitive property of propositional logic is that a false statement implies anything.
\end{example}

Similar tables can be derived for the symbols $\lor$ and $\leftrightarrow$.

Let $A_1, \ldots, A_n$ be a list of $n$ atomic sentences, and let $\mathcal{F}(A_1, \ldots, A_n)$ denote all the formulas that can be built from those atomic sentences given Definition \ref{definition:logic_formula}. The list $A_1, \ldots, A_n$ is denoted by $\mathcal{S}$.

\begin{definition}
An \emph{assignment} of $\mathcal{S}$, denoted by $\mathcal{A}(\mathcal{S})$ or simply $\mathcal{A}$ if there is no doubt about the $S$ to which we are referring, is a mapping of the sentences of $\mathcal{S}$ to a list of $n$ true values. 
\end{definition}

An assignment $\mathcal{A}(\mathcal{S})$ can be extend to all the sentences of $\mathcal{F}(\mathcal{S})$ by means of computing the corresponding true tables. The true value of a sentence $F$ given the assignment $\mathcal{A}(\mathcal{S})$ is denoted by $\mathcal{A}(F)$.

\begin{definition}
If $\mathcal{A}(F)=1$ then it is said that $F$ \emph{holds} under assignment $\mathcal{A}$, or that $\mathcal{A}$ \emph{models} $F$, and it is denoted by $\mathcal{A} \models F$. A formula is \emph{satisfiable} if it holds under some assignment. A formula is \emph{valid}, denoted by $\models F$, if it holds under every assignment; a valid formula is called a \emph{tautology}. A formula is \emph{unsatisfiable} if it holds under no assignment; an unsatisfiable formula is called a \emph{contradiction}.
\end{definition}

\begin{example}
Next table shows that the formula $(A \lor B) \land (\lnot A \land \lnot B)$ is a contradiction.
\begin{center}
\begin{tabular}{ c | c | c | c | c | c | c}
 $A$ & $B$ & $A \lor B$ & $\lnot A$ & $\lnot B$ & $\lnot A \land \lnot B$ & $(A \lor B) \land (\lnot A \land \lnot B)$ \\
 \hline
 $0$ & $0$ & $0$ & $1$ & $1$ & $1$ & $0$ \\
 $0$ & $1$ & $1$ & $1$ & $0$ & $0$ & $0$ \\
 $1$ & $0$ & $1$ & $0$ & $1$ & $0$ & $0$ \\
 $1$ & $1$ & $1$ & $0$ & $0$ & $0$ & $0$
\end{tabular}
\end{center}
\end{example}

\begin{definition}
Let $F$ and $G$ be two formulas. It is said that $G$ is a \emph{consequence} of $F$, denoted by $F \models G$, if, and only if, $F \rightarrow G$ is a tautology, 
\end{definition}

It is easy to show that a formula $G$ is a consequence of formula $F$ if for every assignment $\mathcal{A}$, if $\mathcal{A} \models F$ then $\mathcal{A} \models G$.

\begin{definition}
Let $F$ and $G$ be two formulas. It is said that $F$ and $G$ are \emph{equivalent}, denoted by $F \equiv G$, if, and only if, $F \leftrightarrow G$ is a tautology.
\end{definition}

It is easy to show that if $G$ is a consequence of $F$ and $F$ is a consequence of $G$, then $F$ and $G$ are equivalent.

\begin{example}
The \emph{law of contraposition} states that $A$ implies $B$ is equivalent to not $B$ implies not $A$; with symbols $( A \rightarrow B ) \equiv ( \lnot B \rightarrow \lnot A )$. Next true table shows that $( A \rightarrow B ) \leftrightarrow ( \lnot B \rightarrow \lnot A )$ is a tautology.
\begin{center}
\begin{tabular}{ c | c | c | c | c | c | c}
 $A$ & $B$ & $A \rightarrow B$ & $\lnot B$ & $\lnot A$ & $\lnot B \rightarrow \lnot A$ & $(A \rightarrow B) \leftrightarrow (\lnot B \rightarrow \lnot A)$ \\
 \hline
 $0$ & $0$ & $1$ & $1$ & $1$ & $1$ & $1$ \\
 $0$ & $1$ & $1$ & $0$ & $1$ & $1$ & $1$ \\
 $1$ & $0$ & $0$ & $1$ & $0$ & $0$ & $1$ \\
 $1$ & $1$ & $1$ & $0$ & $0$ & $1$ & $1$
\end{tabular}
\end{center}
\end{example}

{\color{red}

Introduce and explain the following definition.

\begin{definition}
Let $\mathcal{F} = \{ F_1, F_2, ... \}$ be a set of formulas. For any assignment $\mathcal{A}$, we say $\mathcal{A}$ models $\mathcal{F}$, denoted by $\mathcal{A} \models \mathcal{F}$ if $\mathcal{A} \models F_i$ for each formula $F_i \in \mathcal{F}$. We say a formula $G$ is a consequence of $\mathcal{F}$, and write $\mathcal{F} \models G$, if $\mathcal{A} \models \mathcal{F}$ implies $\mathcal{A} \models G$ for every assignment $\mathcal{A}$
\end{definition}

}

{\color{red}

A proof system consists of a set of basic rules for derivations. These rules allow us to deduce formulas from sets of formulas. It may take several steps to derive a given formula $G$ from a set of formulas $\mathcal{F}$, where each step is an application of one of the basic rules. The list of steps forms a formal proof of $G$ from $\mathcal{F}$. 

We write $\mathcal{F} \vdash G$ to abbreviate "$G$ can be derived from $\mathcal{F}$.

A proof system is sound if the following property hold: if a formula $G$ can be derived from a set of formulas $\mathcal{F}$, then $G$ is a consequence of $\mathcal{F}$ (if $\mathcal{F} \vdash G$, then $\mathcal{F} \models G$).

If a proof system is sound, then it provides an alternative to truth tables for determining whether a formula $G$ is a consequence of a set of formulas $F$.

\begin{definition}
A formal proof in propositional logic is a finite sequence of statements of the form "$\mathcal{X} \vdash Y$" (where $\mathcal{X}$ is a set of formulas and $Y$ is a formula) each of which follows from the previous statemens by one of the rules in Table 1.5. We say that $G$ can be derived from $\mathcal{F}$ if there is a formal proof concluding with the statement $\mathcal{F} \vdash G$.
\end{definition}

}

{\color{red}

Formulas $F$ and $G$ are provably equivalent if both $\{ F \} \vdash G$ and $\{ G \} \vdash F$. If $F$ and $G$ are provably equivalent, then they are equivalent.

}

{\color{red} TODO: Proofs in the logic and proofs outside the logic.}

%
% Section: Predicate Logic
%

\section{Predicate Logic}
\label{sec:predicate_logic}

\emph{Predicate logic}, also known as \emph{first-order logic}, extends propositional logic with the use of variables and quantifiers over variables, in such a way that we can state the relation between non-logical objects. The language of predicate logic contains three \emph{primitive symbols}, the two symbols inherited from propositional logic $\lnot$, $\land$, and a new symbol $\exists$ called \emph{exists}. In this book we are interested in predicate logic with equality, and so, we add a fourth primitive symbol $=$ called \emph{equality}.

In propositional logic our object of study where formulas, that is, strings of symbols that follows well-defined syntactic rules. In predicate logic we also deal with formulas. The difference is that some of the symbols contained in formulas are distinguished because they play a special role. The distinguished symbols are :

\vskip 0.25cm

\begin{description}
\item [Variables] denoted by lower case letters from the end of the alphabet $(\ldots, x, y, z)$.
\item [Constants] denoted by lower case letters from the beginning of the alphabet $(a, b, c, \ldots)$. 
\item [N-ary functions] denoted by lower case letters $f, g$ and $h$.
\item [N-ary relations] denoted by upper case letters $P, Q, R$ and $S$.
\end{description}

\vskip 0.25cm

\begin{notation}
Given the limited number of letters of the alphabet, we can use subscripts to distinguish between the elements of formulas. For example, $x_1, x_2, x_3, \ldots$.
\end{notation}

The concept of N-ary function and and N-ary relation is better understood in the context of set theory. However, at this point we can not talk about sets, since the concept of set has not not been formally defined yet. As we will see in Section \ref{sec:set_theory}, in order to deal with sets, we have first to introduce a new symbol $\in$, and assume that some axioms (which are based on predicate logic) are true. By the moment, functions and relations are just distinguished symbols.

Next definition introduces the concept of \emph{term}, an intermediate step before to define the concept of \emph{formula}.

\begin{definition}
A finite string of symbols is a \emph{term} if and only if it is build up by repeated application of the following two rules:
\begin{description}
\item[T1] Every variable and every formula is a term.
\item[T2] If $f$ is an $N$-ary function and $t_1, t_2, \ldots, t_N$ are terms, then $f(t_1, t_2, \ldots, t_N)$ is also a term.
\end{description}
\end{definition}

Given the concept of term, we can formally define what we mean by atomic formula.

\begin{definition}
Let $t_1$ and $t_2$ be two terms, then the string $t_1 = t_2$ is an \emph{atomic formula}.
Let $R$ be a relation and $t_1, t_2, \ldots, t_N$ be $N$ terms, then the string $R(t_1, t_2, \ldots, t_N)$ is an \emph{atomic formula}.
\end{definition}

Formulas are built based on primitive symbols and atomic formulas. Recall rules \textbf{R1} and \textbf{R2} of Definition \ref{definition:logic_formula}. The same rules can be applied in predicate logic, together with a new rule. We use lower case Greek letters to denote formulas.

\begin{definition}
A string of symbols is a formula of first order logic if it is an atomic formula, or it can be derived by repeated application of the following rules:
\begin{description}
\item[R1] If $\varphi$ is a formula, then $\lnot \varphi$ is a formula.
\item[R2] If $\varphi$ and $\psi$ are formulas then $\varphi \land \psi$ is a formula.
\item[R2] If $\varphi$ is a formula and $x$ a variable then $\exists x \varphi$ is a formula.
\end{description}
\end{definition}

In predicate logic we also itroduce the following convenient abbreviation.

\begin{definition}
Let $x$ be a variable and $\varphi$ a formula. The symbol $\forall$, called \emph{for all}, is defined as:
\begin{enumerate}
\item $\forall x \varphi$ abbreviates $\lnot \exists x \lnot \varphi$.
\end{enumerate}
\end{definition}

\begin{example}
\end{example}

If no parenthesis are present, $\lnot$, $\exists$ and $\forall$ have priority over $\land$, $\lor$, $\rightarrow$ and $\leftrightarrow$.

In order to define the semantics of the symbols $\exists$ and $=$ we need the concept of \emph{structure}, since those symbols only make sense when they are associated with a structure. A structure consists of a underlying set together with an interpretation of the constants, functions and relations. However, in order to that, first we have to formally define what we mean by set.

%
% Set Theory
%
\section{Set Theory}
\label{sec:set_theory}

In this section we describe the ZFC axiomatic system for the theory of sets, named after the mathematicians Ernst Zermelo and Abraham Fraenkel. The 'C' in ZFC refers to the axiom of choice, also included in the initial list of axioms. ZFC is considered the standard form for axiomatic set theory, and it is the most common foundation of mathematics. An important point of ZFC is that all the entities in the universe of discource are sets, and so, elements that are not sets themselves are not allowed.

\begin{description}

\item[Axiom of Extensionality] If the set $x$ and the set $y$ have the same elements, then $x=y$.

\item[Axiom of Pairing] For any sets $a$ and $b$ there exist a set $\{a, b\}$ that contains exactly $a$ and $b$.

\item[Axiom Schema of Separation] If $P$ is a property with parameter $p$, then for any set $x$ and parameter $p$ there exists a set $y=\{u \in x : P(u,p) \}$ that contains all those sets $u \in x$ that have property $P$\footnote{It called axiom schema because there exists one axiom for each $P$.}.

\item[Axiom of Union] For any set $x$ there exists a set $y = \cup x$, the union of all elements of $x$. 

\item[Axiom of Power Set] For any set $x$ there exists a set $y = \mathcal{P}(x)$, the set of all subsets of $x$.

\item[Axiom of Infinity] There exists an infinite set.

\item[Axiom Schema of Replacement] If $F$ is a function, then for any set $x$ there exists a set $y = F(x) = \{F(u) : u \in x \}$. 

\item[Axiom of Regularity] Every nonempty set has an $\in$-minimal element.

\item[Axiom of Choice] Every family of nonempty sets has a choice function.

\end{description}


%
% Type Theory
%

\section{Type Theory}

{\color{red}

$\lambda$-calculus is a system that encapsulates a formalization of the basic aspects of functions, in particular their construction and their use.
Types is an abstraction of the process of classifying entities into greater units.

When dealing with functions there are two construction principles an one evaluation rule. The construction principles are the following:

Abstraction: From an expression M and a variable x we can construct a new expression $\lambda x.\:M$. We call this abstraction of x over M.

Application: From expressions M and N we can construct expression $M\:N$. We call this application of M to N.

If necessary, some parentheses should be added during the construction process.

Evaluation: Where an expression of the form $\left(\lambda x.\:M\right)N$ is rewritten to the expression $M\left[x:=N\right]$ (the expression M in
which every x has been replaced with N). We call this process $\beta$-reduction.

Reduction can be extend from subexpressions of bigger expressions (compatibility). The behavior of a function of two (or more) arguments can
be simulated by converting it into a composite of a single argument (currying).

}

We assume the existence of a finite list of symbols $v_1, v_2, \ldots, v_n$ called variables. 

\begin{definition}

A $\lambda$-term is inductively defined as:

$V ::= v_1 \mid v_2 \mid \ldots \mid v_n$

$\lambda-term ::= V \mid \left( \lambda-term \lambda-term \right) \mid \left( \lambda V.\: \lambda-term \right)$

We denote $\Lambda$ the collection of all the $\lambda$-terms definied with the above grammar.

\end{definition}

{\color{red}

The main concern of the discipline of lambda calculus is the behavior of functions in the simplest, most abstract view.
Expressions in the lambda calculus are called $\lambda$-terms.

We assume the existence of an infinite set $V=\{x,y,z,\ldots\}$ of so-called variables.

\begin{definition}
We define $\Lambda$, the set of all $\lambda$-terms inductively as:

i) (Variable) If $u\in V$, then $u\in\Lambda$.

ii) (Application) If $M$ and $N\in\Lambda$, then $\left(M\:N\right)\in\Lambda$.

iii) (Abstraction) If $u\in V$ and $M\in\Lambda$, then $\left(\lambda u.\:M\right)\in\Lambda$.
\end{definition}

Alternatively, we could define $\Lambda$ with the following grammar:$\Lambda=V\mid\left(\Lambda\Lambda\right)\mid\left(\lambda V.\:\Lambda\right)$

We use the letters x, y, z and variants with subscripts and primes to denote variables in V. To denote elements of $\Lambda$, we use L, M, N, P, Q, R
and variants thereof. Syntactically identity of two $\lambda$-terms will be denoted by the symbol $\equiv$.

\begin{definition}
The multiset of subterms, denoted $Sub$, is inductively defined as:

i) (Variable) $Sub\left(x\right)=\left\{ x\right\}$ , for each $x\in V$.

ii) (Application) $Sub\left(\left(MN\right)\right)=Sub\left(M\right)\cup Sub\left(N\right)\cup\left\{ \left(MN\right)\right\}$.

iii) (Abstraction) $Sub\left(\left(\lambda x.\:M\right)\right)=Sub\left(M\right)\cup\left\{ \left(\lambda x.\:M\right)\right\}$.
\end{definition}

We call L a subterm of $M$ if $L\in Sub\left(M\right)$.

Lemma 3. (Reflexivity) For all $\lambda$-terms $M$, we have $M\in Sub\left(M\right)$.
(Transitivity) If $L\in Sub\left(M\right)$ and $M\in Sub\left(N\right)$, then $L\in Sub\left(N\right)$.

\begin{definition}
$L$ is a proper subterm of $M$ if $L$ is a subterm of $M$, but $L\not\equiv M$.
\end{definition}

Parentheses in an outermost position may be omitted; application is left-associative; application takes precedence over abstraction;
successive abstractions may be combined in a right-associative way under one $\lambda$.

}


%
% Category Theory
%
\section{Category Theory}


